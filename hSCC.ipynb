{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Cell 2: force single‐threaded BLAS\n",
    "os.environ[\"OMP_NUM_THREADS\"]       = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: actually cap BLAS to 1 thread\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "# 'blas' covers OpenBLAS, MKL, etc.\n",
    "threadpool_limits(limits=1, user_api='blas')\n",
    "\n",
    "# now import as usual, no more warning\n",
    "import numpy as np\n",
    "import scipy\n",
    "# … any other packages that use OpenBLAS …\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "from sklearn.preprocessing import normalize\n",
    "import ot \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import AdvancedHierarchicalDiffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# patient 2 data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cSCC data...\n",
      "Preparing combined ST data for diffusion training...\n",
      "Common genes across all datasets: 2000\n",
      "Combined ST data shape: (1950, 2000)\n",
      "Combined ST coords shape: (1950, 2)\n",
      "SC data shape: (2688, 2000)\n",
      "Data preparation complete!\n",
      "SC cells: 2688\n",
      "Combined ST spots: 1950\n",
      "Common genes: 2000\n"
     ]
    }
   ],
   "source": [
    "def load_and_process_cscc_data():\n",
    "    \"\"\"\n",
    "    Load and process the cSCC dataset with multiple ST replicates.\n",
    "    \"\"\"\n",
    "    print(\"Loading cSCC data...\")\n",
    "    \n",
    "    # Load SC data\n",
    "    scadata = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP2.h5ad')\n",
    "    \n",
    "    # Load all 3 ST datasets\n",
    "    stadata1 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2.h5ad')\n",
    "    stadata2 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep2.h5ad')\n",
    "    stadata3 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep3.h5ad')\n",
    "    \n",
    "    # Normalize and log transform\n",
    "    for adata in [scadata, stadata1, stadata2, stadata3]:\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "    \n",
    "    # Create rough cell types for SC data\n",
    "    scadata.obs['rough_celltype'] = scadata.obs['level1_celltype'].astype(str)\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CLEC9A','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CD1C','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='ASDC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='PDC','rough_celltype'] = 'PDC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='MDSC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='LC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Mac','rough_celltype'] = 'Myeloid cell'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Tcell','rough_celltype'] = 'T cell'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype']=='TSK','rough_celltype'] = 'TSK'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype'].isin(['Tumor_KC_Basal', 'Tumor_KC_Diff','Tumor_KC_Cyc']),'rough_celltype'] = 'NonTSK'\n",
    "    \n",
    "    return scadata, stadata1, stadata2, stadata3\n",
    "\n",
    "def prepare_combined_st_for_diffusion(stadata1, stadata2, stadata3, scadata):\n",
    "    \"\"\"\n",
    "    Combine all ST datasets for diffusion training while maintaining gene alignment.\n",
    "    Key innovation: Use ALL ST data points for better training.\n",
    "    \"\"\"\n",
    "    print(\"Preparing combined ST data for diffusion training...\")\n",
    "    \n",
    "    # Get common genes between SC and all ST datasets\n",
    "    sc_genes = set(scadata.var_names)\n",
    "    st1_genes = set(stadata1.var_names)\n",
    "    st2_genes = set(stadata2.var_names)\n",
    "    st3_genes = set(stadata3.var_names)\n",
    "    \n",
    "    common_genes = sorted(list(sc_genes & st1_genes & st2_genes & st3_genes))\n",
    "    print(f\"Common genes across all datasets: {len(common_genes)}\")\n",
    "    \n",
    "    # Extract aligned expression data\n",
    "    sc_expr = scadata[:, common_genes].X\n",
    "    st1_expr = stadata1[:, common_genes].X\n",
    "    st2_expr = stadata2[:, common_genes].X\n",
    "    st3_expr = stadata3[:, common_genes].X\n",
    "    \n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(sc_expr, 'toarray'):\n",
    "        sc_expr = sc_expr.toarray()\n",
    "    if hasattr(st1_expr, 'toarray'):\n",
    "        st1_expr = st1_expr.toarray()\n",
    "    if hasattr(st2_expr, 'toarray'):\n",
    "        st2_expr = st2_expr.toarray()\n",
    "    if hasattr(st3_expr, 'toarray'):\n",
    "        st3_expr = st3_expr.toarray()\n",
    "    \n",
    "    # Get spatial coordinates\n",
    "    st1_coords = stadata1.obsm['spatial']\n",
    "    st2_coords = stadata2.obsm['spatial']\n",
    "    st3_coords = stadata3.obsm['spatial']\n",
    "\n",
    "    # Store separate coordinate lists for block-diagonal graph\n",
    "    st_coords_list = [st1_coords, st2_coords, st3_coords]\n",
    "    \n",
    "    # Combine all ST data\n",
    "    st_expr_combined = np.vstack([st1_expr, st2_expr, st3_expr])\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    st_expr_combined = scaler.fit_transform(st_expr_combined)\n",
    "\n",
    "    st_coords_combined = np.vstack([st1_coords, st2_coords, st3_coords])\n",
    "\n",
    "    sc_expr = scaler.fit_transform(sc_expr)\n",
    "\n",
    "    \n",
    "    # Create dataset labels for tracking\n",
    "    dataset_labels = (['dataset1'] * len(st1_expr) + \n",
    "                     ['dataset2'] * len(st2_expr) + \n",
    "                     ['dataset3'] * len(st3_expr))\n",
    "    \n",
    "    print(f\"Combined ST data shape: {st_expr_combined.shape}\")\n",
    "    print(f\"Combined ST coords shape: {st_coords_combined.shape}\")\n",
    "    print(f\"SC data shape: {sc_expr.shape}\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_sc = torch.tensor(sc_expr, dtype=torch.float32)\n",
    "    X_st_combined = torch.tensor(st_expr_combined, dtype=torch.float32)\n",
    "    Y_st_combined = st_coords_combined.astype(np.float32)\n",
    "    \n",
    "    return X_sc, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list\n",
    "\n",
    "# Load and process data\n",
    "scadata, stadata1, stadata2, stadata3 = load_and_process_cscc_data()\n",
    "\n",
    "# Prepare combined data for diffusion\n",
    "X_sc, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list = prepare_combined_st_for_diffusion(\n",
    "    stadata1, stadata2, stadata3, scadata\n",
    ")\n",
    "\n",
    "print(f\"Data preparation complete!\")\n",
    "print(f\"SC cells: {X_sc.shape[0]}\")\n",
    "print(f\"Combined ST spots: {X_st_combined.shape[0]}\")\n",
    "print(f\"Common genes: {len(common_genes)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_cscc_data_individual_norm():\n",
    "    \"\"\"\n",
    "    Load and process cSCC data with individual normalization per ST dataset.\n",
    "    \"\"\"\n",
    "    print(\"Loading cSCC data with individual normalization...\")\n",
    "    \n",
    "    # Load SC data\n",
    "    scadata = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP2.h5ad')\n",
    "    \n",
    "    # Load all 3 ST datasets\n",
    "    stadata1 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2.h5ad')\n",
    "    stadata2 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep2.h5ad')\n",
    "    stadata3 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep3.h5ad')\n",
    "    \n",
    "    # Normalize expression data (same for all)\n",
    "    for adata in [scadata, stadata1, stadata2, stadata3]:\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "    \n",
    "    # Create rough cell types for SC data\n",
    "    scadata.obs['rough_celltype'] = scadata.obs['level1_celltype'].astype(str)\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CLEC9A','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CD1C','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='ASDC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='PDC','rough_celltype'] = 'PDC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='MDSC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='LC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Mac','rough_celltype'] = 'Myeloid cell'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Tcell','rough_celltype'] = 'T cell'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype']=='TSK','rough_celltype'] = 'TSK'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype'].isin(['Tumor_KC_Basal', 'Tumor_KC_Diff','Tumor_KC_Cyc']),'rough_celltype'] = 'NonTSK'\n",
    "\n",
    "\n",
    "    \n",
    "    return scadata, stadata1, stadata2, stadata3\n",
    "\n",
    "def normalize_coordinates_individually(coords):\n",
    "    \"\"\"\n",
    "    Normalize coordinates to [-1, 1] range individually.\n",
    "    \"\"\"\n",
    "    coords_min = coords.min(axis=0)\n",
    "    coords_max = coords.max(axis=0)\n",
    "    coords_range = coords_max - coords_min\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    coords_range[coords_range == 0] = 1.0\n",
    "    \n",
    "    # Normalize to [-1, 1]\n",
    "    coords_normalized = 2 * (coords - coords_min) / coords_range - 1\n",
    "    \n",
    "    return coords_normalized, coords_min, coords_max, coords_range\n",
    "\n",
    "def prepare_individually_normalized_st_data(stadata1, stadata2, stadata3, scadata):\n",
    "    \"\"\"\n",
    "    Normalize each ST dataset individually, then combine.\n",
    "    \"\"\"\n",
    "    print(\"Preparing individually normalized ST data...\")\n",
    "    \n",
    "    # Get common genes\n",
    "    sc_genes = set(scadata.var_names)\n",
    "    st1_genes = set(stadata1.var_names)\n",
    "    st2_genes = set(stadata2.var_names)\n",
    "    st3_genes = set(stadata3.var_names)\n",
    "    \n",
    "    common_genes = sorted(list(sc_genes & st1_genes & st2_genes & st3_genes))\n",
    "    print(f\"Common genes across all datasets: {len(common_genes)}\")\n",
    "    \n",
    "    # Extract aligned expression data\n",
    "    sc_expr = scadata[:, common_genes].X\n",
    "    st1_expr = stadata1[:, common_genes].X\n",
    "    st2_expr = stadata2[:, common_genes].X\n",
    "    st3_expr = stadata3[:, common_genes].X\n",
    "    \n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(sc_expr, 'toarray'):\n",
    "        sc_expr = sc_expr.toarray()\n",
    "    if hasattr(st1_expr, 'toarray'):\n",
    "        st1_expr = st1_expr.toarray()\n",
    "    if hasattr(st2_expr, 'toarray'):\n",
    "        st2_expr = st2_expr.toarray()\n",
    "    if hasattr(st3_expr, 'toarray'):\n",
    "        st3_expr = st3_expr.toarray()\n",
    "    \n",
    "    # Get spatial coordinates and normalize individually\n",
    "    st1_coords = stadata1.obsm['spatial']\n",
    "    st2_coords = stadata2.obsm['spatial']\n",
    "    st3_coords = stadata3.obsm['spatial']\n",
    "    \n",
    "    print(\"Normalizing coordinates individually...\")\n",
    "    st1_coords_norm, st1_min, st1_max, st1_range = normalize_coordinates_individually(st1_coords)\n",
    "    st2_coords_norm, st2_min, st2_max, st2_range = normalize_coordinates_individually(st2_coords)\n",
    "    st3_coords_norm, st3_min, st3_max, st3_range = normalize_coordinates_individually(st3_coords)\n",
    "    \n",
    "    print(f\"ST1 coord range: [{st1_coords_norm.min():.3f}, {st1_coords_norm.max():.3f}]\")\n",
    "    print(f\"ST2 coord range: [{st2_coords_norm.min():.3f}, {st2_coords_norm.max():.3f}]\")\n",
    "    print(f\"ST3 coord range: [{st3_coords_norm.min():.3f}, {st3_coords_norm.max():.3f}]\")\n",
    "    \n",
    "    # Combine all ST data\n",
    "    st_expr_combined = np.vstack([st1_expr, st2_expr, st3_expr])\n",
    "    st_coords_combined = np.vstack([st1_coords_norm, st2_coords_norm, st3_coords_norm])\n",
    "    \n",
    "    # Create dataset metadata\n",
    "    dataset_info = {\n",
    "        'labels': (['dataset1'] * len(st1_expr) + \n",
    "                  ['dataset2'] * len(st2_expr) + \n",
    "                  ['dataset3'] * len(st3_expr)),\n",
    "        'normalization_params': {\n",
    "            'dataset1': {'min': st1_min, 'max': st1_max, 'range': st1_range},\n",
    "            'dataset2': {'min': st2_min, 'max': st2_max, 'range': st2_range},\n",
    "            'dataset3': {'min': st3_min, 'max': st3_max, 'range': st3_range}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"Combined ST data shape: {st_expr_combined.shape}\")\n",
    "    print(f\"Combined ST coords shape: {st_coords_combined.shape}\")\n",
    "    print(f\"SC data shape: {sc_expr.shape}\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_sc = torch.tensor(sc_expr, dtype=torch.float32)\n",
    "    X_st_combined = torch.tensor(st_expr_combined, dtype=torch.float32)\n",
    "    Y_st_combined = st_coords_combined.astype(np.float32)\n",
    "    \n",
    "    return X_sc, X_st_combined, Y_st_combined, dataset_info, common_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cSCC data with individual normalization...\n"
     ]
    }
   ],
   "source": [
    "scadata, stadata1, stadata2, stadata3 = load_and_process_cscc_data_individual_norm()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cSCC data...\n",
      "ST1: X[7.00, 50.00], Y[12.00, 56.00]\n",
      "ST2: X[8.00, 50.00], Y[2.00, 44.00]\n",
      "ST3: X[6.00, 48.00], Y[9.00, 52.00]\n",
      "\n",
      "==================================================\n",
      "Training AdvancedHierarchicalDiffusion model 1/3 for run1\n",
      "==================================================\n",
      "Common genes for run1: 2000\n",
      "SC data shape: (2688, 2000)\n",
      "ST data shape: (666, 2000)\n",
      "ST coords shape: (666, 2)\n",
      "D_st not provided, calculating from spatial coordinates...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 361\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mST\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: X[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoords[:,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoords[:,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Y[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoords[:,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoords[:,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# Train individual AdvancedHierarchicalDiffusion models and get averaged results\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m scadata, advanced_models \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_individual_advanced_diffusion_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstadata1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstadata2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstadata3\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdvanced diffusion training complete! Results saved in scadata.obsm[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madvanced_diffusion_coords_avg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# Visualize results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[39], line 56\u001b[0m, in \u001b[0;36mtrain_individual_advanced_diffusion_models\u001b[0;34m(scadata, stadata1, stadata2, stadata3)\u001b[0m\n\u001b[1;32m     53\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m \u001b[38;5;241m+\u001b[39m i)\n\u001b[1;32m     54\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m \u001b[38;5;241m+\u001b[39m i)\n\u001b[0;32m---> 56\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAdvancedHierarchicalDiffusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mst_gene_expr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mst_expr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mst_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mst_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43msc_gene_expr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msc_expr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcell_types_sc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrough_celltype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mD_st\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mD_induced\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_genes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcommon_genes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_embedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoord_space_diameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.00\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmmdbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_e\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0002\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_denoising_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_hierarchical_scales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madvanced_diffusion_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/sc_st/model/core_models.py:134\u001b[0m, in \u001b[0;36mAdvancedHierarchicalDiffusion.__init__\u001b[0;34m(self, st_gene_expr, st_coords, sc_gene_expr, cell_types_sc, transport_plan, D_st, D_induced, n_genes, n_embedding, coord_space_diameter, st_max_distance, sc_max_distance, sigma, alpha, mmdbatch, batch_size, device, lr_e, lr_d, n_timesteps, n_denoising_blocks, hidden_dim, num_heads, num_hierarchical_scales, dp, outf)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     st_coords_np \u001b[38;5;241m=\u001b[39m st_coords\n\u001b[0;32m--> 134\u001b[0m D_st_np, st_max_distance \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_D_st_from_coords\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspatial_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mst_coords_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD_st \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(D_st_np, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mst_max_distance \u001b[38;5;241m=\u001b[39m st_max_distance\n",
      "File \u001b[0;32m~/sc_st/model/utils.py:575\u001b[0m, in \u001b[0;36mcalculate_D_st_from_coords\u001b[0;34m(spatial_coords, X_st, k_neighbors, graph_mode, aware_st, spot_types, aware_power_st, spot_ids)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_D_st_from_coords\u001b[39m(spatial_coords, X_st\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, k_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, graph_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m, aware_st\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m    560\u001b[0m                                spot_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aware_power_st\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, spot_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    561\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''calculates the spatial distance matrix D_st for spatial transcriptomics data directly from coordinates and optional spot types\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m    args:\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03m        spatial_coords: spatial coordinates of spots (n_spots * 2)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m    returns:\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m        np.ndarray: spatial disance matrix D_st'''\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spatial_coords, \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m    576\u001b[0m         location_array \u001b[38;5;241m=\u001b[39m spatial_coords\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m spot_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def train_individual_advanced_diffusion_models(scadata, stadata1, stadata2, stadata3):\n",
    "    \"\"\"\n",
    "    Train separate AdvancedHierarchicalDiffusion models for each ST dataset and average the results.\n",
    "    MODIFIED: Run stadata1 three times to test for SC cluster rotation/sliding\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Store results from each model\n",
    "    sc_coords_results = []\n",
    "    models_all = []\n",
    "    \n",
    "    # STEP 1: Build canonical angular frame from ST slide (ONCE)\n",
    "    # st_coords_raw = stadata1.obsm['spatial']  # Use raw ST coordinates\n",
    "    # angular_frame = _build_canonical_angular_frame(st_coords_raw)\n",
    "    \n",
    "    # List of ST datasets for iteration - Use stadata1 three times\n",
    "    st_datasets = [\n",
    "        (stadata1, \"run1\"),\n",
    "        (stadata2, \"run2\"), \n",
    "        (stadata3, \"run3\")\n",
    "    ]\n",
    "    \n",
    "    for i, (stadata, run_name) in enumerate(st_datasets):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training AdvancedHierarchicalDiffusion model {i+1}/3 for {run_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Get common genes between SC and current ST dataset\n",
    "        sc_genes = set(scadata.var_names)\n",
    "        st_genes = set(stadata.var_names)\n",
    "        common_genes = sorted(list(sc_genes & st_genes))\n",
    "        \n",
    "        print(f\"Common genes for {run_name}: {len(common_genes)}\")\n",
    "        \n",
    "        # Extract expression data\n",
    "        sc_expr = scadata[:, common_genes].X\n",
    "        st_expr = stadata[:, common_genes].X\n",
    "        \n",
    "        # Convert to dense if sparse\n",
    "        if hasattr(sc_expr, 'toarray'):\n",
    "            sc_expr = sc_expr.toarray()\n",
    "        if hasattr(st_expr, 'toarray'):\n",
    "            st_expr = st_expr.toarray()\n",
    "            \n",
    "        # Get spatial coordinates\n",
    "        st_coords = stadata.obsm['spatial']\n",
    "        \n",
    "        print(f\"SC data shape: {sc_expr.shape}\")\n",
    "        print(f\"ST data shape: {st_expr.shape}\")\n",
    "        print(f\"ST coords shape: {st_coords.shape}\")\n",
    "        \n",
    "        # Initialize model with different random seed for each run\n",
    "        torch.manual_seed(42 + i)\n",
    "        np.random.seed(42 + i)\n",
    "        \n",
    "        model = AdvancedHierarchicalDiffusion(\n",
    "            st_gene_expr=st_expr,\n",
    "            st_coords=st_coords,\n",
    "            sc_gene_expr=sc_expr,\n",
    "            cell_types_sc=scadata.obs['rough_celltype'].values,\n",
    "            transport_plan=None,\n",
    "            D_st=None,\n",
    "            D_induced=None,\n",
    "            n_genes=len(common_genes),\n",
    "            n_embedding=[512, 256, 128],\n",
    "            coord_space_diameter=2.00,\n",
    "            sigma=0.75,\n",
    "            alpha=0.8,\n",
    "            mmdbatch=1000,\n",
    "            batch_size=256,\n",
    "            device=device,\n",
    "            lr_e=0.0001,\n",
    "            lr_d=0.0002,\n",
    "            n_timesteps=800,\n",
    "            n_denoising_blocks=6,\n",
    "            hidden_dim=256,\n",
    "            num_heads=8,\n",
    "            num_hierarchical_scales=3,\n",
    "            dp=0.2,\n",
    "            outf=f'advanced_diffusion_{run_name}'\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        print(f\"Training model for {run_name}...\")\n",
    "        model.train(\n",
    "            encoder_epochs=1000,\n",
    "            vae_epochs=1200,\n",
    "            diffusion_epochs=2500,\n",
    "            lambda_struct=10.0\n",
    "        )\n",
    "\n",
    "        st_coords_raw = model.st_coords_norm.cpu().numpy()  # Use normalized coords from model\n",
    "        angular_frame = _build_canonical_angular_frame(st_coords_raw)\n",
    "        \n",
    "        # Generate SC coordinates\n",
    "        print(f\"Generating SC coordinates using {run_name} model...\")\n",
    "        # sc_coords = model.generate_sc_coordinates()\n",
    "        # sc_coords = model.sample_sc_coordinates_batched(\n",
    "        #     batch_size=512,  # Even smaller batches\n",
    "        #     refine_coords=False\n",
    "        # )\n",
    "\n",
    "        # Sample with geometry guidance\n",
    "        sc_coords = model.sample_sc_coordinates_with_geometry_guidance(\n",
    "            batch_size=512,\n",
    "            guidance_scale=1.0,\n",
    "            geometry_guidance=False,\n",
    "            k_nn=5,\n",
    "            lambda_trip=0.05,\n",
    "            lambda_rep=0.08,\n",
    "            gamma=0.05\n",
    "        )\n",
    "\n",
    "        print(f\"\\n=== Generated SC Coordinates ({run_name}) ===\")\n",
    "        print(f\"  X range: [{sc_coords[:, 0].min():.3f}, {sc_coords[:, 0].max():.3f}]\")\n",
    "        print(f\"  Y range: [{sc_coords[:, 1].min():.3f}, {sc_coords[:, 1].max():.3f}]\")\n",
    "        # print(f\"  Max radius from center: {np.max(np.linalg.norm(sc_coords, axis=1)):.3f}\")\n",
    "        # print(f\"  % points outside unit circle: {(np.linalg.norm(sc_coords, axis=1) > 1).mean()*100:.1f}%\")\n",
    "\n",
    "        # Evaluate geometry preservation\n",
    "        metrics = model.evaluate_geometry_preservation(sc_coords)\n",
    "        sc_coords_results.append(sc_coords)\n",
    "        models_all.append(model)\n",
    "        \n",
    "        # STEP 2: Plot SC cells colored by angle (using ST-derived frame)\n",
    "        _plot_sc_angle_analysis(sc_coords, scadata.obs['rough_celltype'].values, \n",
    "                               angular_frame, st_coords_raw, run_name, i+1)\n",
    "    \n",
    "    # STEP 3: Comparative analysis across runs\n",
    "    _plot_comparative_sc_angle_analysis(sc_coords_results, scadata.obs['rough_celltype'].values,\n",
    "                                       angular_frame, st_coords_raw)\n",
    "    \n",
    "    # Compute averaged SC coordinates\n",
    "    sc_coords_results_np = [coords.cpu().numpy() for coords in sc_coords_results]  # Convert to numpy\n",
    "    sc_coords_avg = np.mean(sc_coords_results_np, axis=0)\n",
    "    sc_coords_std = np.std(sc_coords_results_np, axis=0)\n",
    "\n",
    "    # Store results in scadata\n",
    "    scadata.obsm['advanced_diffusion_coords_avg'] = sc_coords_avg\n",
    "    scadata.obsm['advanced_diffusion_coords_std'] = sc_coords_std\n",
    "\n",
    "    # Store individual results\n",
    "    for i, coords in enumerate(sc_coords_results_np):  # Use numpy arrays\n",
    "        scadata.obsm[f'advanced_diffusion_coords_rep{i+1}'] = coords\n",
    "\n",
    "    print(f\"\\nTraining complete. Results stored in scadata.obsm\")\n",
    "    return scadata, models_all\n",
    "\n",
    "def _build_canonical_angular_frame(st_coords):\n",
    "    \"\"\"Build canonical angular frame from ST coordinates (dataset-specific, run-independent)\"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Compute centroid\n",
    "    centroid = st_coords.mean(axis=0)\n",
    "    \n",
    "    # Find farthest spot from centroid (deterministic 0° direction)\n",
    "    distances = np.linalg.norm(st_coords - centroid, axis=1)\n",
    "    farthest_idx = np.argmax(distances)\n",
    "    a0 = st_coords[farthest_idx] - centroid  # 0° direction vector\n",
    "    \n",
    "    def angle_fn(x):\n",
    "        \"\"\"Compute angle from canonical frame\"\"\"\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        \n",
    "        v = x - centroid\n",
    "        cross = a0[0] * v[:, 1] - a0[1] * v[:, 0]  # z-component of 2D cross\n",
    "        dot = a0[0] * v[:, 0] + a0[1] * v[:, 1]\n",
    "        angles = np.arctan2(cross, dot)\n",
    "        angles = np.where(angles < 0, angles + 2*np.pi, angles)  # Map to [0, 2π)\n",
    "        return angles\n",
    "    \n",
    "    return {\n",
    "        'centroid': centroid,\n",
    "        'zero_direction': a0,\n",
    "        'farthest_idx': farthest_idx,\n",
    "        'angle_fn': angle_fn\n",
    "    }\n",
    "\n",
    "def _plot_sc_angle_analysis(sc_coords, cell_types, angular_frame, st_coords_bg, run_name, run_num):\n",
    "    \"\"\"Plot SC cells colored by angle from ST-derived frame\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Compute angles for SC cells using ST-derived frame\n",
    "    sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "    sc_angles_degrees = np.degrees(sc_angles)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot 1: SC cells colored by angle (with ST outline in background)\n",
    "    ax1.scatter(st_coords_bg[:, 0], st_coords_bg[:, 1], \n",
    "               c='lightgray', s=10, alpha=0.3, label='ST outline')\n",
    "    \n",
    "    scatter = ax1.scatter(sc_coords[:, 0], sc_coords[:, 1], \n",
    "                         c=sc_angles_degrees, cmap='hsv', s=30, alpha=0.8)\n",
    "    \n",
    "    # Mark centroid and 0° direction\n",
    "    centroid = angular_frame['centroid']\n",
    "    zero_dir = angular_frame['zero_direction']\n",
    "    ax1.scatter(centroid[0], centroid[1], c='black', s=100, marker='x', linewidth=3)\n",
    "    ax1.arrow(centroid[0], centroid[1], zero_dir[0]*0.3, zero_dir[1]*0.3, \n",
    "              head_width=0.05, head_length=0.05, fc='red', ec='red', linewidth=2)\n",
    "    \n",
    "    ax1.set_title(f'{run_name}: SC Cells Colored by Angle θ')\n",
    "    ax1.set_xlabel('X coordinate')\n",
    "    ax1.set_ylabel('Y coordinate')\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax1)\n",
    "    cbar.set_label('Angle (degrees)')\n",
    "    \n",
    "    # Plot 2: Per-cell-type angle distribution\n",
    "    unique_types = np.unique(cell_types)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_types)))\n",
    "    \n",
    "    for i, cell_type in enumerate(unique_types):\n",
    "        mask = cell_types == cell_type\n",
    "        if np.sum(mask) > 0:\n",
    "            angles_subset = sc_angles_degrees[mask]\n",
    "            ax2.hist(angles_subset, bins=36, alpha=0.6, label=cell_type, \n",
    "                    color=colors[i], density=True)\n",
    "    \n",
    "    ax2.set_title(f'{run_name}: Angle Distribution by Cell Type')\n",
    "    ax2.set_xlabel('Angle (degrees)')\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.set_xlim(0, 360)\n",
    "    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'sc_angle_analysis_{run_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print circular statistics per cell type\n",
    "    print(f\"\\n{run_name} - Circular statistics per cell type:\")\n",
    "    for cell_type in unique_types:\n",
    "        mask = cell_types == cell_type\n",
    "        if np.sum(mask) > 5:  # Only if enough cells\n",
    "            angles_rad = sc_angles[mask]\n",
    "            # Circular mean\n",
    "            mean_cos = np.mean(np.cos(angles_rad))\n",
    "            mean_sin = np.mean(np.sin(angles_rad))\n",
    "            circular_mean = np.arctan2(mean_sin, mean_cos)\n",
    "            if circular_mean < 0:\n",
    "                circular_mean += 2*np.pi\n",
    "            \n",
    "            print(f\"  {cell_type}: mean={np.degrees(circular_mean):.1f}°, n={np.sum(mask)}\")\n",
    "\n",
    "def _plot_comparative_sc_angle_analysis(sc_coords_list, cell_types, angular_frame, st_coords_bg):\n",
    "    \"\"\"Plot comparative SC angle analysis across all runs\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    n_runs = len(sc_coords_list)\n",
    "    unique_types = np.unique(cell_types)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_runs, figsize=(5*n_runs, 10))\n",
    "    if n_runs == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    # Top row: SC scatter plots per run\n",
    "    for i, sc_coords in enumerate(sc_coords_list):\n",
    "        ax = axes[0, i]\n",
    "        \n",
    "        # ST background\n",
    "        ax.scatter(st_coords_bg[:, 0], st_coords_bg[:, 1], \n",
    "                  c='lightgray', s=5, alpha=0.3)\n",
    "        \n",
    "        # SC cells colored by angle\n",
    "        sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "        sc_angles_degrees = np.degrees(sc_angles)\n",
    "        \n",
    "        scatter = ax.scatter(sc_coords[:, 0], sc_coords[:, 1], \n",
    "                           c=sc_angles_degrees, cmap='hsv', s=20, alpha=0.8)\n",
    "        \n",
    "        ax.set_title(f'Run {i+1}: SC Cells by Angle')\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        if i == n_runs-1:  # Add colorbar to last plot\n",
    "            cbar = plt.colorbar(scatter, ax=ax)\n",
    "            cbar.set_label('Angle (degrees)')\n",
    "    \n",
    "    # Bottom row: Cell type angle distributions per run  \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_types)))\n",
    "    \n",
    "    for i, sc_coords in enumerate(sc_coords_list):\n",
    "        ax = axes[1, i]\n",
    "        \n",
    "        sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "        sc_angles_degrees = np.degrees(sc_angles)\n",
    "        \n",
    "        for j, cell_type in enumerate(unique_types):\n",
    "            mask = cell_types == cell_type\n",
    "            if np.sum(mask) > 5:\n",
    "                angles_subset = sc_angles_degrees[mask]\n",
    "                ax.hist(angles_subset, bins=36, alpha=0.6, \n",
    "                       label=cell_type if i == 0 else \"\", \n",
    "                       color=colors[j], density=True)\n",
    "        \n",
    "        ax.set_title(f'Run {i+1}: Cell Type Angles')\n",
    "        ax.set_xlabel('Angle (degrees)')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_xlim(0, 360)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comparative_sc_angle_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Check for sector sliding\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"SECTOR SLIDING ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for cell_type in unique_types:\n",
    "        mask = cell_types == cell_type\n",
    "        if np.sum(mask) > 10:  # Only analyze cell types with enough cells\n",
    "            circular_means = []\n",
    "            \n",
    "            for i, sc_coords in enumerate(sc_coords_list):\n",
    "                sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "                angles_subset = sc_angles[mask]\n",
    "                \n",
    "                # Circular mean\n",
    "                mean_cos = np.mean(np.cos(angles_subset))\n",
    "                mean_sin = np.mean(np.sin(angles_subset))\n",
    "                circular_mean = np.arctan2(mean_sin, mean_cos)\n",
    "                if circular_mean < 0:\n",
    "                    circular_mean += 2*np.pi\n",
    "                \n",
    "                circular_means.append(np.degrees(circular_mean))\n",
    "            \n",
    "            # Check for large differences between runs\n",
    "            max_diff = max(circular_means) - min(circular_means)\n",
    "            if max_diff > 180:  # Handle wraparound\n",
    "                max_diff = 360 - max_diff\n",
    "            \n",
    "            print(f\"{cell_type}:\")\n",
    "            print(f\"  Run means: {[f'{m:.1f}°' for m in circular_means]}\")\n",
    "            print(f\"  Max difference: {max_diff:.1f}°\")\n",
    "            \n",
    "            if max_diff > 30:  # Significant sliding\n",
    "                print(f\"  ⚠️  SECTOR SLIDING DETECTED!\")\n",
    "            else:\n",
    "                print(f\"  ✅ Consistent placement\")\n",
    "\n",
    "# Load and process data\n",
    "scadata, stadata1, stadata2, stadata3 = load_and_process_cscc_data()\n",
    "\n",
    "# ADD THESE LINES:\n",
    "for i, stdata in enumerate([stadata1, stadata2, stadata3], 1):\n",
    "    coords = stdata.obsm['spatial']\n",
    "    print(f\"ST{i}: X[{coords[:, 0].min():.2f}, {coords[:, 0].max():.2f}], Y[{coords[:, 1].min():.2f}, {coords[:, 1].max():.2f}]\")\n",
    "\n",
    "\n",
    "# Train individual AdvancedHierarchicalDiffusion models and get averaged results\n",
    "scadata, advanced_models = train_individual_advanced_diffusion_models(\n",
    "    scadata, stadata1, stadata2, stadata3\n",
    ")\n",
    "\n",
    "print(\"Advanced diffusion training complete! Results saved in scadata.obsm['advanced_diffusion_coords_avg']\")\n",
    "\n",
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "my_tab20 = sns.color_palette(\"tab20\", n_colors=20).as_hex()\n",
    "\n",
    "# Plot 1: Averaged coordinates\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc.pl.embedding(scadata, basis='advanced_diffusion_coords_avg', color='rough_celltype',\n",
    "               size=85, title='SC Advanced Diffusion Coords (Averaged)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Individual model results\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sc.pl.embedding(scadata, basis=f'advanced_diffusion_coords_rep{i+1}', color='rough_celltype',\n",
    "                   size=85, title=f'SC Coordinates (Advanced Model {i+1})',\n",
    "                   palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehtesamenv_gains",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
