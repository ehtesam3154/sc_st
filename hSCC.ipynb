{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Cell 2: force single‐threaded BLAS\n",
    "os.environ[\"OMP_NUM_THREADS\"]       = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: actually cap BLAS to 1 thread\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "# 'blas' covers OpenBLAS, MKL, etc.\n",
    "threadpool_limits(limits=1, user_api='blas')\n",
    "\n",
    "# now import as usual, no more warning\n",
    "import numpy as np\n",
    "import scipy\n",
    "# … any other packages that use OpenBLAS …\n",
    "from model.core_models_v2 import AdvancedHierarchicalDiffusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "from sklearn.preprocessing import normalize\n",
    "import ot \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# patient 2 data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_cscc_data():\n",
    "    \"\"\"\n",
    "    Load and process the cSCC dataset with multiple ST replicates.\n",
    "    \"\"\"\n",
    "    print(\"Loading cSCC data...\")\n",
    "    \n",
    "    # Load SC data\n",
    "    scadata = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP2.h5ad')\n",
    "    \n",
    "    # Load all 3 ST datasets\n",
    "    stadata1 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2.h5ad')\n",
    "    stadata2 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep2.h5ad')\n",
    "    stadata3 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep3.h5ad')\n",
    "    \n",
    "    # Normalize and log transform\n",
    "    for adata in [scadata, stadata1, stadata2, stadata3]:\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "    \n",
    "    # Create rough cell types for SC data\n",
    "    scadata.obs['rough_celltype'] = scadata.obs['level1_celltype'].astype(str)\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CLEC9A','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CD1C','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='ASDC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='PDC','rough_celltype'] = 'PDC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='MDSC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='LC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Mac','rough_celltype'] = 'Myeloid cell'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Tcell','rough_celltype'] = 'T cell'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype']=='TSK','rough_celltype'] = 'TSK'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype'].isin(['Tumor_KC_Basal', 'Tumor_KC_Diff','Tumor_KC_Cyc']),'rough_celltype'] = 'NonTSK'\n",
    "    \n",
    "    return scadata, stadata1, stadata2, stadata3\n",
    "\n",
    "def prepare_combined_st_for_diffusion(stadata1, stadata2, stadata3, scadata):\n",
    "    \"\"\"\n",
    "    Combine all ST datasets for diffusion training while maintaining gene alignment.\n",
    "    Key innovation: Use ALL ST data points for better training.\n",
    "    \"\"\"\n",
    "    print(\"Preparing combined ST data for diffusion training...\")\n",
    "    \n",
    "    # Get common genes between SC and all ST datasets\n",
    "    sc_genes = set(scadata.var_names)\n",
    "    st1_genes = set(stadata1.var_names)\n",
    "    st2_genes = set(stadata2.var_names)\n",
    "    st3_genes = set(stadata3.var_names)\n",
    "    \n",
    "    common_genes = sorted(list(sc_genes & st1_genes & st2_genes & st3_genes))\n",
    "    print(f\"Common genes across all datasets: {len(common_genes)}\")\n",
    "    \n",
    "    # Extract aligned expression data\n",
    "    sc_expr = scadata[:, common_genes].X\n",
    "    st1_expr = stadata1[:, common_genes].X\n",
    "    st2_expr = stadata2[:, common_genes].X\n",
    "    st3_expr = stadata3[:, common_genes].X\n",
    "    \n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(sc_expr, 'toarray'):\n",
    "        sc_expr = sc_expr.toarray()\n",
    "    if hasattr(st1_expr, 'toarray'):\n",
    "        st1_expr = st1_expr.toarray()\n",
    "    if hasattr(st2_expr, 'toarray'):\n",
    "        st2_expr = st2_expr.toarray()\n",
    "    if hasattr(st3_expr, 'toarray'):\n",
    "        st3_expr = st3_expr.toarray()\n",
    "    \n",
    "    # Get spatial coordinates\n",
    "    st1_coords = stadata1.obsm['spatial']\n",
    "    st2_coords = stadata2.obsm['spatial']\n",
    "    st3_coords = stadata3.obsm['spatial']\n",
    "\n",
    "    # Store separate coordinate lists for block-diagonal graph\n",
    "    st_coords_list = [st1_coords, st2_coords, st3_coords]\n",
    "    \n",
    "    # Combine all ST data\n",
    "    st_expr_combined = np.vstack([st1_expr, st2_expr, st3_expr])\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    st_expr_combined = scaler.fit_transform(st_expr_combined)\n",
    "\n",
    "    st_coords_combined = np.vstack([st1_coords, st2_coords, st3_coords])\n",
    "\n",
    "    sc_expr = scaler.fit_transform(sc_expr)\n",
    "\n",
    "    \n",
    "    # Create dataset labels for tracking\n",
    "    dataset_labels = (['dataset1'] * len(st1_expr) + \n",
    "                     ['dataset2'] * len(st2_expr) + \n",
    "                     ['dataset3'] * len(st3_expr))\n",
    "    \n",
    "    print(f\"Combined ST data shape: {st_expr_combined.shape}\")\n",
    "    print(f\"Combined ST coords shape: {st_coords_combined.shape}\")\n",
    "    print(f\"SC data shape: {sc_expr.shape}\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_sc = torch.tensor(sc_expr, dtype=torch.float32)\n",
    "    X_st_combined = torch.tensor(st_expr_combined, dtype=torch.float32)\n",
    "    Y_st_combined = st_coords_combined.astype(np.float32)\n",
    "    \n",
    "    return X_sc, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list\n",
    "\n",
    "# Load and process data\n",
    "scadata, stadata1, stadata2, stadata3 = load_and_process_cscc_data()\n",
    "\n",
    "# Prepare combined data for diffusion\n",
    "X_sc, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list = prepare_combined_st_for_diffusion(\n",
    "    stadata1, stadata2, stadata3, scadata\n",
    ")\n",
    "\n",
    "print(f\"Data preparation complete!\")\n",
    "print(f\"SC cells: {X_sc.shape[0]}\")\n",
    "print(f\"Combined ST spots: {X_st_combined.shape[0]}\")\n",
    "print(f\"Common genes: {len(common_genes)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_cscc_data_individual_norm():\n",
    "    \"\"\"\n",
    "    Load and process cSCC data with individual normalization per ST dataset.\n",
    "    \"\"\"\n",
    "    print(\"Loading cSCC data with individual normalization...\")\n",
    "    \n",
    "    # Load SC data\n",
    "    scadata = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP2.h5ad')\n",
    "    \n",
    "    # Load all 3 ST datasets\n",
    "    stadata1 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2.h5ad')\n",
    "    stadata2 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep2.h5ad')\n",
    "    stadata3 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep3.h5ad')\n",
    "    \n",
    "    # Normalize expression data (same for all)\n",
    "    for adata in [scadata, stadata1, stadata2, stadata3]:\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "    \n",
    "    # Create rough cell types for SC data\n",
    "    scadata.obs['rough_celltype'] = scadata.obs['level1_celltype'].astype(str)\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CLEC9A','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CD1C','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='ASDC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='PDC','rough_celltype'] = 'PDC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='MDSC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='LC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Mac','rough_celltype'] = 'Myeloid cell'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Tcell','rough_celltype'] = 'T cell'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype']=='TSK','rough_celltype'] = 'TSK'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype'].isin(['Tumor_KC_Basal', 'Tumor_KC_Diff','Tumor_KC_Cyc']),'rough_celltype'] = 'NonTSK'\n",
    "    \n",
    "    return scadata, stadata1, stadata2, stadata3\n",
    "\n",
    "def normalize_coordinates_individually(coords):\n",
    "    \"\"\"\n",
    "    Normalize coordinates to [-1, 1] range individually.\n",
    "    \"\"\"\n",
    "    coords_min = coords.min(axis=0)\n",
    "    coords_max = coords.max(axis=0)\n",
    "    coords_range = coords_max - coords_min\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    coords_range[coords_range == 0] = 1.0\n",
    "    \n",
    "    # Normalize to [-1, 1]\n",
    "    coords_normalized = 2 * (coords - coords_min) / coords_range - 1\n",
    "    \n",
    "    return coords_normalized, coords_min, coords_max, coords_range\n",
    "\n",
    "def prepare_individually_normalized_st_data(stadata1, stadata2, stadata3, scadata):\n",
    "    \"\"\"\n",
    "    Normalize each ST dataset individually, then combine.\n",
    "    \"\"\"\n",
    "    print(\"Preparing individually normalized ST data...\")\n",
    "    \n",
    "    # Get common genes\n",
    "    sc_genes = set(scadata.var_names)\n",
    "    st1_genes = set(stadata1.var_names)\n",
    "    st2_genes = set(stadata2.var_names)\n",
    "    st3_genes = set(stadata3.var_names)\n",
    "    \n",
    "    common_genes = sorted(list(sc_genes & st1_genes & st2_genes & st3_genes))\n",
    "    print(f\"Common genes across all datasets: {len(common_genes)}\")\n",
    "    \n",
    "    # Extract aligned expression data\n",
    "    sc_expr = scadata[:, common_genes].X\n",
    "    st1_expr = stadata1[:, common_genes].X\n",
    "    st2_expr = stadata2[:, common_genes].X\n",
    "    st3_expr = stadata3[:, common_genes].X\n",
    "    \n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(sc_expr, 'toarray'):\n",
    "        sc_expr = sc_expr.toarray()\n",
    "    if hasattr(st1_expr, 'toarray'):\n",
    "        st1_expr = st1_expr.toarray()\n",
    "    if hasattr(st2_expr, 'toarray'):\n",
    "        st2_expr = st2_expr.toarray()\n",
    "    if hasattr(st3_expr, 'toarray'):\n",
    "        st3_expr = st3_expr.toarray()\n",
    "    \n",
    "    # Get spatial coordinates and normalize individually\n",
    "    st1_coords = stadata1.obsm['spatial']\n",
    "    st2_coords = stadata2.obsm['spatial']\n",
    "    st3_coords = stadata3.obsm['spatial']\n",
    "    \n",
    "    print(\"Normalizing coordinates individually...\")\n",
    "    st1_coords_norm, st1_min, st1_max, st1_range = normalize_coordinates_individually(st1_coords)\n",
    "    st2_coords_norm, st2_min, st2_max, st2_range = normalize_coordinates_individually(st2_coords)\n",
    "    st3_coords_norm, st3_min, st3_max, st3_range = normalize_coordinates_individually(st3_coords)\n",
    "    \n",
    "    print(f\"ST1 coord range: [{st1_coords_norm.min():.3f}, {st1_coords_norm.max():.3f}]\")\n",
    "    print(f\"ST2 coord range: [{st2_coords_norm.min():.3f}, {st2_coords_norm.max():.3f}]\")\n",
    "    print(f\"ST3 coord range: [{st3_coords_norm.min():.3f}, {st3_coords_norm.max():.3f}]\")\n",
    "    \n",
    "    # Combine all ST data\n",
    "    st_expr_combined = np.vstack([st1_expr, st2_expr, st3_expr])\n",
    "    st_coords_combined = np.vstack([st1_coords_norm, st2_coords_norm, st3_coords_norm])\n",
    "    \n",
    "    # Create dataset metadata\n",
    "    dataset_info = {\n",
    "        'labels': (['dataset1'] * len(st1_expr) + \n",
    "                  ['dataset2'] * len(st2_expr) + \n",
    "                  ['dataset3'] * len(st3_expr)),\n",
    "        'normalization_params': {\n",
    "            'dataset1': {'min': st1_min, 'max': st1_max, 'range': st1_range},\n",
    "            'dataset2': {'min': st2_min, 'max': st2_max, 'range': st2_range},\n",
    "            'dataset3': {'min': st3_min, 'max': st3_max, 'range': st3_range}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"Combined ST data shape: {st_expr_combined.shape}\")\n",
    "    print(f\"Combined ST coords shape: {st_coords_combined.shape}\")\n",
    "    print(f\"SC data shape: {sc_expr.shape}\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_sc = torch.tensor(sc_expr, dtype=torch.float32)\n",
    "    X_st_combined = torch.tensor(st_expr_combined, dtype=torch.float32)\n",
    "    Y_st_combined = st_coords_combined.astype(np.float32)\n",
    "    \n",
    "    return X_sc, X_st_combined, Y_st_combined, dataset_info, common_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scadata, stadata1, stadata2, stadata3 = load_and_process_cscc_data_individual_norm()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_individual_advanced_diffusion_models(scadata, stadata1, stadata2, stadata3):\n",
    "    \"\"\"\n",
    "    Train separate AdvancedHierarchicalDiffusion models for each ST dataset and average the results.\n",
    "    MODIFIED: Run stadata1 three times to test for SC cluster rotation/sliding\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Store results from each model\n",
    "    sc_coords_results = []\n",
    "    models_all = []\n",
    "    \n",
    "    # STEP 1: Build canonical angular frame from ST slide (ONCE)\n",
    "    # st_coords_raw = stadata1.obsm['spatial']  # Use raw ST coordinates\n",
    "    # angular_frame = _build_canonical_angular_frame(st_coords_raw)\n",
    "    \n",
    "    # List of ST datasets for iteration - Use stadata1 three times\n",
    "    st_datasets = [\n",
    "        (stadata1, \"run1\"),\n",
    "        (stadata2, \"run2\"), \n",
    "        (stadata3, \"run3\")\n",
    "    ]\n",
    "    \n",
    "    for i, (stadata, run_name) in enumerate(st_datasets):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training AdvancedHierarchicalDiffusion model {i+1}/3 for {run_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Get common genes between SC and current ST dataset\n",
    "        sc_genes = set(scadata.var_names)\n",
    "        st_genes = set(stadata.var_names)\n",
    "        common_genes = sorted(list(sc_genes & st_genes))\n",
    "        \n",
    "        print(f\"Common genes for {run_name}: {len(common_genes)}\")\n",
    "        \n",
    "        # Extract expression data\n",
    "        sc_expr = scadata[:, common_genes].X\n",
    "        st_expr = stadata[:, common_genes].X\n",
    "        \n",
    "        # Convert to dense if sparse\n",
    "        if hasattr(sc_expr, 'toarray'):\n",
    "            sc_expr = sc_expr.toarray()\n",
    "        if hasattr(st_expr, 'toarray'):\n",
    "            st_expr = st_expr.toarray()\n",
    "            \n",
    "        # Get spatial coordinates\n",
    "        st_coords = stadata.obsm['spatial']\n",
    "        \n",
    "        print(f\"SC data shape: {sc_expr.shape}\")\n",
    "        print(f\"ST data shape: {st_expr.shape}\")\n",
    "        print(f\"ST coords shape: {st_coords.shape}\")\n",
    "        \n",
    "        # Initialize model with different random seed for each run\n",
    "        torch.manual_seed(42 + i)\n",
    "        np.random.seed(42 + i)\n",
    "\n",
    "        # dp = 1 - scadata.obs['n_genes_by_counts'].median() / stadata.obs['n_genes_by_counts'].median()\n",
    "\n",
    "        \n",
    "        model = AdvancedHierarchicalDiffusion(\n",
    "            st_gene_expr=st_expr,\n",
    "            st_coords=st_coords,\n",
    "            sc_gene_expr=sc_expr,\n",
    "            cell_types_sc=scadata.obs['rough_celltype'].values,\n",
    "            transport_plan=None,\n",
    "            D_st=None,\n",
    "            D_induced=None,\n",
    "            n_genes=len(common_genes),\n",
    "            n_embedding=[512, 256, 128],\n",
    "            coord_space_diameter=2.00,\n",
    "            sigma=0.75,\n",
    "            alpha=0.8,\n",
    "            mmdbatch=1000,\n",
    "            batch_size=256,\n",
    "            device=device,\n",
    "            lr_e=0.002,\n",
    "            lr_d=0.0002,\n",
    "            n_timesteps=300,\n",
    "            n_denoising_blocks=4,\n",
    "            hidden_dim=256,\n",
    "            num_heads=6,\n",
    "            num_hierarchical_scales=3,\n",
    "            dp=0.2,\n",
    "            outf=f'advanced_diffusion_{run_name}'\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        print(f\"Training model for {run_name}...\")\n",
    "        model.train(\n",
    "            encoder_epochs=1201,\n",
    "            vae_epochs=3001,\n",
    "            diffusion_epochs=5001, p_drop_max=0.2\n",
    "        )\n",
    "\n",
    "        # st_coords_raw = model.st_coords_norm.cpu().numpy()  # Use normalized coords from model\n",
    "        st_coords_raw = model.st_coords_norm.cpu().numpy()  # Use normalized coords from model\n",
    "        angular_frame = _build_canonical_angular_frame(st_coords_raw)\n",
    "        \n",
    "        # Generate SC coordinates\n",
    "        print(f\"Generating SC coordinates using {run_name} model...\")\n",
    "\n",
    "        sc_coords = model.sample_sc_coordinates(\n",
    "            batch_size=512,\n",
    "            guidance_scale=8.0,\n",
    "            return_normalized= True\n",
    "        )\n",
    "\n",
    "        print(f\"\\n=== Generated SC Coordinates ({run_name}) ===\")\n",
    "        print(f\"  X range: [{sc_coords[:, 0].min():.3f}, {sc_coords[:, 0].max():.3f}]\")\n",
    "        print(f\"  Y range: [{sc_coords[:, 1].min():.3f}, {sc_coords[:, 1].max():.3f}]\")\n",
    "        # print(f\"  Max radius from center: {np.max(np.linalg.norm(sc_coords, axis=1)):.3f}\")\n",
    "        # print(f\"  % points outside unit circle: {(np.linalg.norm(sc_coords, axis=1) > 1).mean()*100:.1f}%\")\n",
    "\n",
    "        # Evaluate geometry preservation\n",
    "        # metrics = model.evaluate_geometry_preservation(sc_coords)\n",
    "        sc_coords_results.append(sc_coords)\n",
    "        models_all.append(model)\n",
    "        \n",
    "        # STEP 2: Plot SC cells colored by angle (using ST-derived frame)\n",
    "        _plot_sc_angle_analysis(sc_coords, scadata.obs['rough_celltype'].values, \n",
    "                               angular_frame, st_coords_raw, run_name, i+1)\n",
    "    \n",
    "    # STEP 3: Comparative analysis across runs\n",
    "    _plot_comparative_sc_angle_analysis(sc_coords_results, scadata.obs['rough_celltype'].values,\n",
    "                                       angular_frame, st_coords_raw)\n",
    "    \n",
    "    # Compute averaged SC coordinates\n",
    "    sc_coords_results_np = [\n",
    "        coords.cpu().numpy() if hasattr(coords, 'cpu') else coords \n",
    "        for coords in sc_coords_results\n",
    "    ]\n",
    "\n",
    "    sc_coords_avg = np.mean(sc_coords_results_np, axis=0)\n",
    "    sc_coords_std = np.std(sc_coords_results_np, axis=0)\n",
    "\n",
    "    # Store results in scadata\n",
    "    scadata.obsm['advanced_diffusion_coords_avg'] = sc_coords_avg\n",
    "    scadata.obsm['advanced_diffusion_coords_std'] = sc_coords_std\n",
    "\n",
    "    # Store individual results\n",
    "    for i, coords in enumerate(sc_coords_results_np):  # Use numpy arrays\n",
    "        scadata.obsm[f'advanced_diffusion_coords_rep{i+1}'] = coords\n",
    "\n",
    "    print(f\"\\nTraining complete. Results stored in scadata.obsm\")\n",
    "    return scadata, models_all\n",
    "\n",
    "def _build_canonical_angular_frame(st_coords):\n",
    "    \"\"\"Build canonical angular frame from ST coordinates (dataset-specific, run-independent)\"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Compute centroid\n",
    "    centroid = st_coords.mean(axis=0)\n",
    "    \n",
    "    # Find farthest spot from centroid (deterministic 0° direction)\n",
    "    distances = np.linalg.norm(st_coords - centroid, axis=1)\n",
    "    farthest_idx = np.argmax(distances)\n",
    "    a0 = st_coords[farthest_idx] - centroid  # 0° direction vector\n",
    "    \n",
    "    def angle_fn(x):\n",
    "        \"\"\"Compute angle from canonical frame\"\"\"\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        \n",
    "        v = x - centroid\n",
    "        cross = a0[0] * v[:, 1] - a0[1] * v[:, 0]  # z-component of 2D cross\n",
    "        dot = a0[0] * v[:, 0] + a0[1] * v[:, 1]\n",
    "        angles = np.arctan2(cross, dot)\n",
    "        angles = np.where(angles < 0, angles + 2*np.pi, angles)  # Map to [0, 2π)\n",
    "        return angles\n",
    "    \n",
    "    return {\n",
    "        'centroid': centroid,\n",
    "        'zero_direction': a0,\n",
    "        'farthest_idx': farthest_idx,\n",
    "        'angle_fn': angle_fn\n",
    "    }\n",
    "\n",
    "def _plot_sc_angle_analysis(sc_coords, cell_types, angular_frame, st_coords_bg, run_name, run_num):\n",
    "    \"\"\"Plot SC cells colored by angle from ST-derived frame\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Compute angles for SC cells using ST-derived frame\n",
    "    sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "    sc_angles_degrees = np.degrees(sc_angles)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot 1: SC cells colored by angle (with ST outline in background)\n",
    "    ax1.scatter(st_coords_bg[:, 0], st_coords_bg[:, 1], \n",
    "               c='black', s=100, alpha=0.8, label='ST outline')\n",
    "    \n",
    "    scatter = ax1.scatter(sc_coords[:, 0], sc_coords[:, 1], \n",
    "                         c=sc_angles_degrees, cmap='hsv', s=30, alpha=0.8)\n",
    "    \n",
    "    # Mark centroid and 0° direction\n",
    "    centroid = angular_frame['centroid']\n",
    "    zero_dir = angular_frame['zero_direction']\n",
    "    ax1.scatter(centroid[0], centroid[1], c='black', s=100, marker='x', linewidth=3)\n",
    "    ax1.arrow(centroid[0], centroid[1], zero_dir[0]*0.3, zero_dir[1]*0.3, \n",
    "              head_width=0.05, head_length=0.05, fc='red', ec='red', linewidth=2)\n",
    "    \n",
    "    ax1.set_title(f'{run_name}: SC Cells Colored by Angle θ')\n",
    "    ax1.set_xlabel('X coordinate')\n",
    "    ax1.set_ylabel('Y coordinate')\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax1)\n",
    "    cbar.set_label('Angle (degrees)')\n",
    "    \n",
    "    # Plot 2: Per-cell-type angle distribution\n",
    "    unique_types = np.unique(cell_types)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_types)))\n",
    "    \n",
    "    for i, cell_type in enumerate(unique_types):\n",
    "        mask = cell_types == cell_type\n",
    "        if np.sum(mask) > 0:\n",
    "            angles_subset = sc_angles_degrees[mask]\n",
    "            ax2.hist(angles_subset, bins=36, alpha=0.6, label=cell_type, \n",
    "                    color=colors[i], density=True)\n",
    "    \n",
    "    ax2.set_title(f'{run_name}: Angle Distribution by Cell Type')\n",
    "    ax2.set_xlabel('Angle (degrees)')\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.set_xlim(0, 360)\n",
    "    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'sc_angle_analysis_{run_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print circular statistics per cell type\n",
    "    print(f\"\\n{run_name} - Circular statistics per cell type:\")\n",
    "    for cell_type in unique_types:\n",
    "        mask = cell_types == cell_type\n",
    "        if np.sum(mask) > 5:  # Only if enough cells\n",
    "            angles_rad = sc_angles[mask]\n",
    "            # Circular mean\n",
    "            mean_cos = np.mean(np.cos(angles_rad))\n",
    "            mean_sin = np.mean(np.sin(angles_rad))\n",
    "            circular_mean = np.arctan2(mean_sin, mean_cos)\n",
    "            if circular_mean < 0:\n",
    "                circular_mean += 2*np.pi\n",
    "            \n",
    "            print(f\"  {cell_type}: mean={np.degrees(circular_mean):.1f}°, n={np.sum(mask)}\")\n",
    "\n",
    "def _plot_comparative_sc_angle_analysis(sc_coords_list, cell_types, angular_frame, st_coords_bg):\n",
    "    \"\"\"Plot comparative SC angle analysis across all runs\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    n_runs = len(sc_coords_list)\n",
    "    unique_types = np.unique(cell_types)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_runs, figsize=(5*n_runs, 10))\n",
    "    if n_runs == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    # Top row: SC scatter plots per run\n",
    "    for i, sc_coords in enumerate(sc_coords_list):\n",
    "        ax = axes[0, i]\n",
    "        \n",
    "        # ST background\n",
    "        ax.scatter(st_coords_bg[:, 0], st_coords_bg[:, 1], \n",
    "                  c='black', s=20, alpha=0.8)\n",
    "        \n",
    "        # SC cells colored by angle\n",
    "        sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "        sc_angles_degrees = np.degrees(sc_angles)\n",
    "        \n",
    "        scatter = ax.scatter(sc_coords[:, 0], sc_coords[:, 1], \n",
    "                           c=sc_angles_degrees, cmap='hsv', s=20, alpha=0.1)\n",
    "        \n",
    "        ax.set_title(f'Run {i+1}: SC Cells by Angle')\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        if i == n_runs-1:  # Add colorbar to last plot\n",
    "            cbar = plt.colorbar(scatter, ax=ax)\n",
    "            cbar.set_label('Angle (degrees)')\n",
    "    \n",
    "    # Bottom row: Cell type angle distributions per run  \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_types)))\n",
    "    \n",
    "    for i, sc_coords in enumerate(sc_coords_list):\n",
    "        ax = axes[1, i]\n",
    "        \n",
    "        sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "        sc_angles_degrees = np.degrees(sc_angles)\n",
    "        \n",
    "        for j, cell_type in enumerate(unique_types):\n",
    "            mask = cell_types == cell_type\n",
    "            if np.sum(mask) > 5:\n",
    "                angles_subset = sc_angles_degrees[mask]\n",
    "                ax.hist(angles_subset, bins=36, alpha=0.6, \n",
    "                       label=cell_type if i == 0 else \"\", \n",
    "                       color=colors[j], density=True)\n",
    "        \n",
    "        ax.set_title(f'Run {i+1}: Cell Type Angles')\n",
    "        ax.set_xlabel('Angle (degrees)')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_xlim(0, 360)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comparative_sc_angle_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Check for sector sliding\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"SECTOR SLIDING ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for cell_type in unique_types:\n",
    "        mask = cell_types == cell_type\n",
    "        if np.sum(mask) > 10:  # Only analyze cell types with enough cells\n",
    "            circular_means = []\n",
    "            \n",
    "            for i, sc_coords in enumerate(sc_coords_list):\n",
    "                sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "                angles_subset = sc_angles[mask]\n",
    "                \n",
    "                # Circular mean\n",
    "                mean_cos = np.mean(np.cos(angles_subset))\n",
    "                mean_sin = np.mean(np.sin(angles_subset))\n",
    "                circular_mean = np.arctan2(mean_sin, mean_cos)\n",
    "                if circular_mean < 0:\n",
    "                    circular_mean += 2*np.pi\n",
    "                \n",
    "                circular_means.append(np.degrees(circular_mean))\n",
    "            \n",
    "            # Check for large differences between runs\n",
    "            max_diff = max(circular_means) - min(circular_means)\n",
    "            if max_diff > 180:  # Handle wraparound\n",
    "                max_diff = 360 - max_diff\n",
    "            \n",
    "            print(f\"{cell_type}:\")\n",
    "            print(f\"  Run means: {[f'{m:.1f}°' for m in circular_means]}\")\n",
    "            print(f\"  Max difference: {max_diff:.1f}°\")\n",
    "            \n",
    "            if max_diff > 30:  # Significant sliding\n",
    "                print(f\"  ⚠️  SECTOR SLIDING DETECTED!\")\n",
    "            else:\n",
    "                print(f\"  ✅ Consistent placement\")\n",
    "\n",
    "# Load and process data\n",
    "scadata, stadata1, stadata2, stadata3 = load_and_process_cscc_data()\n",
    "\n",
    "# ADD THESE LINES:\n",
    "for i, stdata in enumerate([stadata1, stadata2, stadata3], 1):\n",
    "    coords = stdata.obsm['spatial']\n",
    "    print(f\"ST{i}: X[{coords[:, 0].min():.2f}, {coords[:, 0].max():.2f}], Y[{coords[:, 1].min():.2f}, {coords[:, 1].max():.2f}]\")\n",
    "\n",
    "\n",
    "# Train individual AdvancedHierarchicalDiffusion models and get averaged results\n",
    "scadata, advanced_models = train_individual_advanced_diffusion_models(\n",
    "    scadata, stadata1, stadata2, stadata3\n",
    ")\n",
    "\n",
    "print(\"Advanced diffusion training complete! Results saved in scadata.obsm['advanced_diffusion_coords_avg']\")\n",
    "\n",
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "my_tab20 = sns.color_palette(\"tab20\", n_colors=20).as_hex()\n",
    "\n",
    "# Plot 1: Averaged coordinates\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc.pl.embedding(scadata, basis='advanced_diffusion_coords_avg', color='rough_celltype',\n",
    "               size=85, title='SC Advanced Diffusion Coords (Averaged)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Individual model results\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sc.pl.embedding(scadata, basis=f'advanced_diffusion_coords_rep{i+1}', color='rough_celltype',\n",
    "                   size=85, title=f'SC Coordinates (Advanced Model {i+1})',\n",
    "                   palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Compute distance matrices for the 3 representations\n",
    "coords_list = [scadata.obsm[f'advanced_diffusion_coords_rep{i}'] for i in range(1, 4)]\n",
    "dist_matrices = [squareform(pdist(coords, metric='euclidean')) for coords in coords_list]\n",
    "\n",
    "# Plot the 3 distance matrices side by side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for i, (ax, dist_mat) in enumerate(zip(axes, dist_matrices)):\n",
    "    im = ax.imshow(dist_mat, cmap='viridis', aspect='auto')\n",
    "    ax.set_title(f'Distance Matrix - Rep{i+1}')\n",
    "    plt.colorbar(im, ax=ax)\n",
    "\n",
    "# Compute and print pairwise correlations between distance matrices\n",
    "print(\"Pairwise Correlations between Distance Matrices:\")\n",
    "for i in range(3):\n",
    "    for j in range(i+1, 3):\n",
    "        corr = np.corrcoef(dist_matrices[i].flatten(), dist_matrices[j].flatten())[0, 1]\n",
    "        print(f\"Rep{i+1} vs Rep{j+1}: {corr:.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawstdata = sc.read_csv('/home/ehtesamul/sc_st/data/cSCC/processed/GSM4284316_P2_ST_rep1_stdata.tsv.gz',delimiter='\\t')\n",
    "\n",
    "def normalize_coordinates_isotropic(coords):\n",
    "    \"\"\"Normalize coordinates isotropically to [-1, 1]\"\"\"\n",
    "    center = coords.mean(axis=0)\n",
    "    centered_coords = coords - center\n",
    "    max_dist = np.max(np.linalg.norm(centered_coords, axis=1))\n",
    "    normalized_coords = centered_coords / (max_dist + 1e-8)\n",
    "    return normalized_coords, center, max_dist\n",
    "\n",
    "# Load metadata FIRST to know which spots to keep\n",
    "rawstmeta = pd.read_csv('/home/ehtesamul/sc_st/data/cSCC/processed/GSM4284316_spot_data-selection-P2_ST_rep1.tsv.gz',delimiter='\\t')\n",
    "\n",
    "# Normalize the filtered coordinates\n",
    "stindex=[]\n",
    "for i in range(len(rawstmeta.x.tolist())):\n",
    "    stindex.append(str(rawstmeta.x[i])+'x'+str(rawstmeta.y[i]))\n",
    "rawstmeta.index = stindex\n",
    "\n",
    "# Filter FIRST, then extract and normalize coordinates\n",
    "rawstdata = rawstdata[stindex,:]\n",
    "rawstdata.obs = rawstmeta\n",
    "\n",
    "# NOW extract coordinates from the filtered data\n",
    "coord = np.array([x.split('x') for x in rawstdata.obs_names.tolist()],dtype='int')\n",
    "print(f\"Coordinates shape after filtering: {coord.shape}\")  # Should be (666, 2)\n",
    "\n",
    "# Normalize the filtered coordinates\n",
    "coord_norm, _, _ = normalize_coordinates_isotropic(coord)\n",
    "rawstdata.obsm['spatial'] = coord_norm\n",
    "# rawstdata.obsm['spatial'] = coord\n",
    "\n",
    "\n",
    "# Continue with preprocessing\n",
    "sc.pp.normalize_total(rawstdata, target_sum=1e4)\n",
    "sc.pp.log1p(rawstdata)\n",
    "rawstdata.layers[\"log1p\"] = rawstdata.X.copy()   # keep positive values\n",
    "rawstdata.raw = rawstdata[:, :]                  # optional: make this the .raw snapshot\n",
    "sc.pp.scale(rawstdata)                           # z-score only for downstream PCA etc.\n",
    "\n",
    "\n",
    "print(rawstdata)  # Should show 666 × 17138\n",
    "print(f\"Spatial coordinates shape: {rawstdata.obsm['spatial'].shape}\")  # Should be (666, 2)\n",
    "\n",
    "sc.pl.spatial(rawstdata,color=['BST2','NRP1','JCHAIN'],show=True,basis='spatial',na_in_legend=False,spot_size=0.05, save='all_three_exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "sccooravg = scadata.obsm['advanced_diffusion_coords_avg']\n",
    "PDCcoor = sccooravg[scadata.obs.level2_celltype=='PDC',:]\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# estimate ST spot pitch from nearest-neighbor distance in ST space\n",
    "_nn_st = NearestNeighbors(n_neighbors=2).fit(rawstdata.obsm['spatial'])\n",
    "_d2, _ = _nn_st.kneighbors(rawstdata.obsm['spatial'])\n",
    "spot_pitch = np.median(_d2[:, 1])\n",
    "\n",
    "radius = 1.2 * spot_pitch  # <- toggle this (1.2–2.0× are common)\n",
    "\n",
    "\n",
    "nbrs_rad = NearestNeighbors(radius=radius).fit(rawstdata.obsm['spatial'])\n",
    "ind = nbrs_rad.radius_neighbors(PDCcoor, return_distance=False)\n",
    "nearST = sorted(set(np.concatenate(ind)))\n",
    "\n",
    "# k = 10  # <- toggle (3–10)\n",
    "# nbrs_k = NearestNeighbors(n_neighbors=k).fit(rawstdata.obsm['spatial'])\n",
    "# idx = nbrs_k.kneighbors(PDCcoor, return_distance=False)\n",
    "# nearST = sorted(set(idx.flatten()))\n",
    "\n",
    "\n",
    "rawstdata.obs['pDCnear'] = 'Others'\n",
    "spot_idx = rawstdata.obs.index[nearST]   # index names corresponding to nearST positions\n",
    "rawstdata.obs.loc[spot_idx, 'pDCnear'] = 'pDC'\n",
    "\n",
    "\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "sc.pl.spatial(rawstdata,color=['pDCnear'],show=True,basis='spatial',na_in_legend=False,spot_size=0.05,save='pDCenrich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sccooravg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute spot pitch\n",
    "_nn_st = NearestNeighbors(n_neighbors=2).fit(rawstdata.obsm['spatial'])\n",
    "_d2, _ = _nn_st.kneighbors(rawstdata.obsm['spatial'])\n",
    "spot_pitch = np.median(_d2[:,1])\n",
    "radius = 1.2 * spot_pitch   # choose 1.2–1.8 as sensitivity\n",
    "# radius-based pDC label\n",
    "nbrs_rad = NearestNeighbors(radius=radius).fit(rawstdata.obsm['spatial'])\n",
    "ind = nbrs_rad.radius_neighbors(PDCcoor, return_distance=False)\n",
    "nearST = sorted(set(np.concatenate(ind)))\n",
    "\n",
    "# k = 15  # <- toggle (3–10)\n",
    "# nbrs_k = NearestNeighbors(n_neighbors=k).fit(rawstdata.obsm['spatial'])\n",
    "# idx = nbrs_k.kneighbors(PDCcoor, return_distance=False)\n",
    "# nearST = sorted(set(idx.flatten()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rawstdata.obs['pDCnear_radius'] = 'Others'\n",
    "rawstdata.obs.loc[rawstdata.obs.index[nearST],'pDCnear_radius'] = 'pDC'\n",
    "\n",
    "# run Scanpy DE (genome-wide)\n",
    "sc.tl.rank_genes_groups(rawstdata, groupby='pDCnear_radius', method='wilcoxon',\n",
    "                        layer='log1p', use_raw=False, key_added='deg_pdc_radius')\n",
    "\n",
    "degdf = sc.get.rank_genes_groups_df(rawstdata, group='pDC', key='deg_pdc_radius', log2fc_min=0)\n",
    "# degdf includes: names, logfoldchanges (Scanpy style), scores, pvals, pvals_adj\n",
    "\n",
    "\n",
    "# Print specific genes (BST2, NRP1) in a clean line format\n",
    "for g in ['BST2','NRP1']:\n",
    "    row = degdf.loc[degdf['names'] == g]\n",
    "    if not row.empty:\n",
    "        r = row.iloc[0]\n",
    "        print(f\"{g}: log2FC={r.logfoldchanges:.3f}, scores= {r.scores}, p={r.pvals:.2e}, padj={r.pvals_adj:.2e}\")\n",
    "    else:\n",
    "        print(f\"{g}: not found in DE results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figsize(4,4)\n",
    "# mpl.rcParams['figure.figsize'] = (4, 4)\n",
    "sc.pl.spatial(scadata,color=\"level2_celltype\",groups=[\"Tumor_KC_Cyc\"],spot_size=0.06, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False,save='P2cyc')\n",
    "sc.pl.spatial(scadata,color=\"level2_celltype\",groups=[\"Tumor_KC_Basal\"],spot_size=0.06, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False,save='P2bas')\n",
    "sc.pl.spatial(scadata,color=\"level2_celltype\",groups=[\"Tumor_KC_Diff\"],spot_size=0.06, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False,save='P2diff')\n",
    "#save='nonTSK',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squidpy as sq\n",
    "sq.gr.spatial_neighbors(scadata,spatial_key='advanced_diffusion_coords_avg')\n",
    "sq.gr.nhood_enrichment(scadata,cluster_key='rough_celltype')\n",
    "sq.gr.interaction_matrix(scadata,cluster_key='rough_celltype')\n",
    "kscadata = scadata[ scadata.obs.level2_celltype.isin(['Tumor_KC_Cyc','Tumor_KC_Basal','Tumor_KC_Diff','TSK'])].copy()\n",
    "sq.gr.spatial_neighbors(kscadata,spatial_key='advanced_diffusion_coords_avg')\n",
    "sq.gr.nhood_enrichment(kscadata,cluster_key='level2_celltype')\n",
    "# sq.pl.nhood_enrichment(kscadata, cluster_key=\"level2_celltype\",cmap='coolwarm',save='TSKKC_new_good.png',figsize=(3,5))\n",
    "sq.pl.nhood_enrichment(kscadata, cluster_key=\"level2_celltype\",cmap='coolwarm',figsize=(2,2), save='TSKKC_P2_avg.svg', dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# patient 10 stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Load all 3 ST datasets\n",
    "stadata1_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep1.h5ad')\n",
    "stadata2_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep2.h5ad')\n",
    "stadata3_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep3.h5ad')\n",
    "\n",
    "datasets = [stadata1_p10, stadata2_p10, stadata3_p10]\n",
    "names = ['ST_P10_Rep1', 'ST_P10_Rep2', 'ST_P10_Rep3']\n",
    "\n",
    "# Basic info\n",
    "print(\"Dataset Basic Info:\")\n",
    "for i, (data, name) in enumerate(zip(datasets, names)):\n",
    "    print(f\"{name}: {data.shape[0]} spots, {data.shape[1]} genes\")\n",
    "    print(f\"  Spatial coords range: X[{data.obsm['spatial'][:,0].min():.2f}, {data.obsm['spatial'][:,0].max():.2f}], Y[{data.obsm['spatial'][:,1].min():.2f}, {data.obsm['spatial'][:,1].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_cscc_data_p10():\n",
    "    \"\"\"\n",
    "    Load and process the cSCC dataset with multiple ST replicates.\n",
    "    \"\"\"\n",
    "    print(\"Loading cSCC data...\")\n",
    "    \n",
    "    # Load SC data\n",
    "    scadata_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP10.h5ad')\n",
    "    \n",
    "    # Load all 3 ST datasets\n",
    "    stadata1_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep1.h5ad')\n",
    "    stadata2_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep2.h5ad')\n",
    "    stadata3_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep3.h5ad')\n",
    "    \n",
    "    # Normalize and log transform\n",
    "    for adata in [scadata_p10, stadata1_p10, stadata2_p10, stadata3_p10]:\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "    \n",
    "    # Create rough cell types for SC data\n",
    "    scadata_p10.obs['rough_celltype'] = scadata_p10.obs['level1_celltype'].astype(str)\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='CLEC9A','rough_celltype'] = 'DC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='CD1C','rough_celltype'] = 'DC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='ASDC','rough_celltype'] = 'DC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='PDC','rough_celltype'] = 'PDC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='MDSC','rough_celltype'] = 'DC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='LC','rough_celltype'] = 'DC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='Mac','rough_celltype'] = 'Myeloid cell'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='Tcell','rough_celltype'] = 'T cell'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level2_celltype']=='TSK','rough_celltype'] = 'TSK'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level2_celltype'].isin(['Tumor_KC_Basal', 'Tumor_KC_Diff','Tumor_KC_Cyc']),'rough_celltype'] = 'NonTSK'\n",
    "    \n",
    "    return scadata_p10, stadata1_p10, stadata2_p10, stadata3_p10\n",
    "\n",
    "def prepare_combined_st_for_diffusion(stadata1, stadata2, stadata3, scadata):\n",
    "    \"\"\"\n",
    "    Combine all ST datasets for diffusion training while maintaining gene alignment.\n",
    "    Key innovation: Use ALL ST data points for better training.\n",
    "    \"\"\"\n",
    "    print(\"Preparing combined ST data for diffusion training...\")\n",
    "    \n",
    "    # Get common genes between SC and all ST datasets\n",
    "    sc_genes = set(scadata.var_names)\n",
    "    st1_genes = set(stadata1.var_names)\n",
    "    st2_genes = set(stadata2.var_names)\n",
    "    st3_genes = set(stadata3.var_names)\n",
    "    \n",
    "    common_genes = sorted(list(sc_genes & st1_genes & st2_genes & st3_genes))\n",
    "    print(f\"Common genes across all datasets: {len(common_genes)}\")\n",
    "    \n",
    "    # Extract aligned expression data\n",
    "    sc_expr = scadata[:, common_genes].X\n",
    "    st1_expr = stadata1[:, common_genes].X\n",
    "    st2_expr = stadata2[:, common_genes].X\n",
    "    st3_expr = stadata3[:, common_genes].X\n",
    "    \n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(sc_expr, 'toarray'):\n",
    "        sc_expr = sc_expr.toarray()\n",
    "    if hasattr(st1_expr, 'toarray'):\n",
    "        st1_expr = st1_expr.toarray()\n",
    "    if hasattr(st2_expr, 'toarray'):\n",
    "        st2_expr = st2_expr.toarray()\n",
    "    if hasattr(st3_expr, 'toarray'):\n",
    "        st3_expr = st3_expr.toarray()\n",
    "    \n",
    "    # Get spatial coordinates\n",
    "    st1_coords = stadata1.obsm['spatial']\n",
    "    st2_coords = stadata2.obsm['spatial']\n",
    "    st3_coords = stadata3.obsm['spatial']\n",
    "\n",
    "    # Store separate coordinate lists for block-diagonal graph\n",
    "    st_coords_list = [st1_coords, st2_coords, st3_coords]\n",
    "    \n",
    "    # Combine all ST data\n",
    "    st_expr_combined = np.vstack([st1_expr, st2_expr, st3_expr])\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    st_expr_combined = scaler.fit_transform(st_expr_combined)\n",
    "\n",
    "    st_coords_combined = np.vstack([st1_coords, st2_coords, st3_coords])\n",
    "\n",
    "    sc_expr = scaler.fit_transform(sc_expr)\n",
    "\n",
    "\n",
    "    \n",
    "    # Create dataset labels for tracking\n",
    "    dataset_labels = (['dataset1'] * len(st1_expr) + \n",
    "                     ['dataset2'] * len(st2_expr) + \n",
    "                     ['dataset3'] * len(st3_expr))\n",
    "    \n",
    "    print(f\"Combined ST data shape: {st_expr_combined.shape}\")\n",
    "    print(f\"Combined ST coords shape: {st_coords_combined.shape}\")\n",
    "    print(f\"SC data shape: {sc_expr.shape}\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_sc = torch.tensor(sc_expr, dtype=torch.float32)\n",
    "    X_st_combined = torch.tensor(st_expr_combined, dtype=torch.float32)\n",
    "    Y_st_combined = st_coords_combined.astype(np.float32)\n",
    "    \n",
    "    return X_sc, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list\n",
    "\n",
    "# Load and process data\n",
    "scadata_p10, stadata1_p10, stadata2_p10, stadata3_p10 = load_and_process_cscc_data_p10()\n",
    "\n",
    "# Prepare combined data for diffusion\n",
    "X_sc, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list = prepare_combined_st_for_diffusion(\n",
    "    stadata1_p10, stadata2_p10, stadata3_p10, scadata_p10\n",
    ")\n",
    "\n",
    "print(f\"Data preparation complete!\")\n",
    "print(f\"SC cells: {X_sc.shape[0]}\")\n",
    "print(f\"Combined ST spots: {X_st_combined.shape[0]}\")\n",
    "print(f\"Common genes: {len(common_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal notebook cell: Procrustes alignment for 5 points across 3 coordinate systems\n",
    "import numpy as np\n",
    "\n",
    "def procrustes_align(X_ref, Y, allow_scaling=True, allow_reflection=True):\n",
    "    X = np.asarray(X_ref, float); Y = np.asarray(Y, float)\n",
    "    if X.shape != Y.shape: raise ValueError(\"X_ref and Y must have the same shape\")\n",
    "    n = X.shape[0]\n",
    "    Xc = X - X.mean(axis=0, keepdims=True)\n",
    "    Yc = Y - Y.mean(axis=0, keepdims=True)\n",
    "    C = Yc.T @ Xc / n\n",
    "    U, S, Vt = np.linalg.svd(C)\n",
    "    R = U @ Vt\n",
    "    if (not allow_reflection) and (np.linalg.det(R) < 0):\n",
    "        Vt[-1] *= -1\n",
    "        R = U @ Vt\n",
    "    s = (S.sum()) / (np.linalg.norm(Yc) ** 2 / n) if allow_scaling else 1.0\n",
    "    Y_aligned = s * (Yc @ R) + X.mean(axis=0, keepdims=True)\n",
    "    t = (X.mean(axis=0) - s * (Y.mean(axis=0) @ R))\n",
    "    rmsd = np.sqrt(((X - Y_aligned)**2).sum() / n)\n",
    "    return Y_aligned, R, s, t, rmsd\n",
    "\n",
    "def transform(P, theta_deg=0, tx=0, ty=0, scale=1.0, reflect=False, noise=0.0, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    th = np.deg2rad(theta_deg)\n",
    "    R = np.array([[np.cos(th), -np.sin(th)],\n",
    "                  [np.sin(th),  np.cos(th)]])\n",
    "    if reflect: R[:,0] *= -1\n",
    "    Q = (P @ R.T) * scale + np.array([tx, ty])\n",
    "    if noise > 0: Q = Q + rng.normal(0, noise, size=Q.shape)\n",
    "    return Q\n",
    "\n",
    "# --- Example data (5 points) ---\n",
    "base = np.array([[0.0, 0.0],\n",
    "                 [1.2, 0.1],\n",
    "                 [1.1, 1.1],\n",
    "                 [0.2, 1.3],\n",
    "                 [-0.3, 0.6]], float)\n",
    "A = base\n",
    "B = transform(base, theta_deg=35, tx=2.0, ty=-1.0, scale=1.0, noise=0.01, seed=1)\n",
    "C = transform(base, theta_deg=-95, tx=-1.3, ty=0.9, scale=1.25, reflect=True, noise=0.01, seed=2)\n",
    "\n",
    "# --- Align B, C → A ---\n",
    "B_aln, Rb, sb, tb, rmsd_b = procrustes_align(A, B, allow_scaling=True, allow_reflection=True)\n",
    "C_aln, Rc, sc, tc, rmsd_c = procrustes_align(A, C, allow_scaling=True, allow_reflection=True)\n",
    "\n",
    "# Results you can print or inspect\n",
    "print(\"B→A  s=\", round(sb,4), \"RMSD=\", round(rmsd_b,6), \"\\nR=\\n\", Rb, \"\\nt=\", tb)\n",
    "print(\"\\nC→A  s=\", round(sc,4), \"RMSD=\", round(rmsd_c,6), \"\\nR=\\n\", Rc, \"\\nt=\", tc)\n",
    "\n",
    "# Optional plotting (disabled by default)\n",
    "SHOW_PLOTS = True\n",
    "if SHOW_PLOTS:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(); plt.scatter(A[:,0],A[:,1]); plt.scatter(B[:,0],B[:,1]); plt.scatter(C[:,0],C[:,1]); plt.axis('equal'); plt.title(\"Before\"); plt.show()\n",
    "    plt.figure(); plt.scatter(A[:,0],A[:,1]); plt.scatter(B_aln[:,0],B_aln[:,1]); plt.scatter(C_aln[:,0],C_aln[:,1]); plt.axis('equal'); plt.title(\"After\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "def train_individual_advanced_diffusion_models(scadata, stadata1, stadata2, stadata3):\n",
    "    \"\"\"\n",
    "    Train separate AdvancedHierarchicalDiffusion models for each ST dataset and average the results.\n",
    "    MODIFIED: Run stadata1 three times to test for SC cluster rotation/sliding\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Store results from each model\n",
    "    sc_coords_results = []\n",
    "    models_all = []\n",
    "    \n",
    "    # STEP 1: Build canonical angular frame from ST slide (ONCE)\n",
    "    # st_coords_raw = stadata1.obsm['spatial']  # Use raw ST coordinates\n",
    "    # angular_frame = _build_canonical_angular_frame(st_coords_raw)\n",
    "    \n",
    "    # List of ST datasets for iteration - Use stadata1 three times\n",
    "    st_datasets = [\n",
    "        (stadata1, \"run1\"),\n",
    "        (stadata2, \"run2\"), \n",
    "        (stadata3, \"run3\")\n",
    "    ]\n",
    "    \n",
    "    for i, (stadata, run_name) in enumerate(st_datasets):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training AdvancedHierarchicalDiffusion model {i+1}/3 for {run_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Get common genes between SC and current ST dataset\n",
    "        sc_genes = set(scadata.var_names)\n",
    "        st_genes = set(stadata.var_names)\n",
    "        common_genes = sorted(list(sc_genes & st_genes))\n",
    "        \n",
    "        print(f\"Common genes for {run_name}: {len(common_genes)}\")\n",
    "        \n",
    "        # Extract expression data\n",
    "        sc_expr = scadata[:, common_genes].X\n",
    "        st_expr = stadata[:, common_genes].X\n",
    "        \n",
    "        # Convert to dense if sparse\n",
    "        if hasattr(sc_expr, 'toarray'):\n",
    "            sc_expr = sc_expr.toarray()\n",
    "        if hasattr(st_expr, 'toarray'):\n",
    "            st_expr = st_expr.toarray()\n",
    "            \n",
    "        # Get spatial coordinates\n",
    "        st_coords = stadata.obsm['spatial']\n",
    "        \n",
    "        print(f\"SC data shape: {sc_expr.shape}\")\n",
    "        print(f\"ST data shape: {st_expr.shape}\")\n",
    "        print(f\"ST coords shape: {st_coords.shape}\")\n",
    "        \n",
    "        # Initialize model with different random seed for each run\n",
    "        torch.manual_seed(42 + i)\n",
    "        np.random.seed(42 + i)\n",
    "\n",
    "        # dp = 1 - scadata.obs['n_genes_by_counts'].median() / stadata.obs['n_genes_by_counts'].median()\n",
    "\n",
    "        \n",
    "        model = AdvancedHierarchicalDiffusion(\n",
    "            st_gene_expr=st_expr,\n",
    "            st_coords=st_coords,\n",
    "            sc_gene_expr=sc_expr,\n",
    "            cell_types_sc=scadata.obs['rough_celltype'].values,\n",
    "            transport_plan=None,\n",
    "            D_st=None,\n",
    "            D_induced=None,\n",
    "            n_genes=len(common_genes),\n",
    "            n_embedding=[512, 256, 128],\n",
    "            coord_space_diameter=2.00,\n",
    "            sigma=0.75,\n",
    "            alpha=0.8,\n",
    "            mmdbatch=1000,\n",
    "            batch_size=256,\n",
    "            device=device,\n",
    "            lr_e=0.002,\n",
    "            lr_d=0.0002,\n",
    "            n_timesteps=300,\n",
    "            n_denoising_blocks=4,\n",
    "            hidden_dim=256,\n",
    "            num_heads=6,\n",
    "            num_hierarchical_scales=3,\n",
    "            dp=0.2,\n",
    "            outf=f'advanced_diffusion_{run_name}'\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        print(f\"Training model for {run_name}...\")\n",
    "        model.train(\n",
    "            encoder_epochs=1201,\n",
    "            vae_epochs=3001,\n",
    "            diffusion_epochs=5001, p_drop_max=0.15\n",
    "        )\n",
    "\n",
    "        # st_coords_raw = model.st_coords_norm.cpu().numpy()  # Use normalized coords from model\n",
    "        st_coords_raw = model.st_coords_norm.cpu().numpy()  # Use normalized coords from model\n",
    "        angular_frame = _build_canonical_angular_frame(st_coords_raw)\n",
    "        \n",
    "        # Generate SC coordinates\n",
    "        print(f\"Generating SC coordinates using {run_name} model...\")\n",
    "        # sc_coords = model.generate_sc_coordinates()\n",
    "        # sc_coords = model.sample_sc_coordinates_batched(\n",
    "        #     batch_size=512,  # Even smaller batches\n",
    "        #     refine_coords=False\n",
    "        # )\n",
    "\n",
    "        # model.fine_tune_decoder_boundary(\n",
    "        #     epochs=10,           # 8–15 is typical\n",
    "        #     batch_size=1024,\n",
    "        #     lambda_hull=3.0,     # 3–8 works well; increase only if leaks remain\n",
    "        #     outlier_sigma= 0.5   # amount of latent perturbation for hull shaping\n",
    "        # )\n",
    "\n",
    "\n",
    "        # sc_coords = model.sample_sc_coordinates_pure_diffusion(\n",
    "        #     batch_size=512, return_normalized=False\n",
    "        # )\n",
    "        sc_coords = model.sample_sc_coordinates(\n",
    "            batch_size=512,\n",
    "            guidance_scale=10.0,\n",
    "            return_normalized= True\n",
    "        )\n",
    "\n",
    "        print(f\"\\n=== Generated SC Coordinates ({run_name}) ===\")\n",
    "        print(f\"  X range: [{sc_coords[:, 0].min():.3f}, {sc_coords[:, 0].max():.3f}]\")\n",
    "        print(f\"  Y range: [{sc_coords[:, 1].min():.3f}, {sc_coords[:, 1].max():.3f}]\")\n",
    "        # print(f\"  Max radius from center: {np.max(np.linalg.norm(sc_coords, axis=1)):.3f}\")\n",
    "        # print(f\"  % points outside unit circle: {(np.linalg.norm(sc_coords, axis=1) > 1).mean()*100:.1f}%\")\n",
    "\n",
    "        # Evaluate geometry preservation\n",
    "        # metrics = model.evaluate_geometry_preservation(sc_coords)\n",
    "        sc_coords_results.append(sc_coords)\n",
    "        models_all.append(model)\n",
    "        \n",
    "        # STEP 2: Plot SC cells colored by angle (using ST-derived frame)\n",
    "        _plot_sc_angle_analysis(sc_coords, scadata.obs['rough_celltype'].values, \n",
    "                               angular_frame, st_coords_raw, run_name, i+1)\n",
    "    \n",
    "    # STEP 3: Comparative analysis across runs\n",
    "    _plot_comparative_sc_angle_analysis(sc_coords_results, scadata.obs['rough_celltype'].values,\n",
    "                                       angular_frame, st_coords_raw)\n",
    "    \n",
    "    # Compute averaged SC coordinates\n",
    "    sc_coords_results_np = [\n",
    "        coords.cpu().numpy() if hasattr(coords, 'cpu') else coords \n",
    "        for coords in sc_coords_results\n",
    "    ]\n",
    "\n",
    "    sc_coords_avg = np.mean(sc_coords_results_np, axis=0)\n",
    "    sc_coords_std = np.std(sc_coords_results_np, axis=0)\n",
    "\n",
    "    # Store results in scadata\n",
    "    scadata.obsm['advanced_diffusion_coords_avg'] = sc_coords_avg\n",
    "    scadata.obsm['advanced_diffusion_coords_std'] = sc_coords_std\n",
    "\n",
    "    # Store individual results\n",
    "    for i, coords in enumerate(sc_coords_results_np):  # Use numpy arrays\n",
    "        scadata.obsm[f'advanced_diffusion_coords_rep{i+1}'] = coords\n",
    "\n",
    "    print(f\"\\nTraining complete. Results stored in scadata.obsm\")\n",
    "    return scadata, models_all\n",
    "\n",
    "def _build_canonical_angular_frame(st_coords):\n",
    "    \"\"\"Build canonical angular frame from ST coordinates (dataset-specific, run-independent)\"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Compute centroid\n",
    "    centroid = st_coords.mean(axis=0)\n",
    "    \n",
    "    # Find farthest spot from centroid (deterministic 0° direction)\n",
    "    distances = np.linalg.norm(st_coords - centroid, axis=1)\n",
    "    farthest_idx = np.argmax(distances)\n",
    "    a0 = st_coords[farthest_idx] - centroid  # 0° direction vector\n",
    "    \n",
    "    def angle_fn(x):\n",
    "        \"\"\"Compute angle from canonical frame\"\"\"\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        \n",
    "        v = x - centroid\n",
    "        cross = a0[0] * v[:, 1] - a0[1] * v[:, 0]  # z-component of 2D cross\n",
    "        dot = a0[0] * v[:, 0] + a0[1] * v[:, 1]\n",
    "        angles = np.arctan2(cross, dot)\n",
    "        angles = np.where(angles < 0, angles + 2*np.pi, angles)  # Map to [0, 2π)\n",
    "        return angles\n",
    "    \n",
    "    return {\n",
    "        'centroid': centroid,\n",
    "        'zero_direction': a0,\n",
    "        'farthest_idx': farthest_idx,\n",
    "        'angle_fn': angle_fn\n",
    "    }\n",
    "\n",
    "def _plot_sc_angle_analysis(sc_coords, cell_types, angular_frame, st_coords_bg, run_name, run_num):\n",
    "    \"\"\"Plot SC cells colored by angle from ST-derived frame\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Compute angles for SC cells using ST-derived frame\n",
    "    sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "    sc_angles_degrees = np.degrees(sc_angles)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot 1: SC cells colored by angle (with ST outline in background)\n",
    "    ax1.scatter(st_coords_bg[:, 0], st_coords_bg[:, 1], \n",
    "               c='black', s=100, alpha=0.8, label='ST outline')\n",
    "    \n",
    "    scatter = ax1.scatter(sc_coords[:, 0], sc_coords[:, 1], \n",
    "                         c=sc_angles_degrees, cmap='hsv', s=30, alpha=0.8)\n",
    "    \n",
    "    # Mark centroid and 0° direction\n",
    "    centroid = angular_frame['centroid']\n",
    "    zero_dir = angular_frame['zero_direction']\n",
    "    ax1.scatter(centroid[0], centroid[1], c='black', s=100, marker='x', linewidth=3)\n",
    "    ax1.arrow(centroid[0], centroid[1], zero_dir[0]*0.3, zero_dir[1]*0.3, \n",
    "              head_width=0.05, head_length=0.05, fc='red', ec='red', linewidth=2)\n",
    "    \n",
    "    ax1.set_title(f'{run_name}: SC Cells Colored by Angle θ')\n",
    "    ax1.set_xlabel('X coordinate')\n",
    "    ax1.set_ylabel('Y coordinate')\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax1)\n",
    "    cbar.set_label('Angle (degrees)')\n",
    "    \n",
    "    # Plot 2: Per-cell-type angle distribution\n",
    "    unique_types = np.unique(cell_types)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_types)))\n",
    "    \n",
    "    for i, cell_type in enumerate(unique_types):\n",
    "        mask = cell_types == cell_type\n",
    "        if np.sum(mask) > 0:\n",
    "            angles_subset = sc_angles_degrees[mask]\n",
    "            ax2.hist(angles_subset, bins=36, alpha=0.6, label=cell_type, \n",
    "                    color=colors[i], density=True)\n",
    "    \n",
    "    ax2.set_title(f'{run_name}: Angle Distribution by Cell Type')\n",
    "    ax2.set_xlabel('Angle (degrees)')\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.set_xlim(0, 360)\n",
    "    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'sc_angle_analysis_{run_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print circular statistics per cell type\n",
    "    print(f\"\\n{run_name} - Circular statistics per cell type:\")\n",
    "    for cell_type in unique_types:\n",
    "        mask = cell_types == cell_type\n",
    "        if np.sum(mask) > 5:  # Only if enough cells\n",
    "            angles_rad = sc_angles[mask]\n",
    "            # Circular mean\n",
    "            mean_cos = np.mean(np.cos(angles_rad))\n",
    "            mean_sin = np.mean(np.sin(angles_rad))\n",
    "            circular_mean = np.arctan2(mean_sin, mean_cos)\n",
    "            if circular_mean < 0:\n",
    "                circular_mean += 2*np.pi\n",
    "            \n",
    "            print(f\"  {cell_type}: mean={np.degrees(circular_mean):.1f}°, n={np.sum(mask)}\")\n",
    "\n",
    "def _plot_comparative_sc_angle_analysis(sc_coords_list, cell_types, angular_frame, st_coords_bg):\n",
    "    \"\"\"Plot comparative SC angle analysis across all runs\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    n_runs = len(sc_coords_list)\n",
    "    unique_types = np.unique(cell_types)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_runs, figsize=(5*n_runs, 10))\n",
    "    if n_runs == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    # Top row: SC scatter plots per run\n",
    "    for i, sc_coords in enumerate(sc_coords_list):\n",
    "        ax = axes[0, i]\n",
    "        \n",
    "        # ST background\n",
    "        ax.scatter(st_coords_bg[:, 0], st_coords_bg[:, 1], \n",
    "                  c='black', s=20, alpha=0.8)\n",
    "        \n",
    "        # SC cells colored by angle\n",
    "        sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "        sc_angles_degrees = np.degrees(sc_angles)\n",
    "        \n",
    "        scatter = ax.scatter(sc_coords[:, 0], sc_coords[:, 1], \n",
    "                           c=sc_angles_degrees, cmap='hsv', s=20, alpha=0.1)\n",
    "        \n",
    "        ax.set_title(f'Run {i+1}: SC Cells by Angle')\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        if i == n_runs-1:  # Add colorbar to last plot\n",
    "            cbar = plt.colorbar(scatter, ax=ax)\n",
    "            cbar.set_label('Angle (degrees)')\n",
    "    \n",
    "    # Bottom row: Cell type angle distributions per run  \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_types)))\n",
    "    \n",
    "    for i, sc_coords in enumerate(sc_coords_list):\n",
    "        ax = axes[1, i]\n",
    "        \n",
    "        sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "        sc_angles_degrees = np.degrees(sc_angles)\n",
    "        \n",
    "        for j, cell_type in enumerate(unique_types):\n",
    "            mask = cell_types == cell_type\n",
    "            if np.sum(mask) > 5:\n",
    "                angles_subset = sc_angles_degrees[mask]\n",
    "                ax.hist(angles_subset, bins=36, alpha=0.6, \n",
    "                       label=cell_type if i == 0 else \"\", \n",
    "                       color=colors[j], density=True)\n",
    "        \n",
    "        ax.set_title(f'Run {i+1}: Cell Type Angles')\n",
    "        ax.set_xlabel('Angle (degrees)')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_xlim(0, 360)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comparative_sc_angle_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Check for sector sliding\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"SECTOR SLIDING ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for cell_type in unique_types:\n",
    "        mask = cell_types == cell_type\n",
    "        if np.sum(mask) > 10:  # Only analyze cell types with enough cells\n",
    "            circular_means = []\n",
    "            \n",
    "            for i, sc_coords in enumerate(sc_coords_list):\n",
    "                sc_angles = angular_frame['angle_fn'](sc_coords)\n",
    "                angles_subset = sc_angles[mask]\n",
    "                \n",
    "                # Circular mean\n",
    "                mean_cos = np.mean(np.cos(angles_subset))\n",
    "                mean_sin = np.mean(np.sin(angles_subset))\n",
    "                circular_mean = np.arctan2(mean_sin, mean_cos)\n",
    "                if circular_mean < 0:\n",
    "                    circular_mean += 2*np.pi\n",
    "                \n",
    "                circular_means.append(np.degrees(circular_mean))\n",
    "            \n",
    "            # Check for large differences between runs\n",
    "            max_diff = max(circular_means) - min(circular_means)\n",
    "            if max_diff > 180:  # Handle wraparound\n",
    "                max_diff = 360 - max_diff\n",
    "            \n",
    "            print(f\"{cell_type}:\")\n",
    "            print(f\"  Run means: {[f'{m:.1f}°' for m in circular_means]}\")\n",
    "            print(f\"  Max difference: {max_diff:.1f}°\")\n",
    "            \n",
    "            if max_diff > 30:  # Significant sliding\n",
    "                print(f\"  ⚠️  SECTOR SLIDING DETECTED!\")\n",
    "            else:\n",
    "                print(f\"  ✅ Consistent placement\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "scadata_p10, stadata1_p10, stadata2_p10, stadata3_p10 = load_and_process_cscc_data_p10()\n",
    "\n",
    "# Train individual AdvancedHierarchicalDiffusion models and get averaged results\n",
    "scadata_p10, advanced_models_p10 = train_individual_advanced_diffusion_models(\n",
    "    scadata_p10, stadata1_p10, stadata2_p10, stadata3_p10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Rigid Procrustes (no scaling, no reflection) ---\n",
    "def procrustes_align(X_ref, Y, allow_scaling=False, allow_reflection=False):\n",
    "    X = np.asarray(X_ref, float); Y = np.asarray(Y, float)\n",
    "    if X.shape != Y.shape:\n",
    "        raise ValueError(\"X_ref and Y must have the same shape (same cells, same order).\")\n",
    "    n = X.shape[0]\n",
    "\n",
    "    Xc = X - X.mean(axis=0, keepdims=True)\n",
    "    Yc = Y - Y.mean(axis=0, keepdims=True)\n",
    "\n",
    "    C = Yc.T @ Xc / n\n",
    "    U, S, Vt = np.linalg.svd(C)\n",
    "    R = U @ Vt\n",
    "    if (not allow_reflection) and (np.linalg.det(R) < 0):\n",
    "        Vt[-1] *= -1\n",
    "        R = U @ Vt\n",
    "\n",
    "    s = 1.0 if not allow_scaling else (S.sum()) / (np.linalg.norm(Yc) ** 2 / n)\n",
    "    Y_aligned = s * (Yc @ R) + X.mean(axis=0, keepdims=True)\n",
    "    t = (X.mean(axis=0) - s * (Y.mean(axis=0) @ R))\n",
    "    rmsd = np.sqrt(((X - Y_aligned) ** 2).sum() / n)\n",
    "    return Y_aligned, R, s, t, rmsd\n",
    "\n",
    "# --- Fetch reps (as numpy) ---\n",
    "rep1 = np.asarray(scadata_p10.obsm['advanced_diffusion_coords_rep1'], float)\n",
    "rep2 = np.asarray(scadata_p10.obsm['advanced_diffusion_coords_rep2'], float)\n",
    "rep3 = np.asarray(scadata_p10.obsm['advanced_diffusion_coords_rep3'], float)\n",
    "\n",
    "# Sanity checks\n",
    "assert rep1.shape == rep2.shape == rep3.shape, \"rep shapes differ\"\n",
    "assert not np.isnan(rep1).any() and not np.isnan(rep2).any() and not np.isnan(rep3).any(), \"NaNs present\"\n",
    "\n",
    "# --- Align rep2, rep3 to rep1 (rigid: rotation+translation only) ---\n",
    "rep2_aln, R2, s2, t2, rmsd2 = procrustes_align(rep1, rep2, allow_scaling=False, allow_reflection=False)\n",
    "rep3_aln, R3, s3, t3, rmsd3 = procrustes_align(rep1, rep3, allow_scaling=False, allow_reflection=False)\n",
    "\n",
    "print(f\"rep2→rep1  scale={s2:.4f} (fixed to 1.0), reflection={'yes' if np.linalg.det(R2)<0 else 'no'}, RMSD={rmsd2:.6f}\")\n",
    "print(f\"rep3→rep1  scale={s3:.4f} (fixed to 1.0), reflection={'yes' if np.linalg.det(R3)<0 else 'no'}, RMSD={rmsd3:.6f}\")\n",
    "\n",
    "# --- Save aligned reps back and recompute average/std ---\n",
    "scadata_p10.obsm['advanced_diffusion_coords_rep1_aligned'] = rep1\n",
    "scadata_p10.obsm['advanced_diffusion_coords_rep2_aligned'] = rep2_aln\n",
    "scadata_p10.obsm['advanced_diffusion_coords_rep3_aligned'] = rep3_aln\n",
    "\n",
    "stack = np.stack([rep1, rep2_aln, rep3_aln], axis=0)  # (3, n_cells, 2)\n",
    "scadata_p10.obsm['advanced_diffusion_coords_avg_rigid'] = stack.mean(axis=0)\n",
    "scadata_p10.obsm['advanced_diffusion_coords_std_rigid'] = stack.std(axis=0)\n",
    "\n",
    "# Optional: keep transforms if you want to reapply later\n",
    "scadata_p10.uns['advanced_diffusion_rigid_transforms'] = {\n",
    "    'rep2': {'R': R2, 's': float(s2), 't': t2, 'rmsd': float(rmsd2)},\n",
    "    'rep3': {'R': R3, 's': float(s3), 't': t3, 'rmsd': float(rmsd3)},\n",
    "}\n",
    "\n",
    "print(\"Aligned coords stored in:\")\n",
    "print(\"  obsm['advanced_diffusion_coords_rep2_aligned']\")\n",
    "print(\"  obsm['advanced_diffusion_coords_rep3_aligned']\")\n",
    "print(\"Averaged coords (rigid) in:\")\n",
    "print(\"  obsm['advanced_diffusion_coords_avg_rigid'], std in 'advanced_diffusion_coords_std_rigid'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import scanpy as sc\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (4, 4)\n",
    "\n",
    "my_tab20 = sns.color_palette(\"tab20\", n_colors=20).as_hex()\n",
    "\n",
    "# Plot 1: Averaged coordinates\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc.pl.embedding(scadata_p10, basis='advanced_diffusion_coords_avg', color='rough_celltype',\n",
    "               size=85, title='SC Advanced Diffusion Coords (Averaged)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Individual model results\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sc.pl.embedding(scadata_p10, basis=f'advanced_diffusion_coords_rep{i+1}', color='rough_celltype',\n",
    "                   size=85, title=f'SC Coordinates (Advanced Model {i+1})',\n",
    "                   palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "\n",
    "import seaborn as sns\n",
    "n_groups = scadata_p10.obs[\"rough_celltype\"].nunique()\n",
    "my_tab20 = sns.color_palette(\"tab20\", n_colors=n_groups).as_hex()\n",
    "\n",
    "# my_tab20 = sns.color_palette(\"tab10\", n_colors=20).as_hex()\n",
    "\n",
    "\n",
    "# ---------- user preferences ----------\n",
    "sc.settings.set_figure_params(format='svg')      # keep default SVG\n",
    "mpl.rcParams['figure.figsize'] = (6, 6)          # default figsize (will be overridden for this fig)\n",
    "os.makedirs(\"figures\", exist_ok=True)            # create folder on the go\n",
    "outpath = \"figures/P10_rep1_v1.svg\"                 # final save path\n",
    "dpi_save = 600                                   # desired DPI for export\n",
    "# --------------------------------------\n",
    "\n",
    "# (optional) temporarily silence the FutureWarning about squidpy alternative\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Plot with Scanpy but DON'T save yet (show=False), so we can customize the legend\n",
    "sc.pl.spatial(\n",
    "    scadata_p10,\n",
    "    color=\"rough_celltype\",\n",
    "    spot_size=0.03,\n",
    "    show=False,                         # prevent automatic display/save so we can customize\n",
    "    basis='advanced_diffusion_coords_avg',\n",
    "    title='reconstructed',\n",
    "    save=None,                           # make sure Scanpy doesn't auto-save; we handle saving below\n",
    "    palette = my_tab20\n",
    ")\n",
    "\n",
    "# grab current Axes & Figure\n",
    "ax = plt.gca()\n",
    "fig = ax.get_figure()\n",
    "\n",
    "# --- Optional: make the figure wider so the horizontal legend fits comfortably ---\n",
    "# You can change these numbers (width, height) to taste.\n",
    "fig.set_size_inches(10, 6)   # increase width (was 5x5); user said wider is fine\n",
    "\n",
    "# --- Build a clean horizontal legend BELOW the plot ---\n",
    "# Remove any existing legend first (Scanpy sometimes creates one)\n",
    "old_leg = ax.get_legend()\n",
    "if old_leg:\n",
    "    old_leg.remove()\n",
    "\n",
    "# obtain handles & labels from the scatter artist(s)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# If Scanpy produced extra \"title-like\" legend entries, you might get duplicate/empty labels;\n",
    "# if so, filter them out (uncomment if needed)\n",
    "# pairs = [(h, l) for h, l in zip(handles, labels) if l not in (None, '')]\n",
    "# if pairs:\n",
    "#     handles, labels = zip(*pairs)\n",
    "# else:\n",
    "#     handles, labels = [], []\n",
    "\n",
    "# place legend as a horizontal strip below the main axes\n",
    "# - loc='upper center' with bbox_to_anchor centers the legend beneath the axes\n",
    "# - bbox_to_anchor: (0.5, -0.15) -> x=0.5 center, y negative moves it below the axes; tweak y to move further down\n",
    "# - ncol: set how many columns you want; set to len(labels) for a single-row legend (will be wide)\n",
    "# - frameon: False removes the border if you want a clean strip\n",
    "ncol = len(labels)                 # puts all entries in a single row; change to e.g. 6 for multiple rows\n",
    "legend = ax.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.5, -0.13),\n",
    "    ncol=ncol,\n",
    "    frameon=False,\n",
    "    handlelength=2.5,\n",
    "    columnspacing=1.0,\n",
    "    fontsize=14\n",
    ")\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# after you create `legend`:\n",
    "for h in legend.legendHandles:\n",
    "    if isinstance(h, matplotlib.collections.PathCollection):\n",
    "        # size is in points^2 (try values like 50, 100, 200, 400)\n",
    "        h.set_sizes([200.0])     # <- increase this number to make markers bigger\n",
    "    else:\n",
    "        try:\n",
    "            h.set_markersize(10)  # for Line2D handles (if any)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "# Reserve space at the bottom so the legend isn't clipped\n",
    "# Increase the bottom margin proportionally to how far below you placed the legend\n",
    "fig.subplots_adjust(bottom=0.22)   # increase if you move legend further down (or more rows)\n",
    "\n",
    "# If you prefer the legend to be drawn across the whole figure, you can use fig.legend(...) instead.\n",
    "# Example: fig.legend(handles, labels, loc='lower center', ncol=ncol, bbox_to_anchor=(0.5, 0.02))\n",
    "# But ax.legend above keeps alignment with the axes more predictably.\n",
    "\n",
    "# --- Save the figure to the folder as SVG at 600 DPI ---\n",
    "fig.savefig(outpath, format=\"svg\", dpi=dpi_save, bbox_inches=\"tight\")\n",
    "\n",
    "# show the final adjusted figure in the notebook\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcParams['pdf.fonttype'] = 42\n",
    "# rcParams['ps.fonttype'] = 42\n",
    "# figsize(4,4)\n",
    "mpl.rcParams['figure.figsize'] = (5, 5)\n",
    "# sc.pl.spatial(scadata,color=\"level3_celltype\",groups=[\"TSK\"],spot_size=0.06, show=True,basis='advanced_diffusion_coords_rep3',title='reconstructed',na_in_legend=False, save='P2_rep3_tsk_v2')\n",
    "sc.pl.spatial(\n",
    "    scadata_p10,\n",
    "    color=\"level3_celltype\",\n",
    "    groups=[\"TSK\"],\n",
    "    spot_size=0.06,\n",
    "    show=False,  # <- Important: prevent auto-show\n",
    "    basis='advanced_diffusion_coords_avg',\n",
    "    title='reconstructed',\n",
    "    na_in_legend=False\n",
    ")\n",
    "\n",
    "# Save manually with high resolution\n",
    "plt.savefig(\"P10_rep2_tsk_v10.svg\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "#save='TSK',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scadata_p10.obs['selection'] = (scadata_p10.obs['level2_celltype']=='TSK').astype(int)\n",
    "scadata_p10.obs['selection2'] = (scadata_p10.obs['level1_celltype']=='Fibroblast').astype(int)\n",
    "scadata_p10.obs['selection3'] = (scadata_p10.obs['rough_celltype']=='Epithelial').astype(int)\n",
    "\n",
    "# figsize(6,5)\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "sc.pl.spatial(scadata_p10, color=['selection','selection2','selection3','level3_celltype'], spot_size=0.025,cmap='bwr',basis='advanced_diffusion_coords_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squidpy as sq\n",
    "sq.gr.spatial_neighbors(scadata_p10,spatial_key='advanced_diffusion_coords_avg')\n",
    "sq.gr.nhood_enrichment(scadata_p10,cluster_key='rough_celltype')\n",
    "sq.gr.interaction_matrix(scadata_p10,cluster_key='rough_celltype')\n",
    "kscadata_p10 = scadata_p10[ scadata_p10.obs.level2_celltype.isin(['Tumor_KC_Cyc','Tumor_KC_Basal','Tumor_KC_Diff','TSK'])].copy()\n",
    "sq.gr.spatial_neighbors(kscadata_p10,spatial_key='advanced_diffusion_coords_avg')\n",
    "sq.gr.nhood_enrichment(kscadata_p10,cluster_key='level2_celltype')\n",
    "# sq.pl.nhood_enrichment(kscadata, cluster_key=\"level2_celltype\",cmap='coolwarm',save='TSKKC_new_best_p10.svg',figsize=(3,5), title=None)\n",
    "# sq.pl.nhood_enrichment(kscadata, cluster_key=\"level2_celltype\", cmap='coolwarm', save='TSKKC_new_best_p10.svg', figsize=(3,5), ylabel='')\n",
    "# sq.pl.nhood_enrichment(kscadata, cluster_key=\"level2_celltype\",cmap='coolwarm',figsize=(3,5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,5))\n",
    "sq.pl.nhood_enrichment(kscadata_p10, cluster_key=\"level2_celltype\", cmap='coolwarm', ax=ax)\n",
    "ax.set_ylabel('')\n",
    "# plt.savefig('TSKKC_new_best_p10.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Load all 3 ST datasets\n",
    "stadata1_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep1.h5ad')\n",
    "stadata2_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep2.h5ad')\n",
    "stadata3_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep3.h5ad')\n",
    "\n",
    "datasets = [stadata1_p10, stadata2_p10, stadata3_p10]\n",
    "names = ['ST_P10_Rep1', 'ST_P10_Rep2', 'ST_P10_Rep3']\n",
    "\n",
    "# Basic info\n",
    "print(\"Dataset Basic Info:\")\n",
    "for i, (data, name) in enumerate(zip(datasets, names)):\n",
    "    print(f\"{name}: {data.shape[0]} spots, {data.shape[1]} genes\")\n",
    "    print(f\"  Spatial coords range: X[{data.obsm['spatial'][:,0].min():.2f}, {data.obsm['spatial'][:,0].max():.2f}], Y[{data.obsm['spatial'][:,1].min():.2f}, {data.obsm['spatial'][:,1].max():.2f}]\")\n",
    "\n",
    "# Plot spatial coordinates\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Individual plots\n",
    "for i, (data, name) in enumerate(zip(datasets, names)):\n",
    "    coords = data.obsm['spatial']\n",
    "    row = 0 if i < 2 else 1\n",
    "    col = i if i < 2 else 0\n",
    "    axes[row, col].scatter(coords[:, 0], coords[:, 1], alpha=0.6, s=20)\n",
    "    axes[row, col].set_title(f'{name}\\n{data.shape[0]} spots')\n",
    "    axes[row, col].set_xlabel('X coordinate')\n",
    "    axes[row, col].set_ylabel('Y coordinate')\n",
    "\n",
    "# Overlay plot\n",
    "colors = ['red', 'blue', 'green']\n",
    "for i, (data, name, color) in enumerate(zip(datasets, names, colors)):\n",
    "    coords = data.obsm['spatial']\n",
    "    axes[1, 1].scatter(coords[:, 0], coords[:, 1], alpha=0.5, s=15, c=color, label=name)\n",
    "axes[1, 1].set_title('All Datasets Overlay')\n",
    "axes[1, 1].set_xlabel('X coordinate')\n",
    "axes[1, 1].set_ylabel('Y coordinate')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find common genes\n",
    "all_genes = [set(data.var_names) for data in datasets]\n",
    "common_genes = sorted(list(all_genes[0] & all_genes[1] & all_genes[2]))\n",
    "print(f\"\\nCommon genes across all datasets: {len(common_genes)}\")\n",
    "\n",
    "# Coordinate overlap analysis\n",
    "print(\"\\nCoordinate Overlap Analysis:\")\n",
    "tolerance = 1.0  # Distance tolerance for \"overlap\"\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    for j in range(i+1, len(datasets)):\n",
    "        coords_i = datasets[i].obsm['spatial']\n",
    "        coords_j = datasets[j].obsm['spatial']\n",
    "        \n",
    "        # Calculate pairwise distances\n",
    "        distances = cdist(coords_i, coords_j)\n",
    "        min_distances = np.min(distances, axis=1)\n",
    "        \n",
    "        # Count overlaps within tolerance\n",
    "        overlaps = np.sum(min_distances < tolerance)\n",
    "        \n",
    "        print(f\"{names[i]} vs {names[j]}:\")\n",
    "        print(f\"  Spots within {tolerance} units: {overlaps}/{len(coords_i)} ({overlaps/len(coords_i)*100:.1f}%)\")\n",
    "        print(f\"  Mean min distance: {np.mean(min_distances):.2f}\")\n",
    "\n",
    "# Gene expression similarity for closest spots\n",
    "print(\"\\nGene Expression Similarity (for closest coordinate pairs):\")\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    for j in range(i+1, len(datasets)):\n",
    "        # Get common genes data\n",
    "        expr_i = datasets[i][:, common_genes].X\n",
    "        expr_j = datasets[j][:, common_genes].X\n",
    "        \n",
    "        if hasattr(expr_i, 'toarray'):\n",
    "            expr_i = expr_i.toarray()\n",
    "        if hasattr(expr_j, 'toarray'):\n",
    "            expr_j = expr_j.toarray()\n",
    "        \n",
    "        coords_i = datasets[i].obsm['spatial']\n",
    "        coords_j = datasets[j].obsm['spatial']\n",
    "        \n",
    "        # Find closest pairs\n",
    "        distances = cdist(coords_i, coords_j)\n",
    "        closest_j_indices = np.argmin(distances, axis=1)\n",
    "        \n",
    "        # Calculate correlations for closest pairs\n",
    "        correlations = []\n",
    "        for spot_i in range(len(expr_i)):\n",
    "            closest_j = closest_j_indices[spot_i]\n",
    "            corr = np.corrcoef(expr_i[spot_i], expr_j[closest_j])[0, 1]\n",
    "            if not np.isnan(corr):\n",
    "                correlations.append(corr)\n",
    "        \n",
    "        print(f\"{names[i]} vs {names[j]}:\")\n",
    "        print(f\"  Mean gene expression correlation: {np.mean(correlations):.4f}\")\n",
    "        print(f\"  Median correlation: {np.median(correlations):.4f}\")\n",
    "        print(f\"  Correlations > 0.5: {np.sum(np.array(correlations) > 0.5)}/{len(correlations)} ({np.sum(np.array(correlations) > 0.5)/len(correlations)*100:.1f}%)\")\n",
    "\n",
    "# Distance distribution plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "pair_idx = 0\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    for j in range(i+1, len(datasets)):\n",
    "        coords_i = datasets[i].obsm['spatial']\n",
    "        coords_j = datasets[j].obsm['spatial']\n",
    "        \n",
    "        distances = cdist(coords_i, coords_j)\n",
    "        min_distances = np.min(distances, axis=1)\n",
    "        \n",
    "        axes[pair_idx].hist(min_distances, bins=50, alpha=0.7)\n",
    "        axes[pair_idx].set_title(f'{names[i]} vs {names[j]}\\nMin Distance Distribution')\n",
    "        axes[pair_idx].set_xlabel('Distance to closest spot')\n",
    "        axes[pair_idx].set_ylabel('Frequency')\n",
    "        axes[pair_idx].axvline(tolerance, color='red', linestyle='--', label=f'Tolerance={tolerance}')\n",
    "        axes[pair_idx].legend()\n",
    "        \n",
    "        pair_idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehtesamenv_gains",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
