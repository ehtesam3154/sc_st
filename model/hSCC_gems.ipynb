{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from threadpoolctl import threadpool_limits\n",
    "threadpool_limits(limits=1, user_api='blas')\n",
    "\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import GEMS components\n",
    "from core_models_et_p1 import SharedEncoder, STStageBPrecomputer, STSetDataset\n",
    "from core_models_et_p2 import SetEncoderContext, DiffusionScoreNet, sample_sc_edm\n",
    "from core_models_et_p3 import GEMSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_process_cscc_data():\n",
    "    \"\"\"\n",
    "    Load and process the cSCC dataset with multiple ST replicates.\n",
    "    Follows exact structure from hSCC.ipynb Cell 6\n",
    "    \"\"\"\n",
    "    print(\"Loading cSCC data...\")\n",
    "    \n",
    "    # Load SC data\n",
    "    scadata = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP2.h5ad')\n",
    "    \n",
    "    # Load all 3 ST datasets\n",
    "    stadata1 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2.h5ad')\n",
    "    stadata2 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep2.h5ad')\n",
    "    stadata3 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep3.h5ad')\n",
    "    \n",
    "    # Normalize and log transform\n",
    "    for adata in [scadata, stadata1, stadata2, stadata3]:\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "    \n",
    "    # Create rough cell types for SC data\n",
    "    scadata.obs['rough_celltype'] = scadata.obs['level1_celltype'].astype(str)\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CLEC9A', 'rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CD1C', 'rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='ASDC', 'rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='PDC', 'rough_celltype'] = 'PDC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='MDSC', 'rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='LC', 'rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Mac', 'rough_celltype'] = 'Myeloid cell'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Tcell', 'rough_celltype'] = 'T cell'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype']=='TSK', 'rough_celltype'] = 'TSK'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype'].isin(['Tumor_KC_Basal', 'Tumor_KC_Diff', 'Tumor_KC_Cyc']), 'rough_celltype'] = 'NonTSK'\n",
    "    \n",
    "    return scadata, stadata1, stadata2, stadata3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_combined_st_for_diffusion(stadata1, stadata2, stadata3, scadata):\n",
    "    \"\"\"\n",
    "    Combine all ST datasets for diffusion training while maintaining gene alignment.\n",
    "    Follows exact structure from hSCC.ipynb\n",
    "    \"\"\"\n",
    "    print(\"Preparing combined ST data for diffusion training...\")\n",
    "    \n",
    "    # Get common genes between SC and all ST datasets\n",
    "    sc_genes = set(scadata.var_names)\n",
    "    st1_genes = set(stadata1.var_names)\n",
    "    st2_genes = set(stadata2.var_names)\n",
    "    st3_genes = set(stadata3.var_names)\n",
    "    \n",
    "    common_genes = sorted(list(sc_genes & st1_genes & st2_genes & st3_genes))\n",
    "    print(f\"Common genes across all datasets: {len(common_genes)}\")\n",
    "    \n",
    "    # Extract aligned expression data\n",
    "    sc_expr = scadata[:, common_genes].X\n",
    "    st1_expr = stadata1[:, common_genes].X\n",
    "    st2_expr = stadata2[:, common_genes].X\n",
    "    st3_expr = stadata3[:, common_genes].X\n",
    "    \n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(sc_expr, 'toarray'):\n",
    "        sc_expr = sc_expr.toarray()\n",
    "    if hasattr(st1_expr, 'toarray'):\n",
    "        st1_expr = st1_expr.toarray()\n",
    "    if hasattr(st2_expr, 'toarray'):\n",
    "        st2_expr = st2_expr.toarray()\n",
    "    if hasattr(st3_expr, 'toarray'):\n",
    "        st3_expr = st3_expr.toarray()\n",
    "    \n",
    "    # Get spatial coordinates\n",
    "    st1_coords = stadata1.obsm['spatial']\n",
    "    st2_coords = stadata2.obsm['spatial']\n",
    "    st3_coords = stadata3.obsm['spatial']\n",
    "    \n",
    "    # Combine ST data\n",
    "    X_st_combined = np.vstack([st1_expr, st2_expr, st3_expr])\n",
    "    Y_st_combined = np.vstack([st1_coords, st2_coords, st3_coords])\n",
    "    \n",
    "    # Create dataset labels\n",
    "    dataset_labels = np.concatenate([\n",
    "        np.zeros(st1_expr.shape[0], dtype=int),\n",
    "        np.ones(st2_expr.shape[0], dtype=int),\n",
    "        np.full(st3_expr.shape[0], 2, dtype=int)\n",
    "    ])\n",
    "    \n",
    "    st_coords_list = [st1_coords, st2_coords, st3_coords]\n",
    "    \n",
    "    return sc_expr, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tensors_for_gems(scadata, stadata1, stadata2, stadata3, common_genes):\n",
    "    \"\"\"\n",
    "    Convert AnnData to PyTorch tensors with slide IDs for GEMS training.\n",
    "    \"\"\"\n",
    "    # SC expression\n",
    "    sc_expr = scadata[:, common_genes].X\n",
    "    if hasattr(sc_expr, 'toarray'):\n",
    "        sc_expr = sc_expr.toarray()\n",
    "    \n",
    "    # ST expression and coordinates (combined)\n",
    "    st_expr_list = []\n",
    "    st_coords_list = []\n",
    "    slide_ids_list = []\n",
    "    slides_dict = {}\n",
    "    st_gene_expr_dict = {}\n",
    "    \n",
    "    stadatas = [stadata1, stadata2, stadata3]\n",
    "    \n",
    "    for slide_id, stadata in enumerate(stadatas):\n",
    "        st_expr = stadata[:, common_genes].X\n",
    "        if hasattr(st_expr, 'toarray'):\n",
    "            st_expr = st_expr.toarray()\n",
    "        \n",
    "        st_coords = stadata.obsm['spatial']\n",
    "        n_spots = st_expr.shape[0]\n",
    "        \n",
    "        st_expr_list.append(st_expr)\n",
    "        st_coords_list.append(st_coords)\n",
    "        slide_ids_list.append(np.full(n_spots, slide_id))\n",
    "        \n",
    "        # For Stage B\n",
    "        slides_dict[slide_id] = (\n",
    "            torch.tensor(st_coords, dtype=torch.float32),\n",
    "            torch.tensor(st_expr, dtype=torch.float32)\n",
    "        )\n",
    "        st_gene_expr_dict[slide_id] = torch.tensor(st_expr, dtype=torch.float32)\n",
    "    \n",
    "    # Combine\n",
    "    sc_expr = torch.tensor(sc_expr, dtype=torch.float32)\n",
    "    st_expr_combined = torch.tensor(np.vstack(st_expr_list), dtype=torch.float32)\n",
    "    st_coords_combined = torch.tensor(np.vstack(st_coords_list), dtype=torch.float32)\n",
    "    slide_ids = torch.tensor(np.concatenate(slide_ids_list), dtype=torch.long)\n",
    "    \n",
    "    return sc_expr, st_expr_combined, st_coords_combined, slide_ids, slides_dict, st_gene_expr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TRAINING PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "def train_gems_hscc(\n",
    "    sc_expr,\n",
    "    st_expr_combined,\n",
    "    st_coords_combined,\n",
    "    slide_ids,\n",
    "    slides_dict,\n",
    "    st_gene_expr_dict,\n",
    "    n_genes,\n",
    "    output_dir='gems_hscc_p2_output',\n",
    "    device='cuda'\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete GEMS training pipeline for hSCC P2 data.\n",
    "    \"\"\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GEMS hSCC P2 TRAINING PIPELINE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"SC cells: {sc_expr.shape[0]}\")\n",
    "    print(f\"ST spots (total): {st_expr_combined.shape[0]}\")\n",
    "    print(f\"Number of slides: {len(slides_dict)}\")\n",
    "    print(f\"Genes: {n_genes}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = GEMSModel(\n",
    "        n_genes=n_genes,\n",
    "        n_embedding=[512, 256, 128],\n",
    "        D_latent=16,\n",
    "        c_dim=256,\n",
    "        n_heads=4,\n",
    "        isab_m=64,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STAGE A: Train Shared Encoder\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STAGE A: Training Shared Encoder (Multi-Slide)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # model.train_stageA(\n",
    "    #     st_gene_expr=st_expr_combined.to(device),\n",
    "    #     st_coords=st_coords_combined.to(device),\n",
    "    #     sc_gene_expr=sc_expr.to(device),\n",
    "    #     slide_ids=slide_ids.to(device),\n",
    "    #     n_epochs=1200,\n",
    "    #     batch_size=256,\n",
    "    #     lr=2e-4,\n",
    "    #     sigma=None,\n",
    "    #     alpha=0.75,\n",
    "    #     mmdbatch=1000,\n",
    "    #     outf=output_dir\n",
    "    # )\n",
    "\n",
    "    model.train_stageA(\n",
    "        st_gene_expr=st_expr_combined,\n",
    "        st_coords=st_coords_combined,\n",
    "        sc_gene_expr=sc_expr,\n",
    "        slide_ids=slide_ids,\n",
    "        n_epochs=1000,\n",
    "        batch_size=256,\n",
    "        lr=0.002,  # Your old lr_e      \n",
    "        sigma=None,     \n",
    "        alpha=0.8,\n",
    "        mmdbatch=1.0,            \n",
    "        ratio_start=0.0,   \n",
    "        ratio_end=1.0,\n",
    "        \n",
    "        outf=output_dir\n",
    "    )\n",
    "        \n",
    "    # ========================================================================\n",
    "    # STAGE B: Precompute Geometric Targets\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STAGE B: Precomputing Geometric Targets\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    slides_dict_device = {\n",
    "        sid: (coords.to(device), expr.to(device))\n",
    "        for sid, (coords, expr) in slides_dict.items()\n",
    "    }\n",
    "    \n",
    "    model.train_stageB(\n",
    "        slides=slides_dict_device,\n",
    "        outdir=Path(output_dir) / 'stage_b_cache'\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STAGE C: Train Diffusion Generator\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STAGE C: Training Diffusion Generator\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    st_gene_expr_dict_device = {\n",
    "        sid: expr.to(device)\n",
    "        for sid, expr in st_gene_expr_dict.items()\n",
    "    }\n",
    "    \n",
    "    model.train_stageC(\n",
    "        st_gene_expr_dict=st_gene_expr_dict_device,\n",
    "        n_min=128,\n",
    "        n_max=512,\n",
    "        num_samples=300,\n",
    "        n_epochs=10,\n",
    "        batch_size=8,\n",
    "        lr=1e-4,\n",
    "        n_timesteps=600,\n",
    "        sigma_min=0.01,\n",
    "        sigma_max=10.0,\n",
    "        loss_weights={'alpha': 0.1, 'beta': 1.0, 'gamma': 0.5, 'eta': 0.5},\n",
    "        outf=output_dir\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    model.save(Path(output_dir) / 'gems_model_hscc_p2.pt')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# INFERENCE\n",
    "# ==============================================================================\n",
    "\n",
    "def infer_sc_coordinates(model, sc_expr, device='cuda'):\n",
    "    \"\"\"\n",
    "    Infer SC coordinates using trained GEMS model.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SC COORDINATE INFERENCE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results = model.infer_sc(\n",
    "        sc_gene_expr=sc_expr.to(device),\n",
    "        n_samples=1,\n",
    "        n_timesteps_sample=250,\n",
    "        return_coords=True\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# VISUALIZATION - Following hSCC.ipynb style\n",
    "# ==============================================================================\n",
    "\n",
    "def visualize_results_hscc(scadata, save_dir='figures'):\n",
    "    \"\"\"\n",
    "    Visualize inferred SC coordinates following hSCC.ipynb style.\n",
    "    \"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sc.settings.set_figure_params(format='svg')\n",
    "    \n",
    "    n_groups = scadata.obs[\"rough_celltype\"].nunique()\n",
    "    my_tab20 = sns.color_palette(\"tab20\", n_colors=n_groups).as_hex()\n",
    "    \n",
    "    # Plot averaged coordinates\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sc.pl.embedding(\n",
    "        scadata, \n",
    "        basis='gems_coords_avg', \n",
    "        color='rough_celltype',\n",
    "        size=85, \n",
    "        title='SC GEMS Coordinates (Averaged)',\n",
    "        palette=my_tab20, \n",
    "        legend_loc='right margin', \n",
    "        legend_fontsize=10,\n",
    "        save='_hscc_p2_gems_avg.svg'\n",
    "    )\n",
    "    \n",
    "    print(f\"Figures saved to {save_dir}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Main execution for hSCC Patient 2 training.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    output_dir = 'gems_hscc_p2_output'\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"hSCC P2 GEMS TRAINING - START\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Load and process data\n",
    "    # ========================================================================\n",
    "    print(\"\\nStep 1: Loading data...\")\n",
    "    scadata, stadata1, stadata2, stadata3 = load_and_process_cscc_data()\n",
    "    \n",
    "    print(f\"\\nData loaded successfully:\")\n",
    "    print(f\"  SC cells: {scadata.shape[0]}\")\n",
    "    print(f\"  ST slide 1: {stadata1.shape[0]} spots\")\n",
    "    print(f\"  ST slide 2: {stadata2.shape[0]} spots\")\n",
    "    print(f\"  ST slide 3: {stadata3.shape[0]} spots\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Prepare data for GEMS\n",
    "    # ========================================================================\n",
    "    print(\"\\nStep 2: Preparing data for GEMS...\")\n",
    "    sc_expr, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list = \\\n",
    "        prepare_combined_st_for_diffusion(stadata1, stadata2, stadata3, scadata)\n",
    "    \n",
    "    sc_expr_tensor, st_expr_combined, st_coords_combined, slide_ids, slides_dict, st_gene_expr_dict = \\\n",
    "        prepare_tensors_for_gems(scadata, stadata1, stadata2, stadata3, common_genes)\n",
    "    \n",
    "    n_genes = len(common_genes)\n",
    "    \n",
    "    print(f\"\\nData preparation complete:\")\n",
    "    print(f\"  SC expression: {sc_expr_tensor.shape}\")\n",
    "    print(f\"  ST expression (combined): {st_expr_combined.shape}\")\n",
    "    print(f\"  ST coordinates (combined): {st_coords_combined.shape}\")\n",
    "    print(f\"  Slide IDs: {slide_ids.shape}\")\n",
    "    print(f\"  Common genes: {n_genes}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Train GEMS\n",
    "    # ========================================================================\n",
    "    print(\"\\nStep 3: Training GEMS model...\")\n",
    "    model = train_gems_hscc(\n",
    "        sc_expr=sc_expr_tensor,\n",
    "        st_expr_combined=st_expr_combined,\n",
    "        st_coords_combined=st_coords_combined,\n",
    "        slide_ids=slide_ids,\n",
    "        slides_dict=slides_dict,\n",
    "        st_gene_expr_dict=st_gene_expr_dict,\n",
    "        n_genes=n_genes,\n",
    "        output_dir=output_dir,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Inference\n",
    "    # ========================================================================\n",
    "    print(\"\\nStep 4: Running inference on SC data...\")\n",
    "    # results = infer_sc_coordinates(model, sc_expr_tensor, device=device)\n",
    "    \n",
    "    print(\"\\nStep 4: Running inference on SC data...\")\n",
    "\n",
    "    # Clear cache before inference\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "    # Use batched inference\n",
    "    results = model.infer_sc_batched(\n",
    "        sc_gene_expr=sc_expr_tensor.to(device),\n",
    "        n_timesteps_sample=250,\n",
    "        return_coords=True,\n",
    "        batch_size=512  # Start here, reduce to 256/128 if still OOM\n",
    "    )\n",
    "\n",
    "    print(f\"\\nInference complete:\")\n",
    "    print(f\"  D_edm shape: {results['D_edm'].shape}\")\n",
    "    if 'coords_canon' in results:\n",
    "        print(f\"  Coordinates shape: {results['coords_canon'].shape}\")\n",
    "    \n",
    "    # Add coordinates to scadata\n",
    "    coords_avg = results['coords_canon'].cpu().numpy()\n",
    "    scadata.obsm['gems_coords_avg'] = coords_avg\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Visualization\n",
    "    # ========================================================================\n",
    "    print(\"\\nStep 5: Visualizing results...\")\n",
    "    visualize_results_hscc(scadata, save_dir='figures')\n",
    "    \n",
    "    # Save scadata with GEMS coordinates\n",
    "    scadata.write_h5ad(Path(output_dir) / 'scadata_with_gems_coords.h5ad')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"hSCC P2 GEMS TRAINING - COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nOutputs:\")\n",
    "    print(f\"  Model: {output_dir}/gems_model_hscc_p2.pt\")\n",
    "    print(f\"  Cached targets: {output_dir}/stage_b_cache/\")\n",
    "    print(f\"  SC data with coords: {output_dir}/scadata_with_gems_coords.h5ad\")\n",
    "    print(f\"  Figures: figures/\")\n",
    "    print(\"\\nCoordinates stored in scadata.obsm['gems_coords_avg']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== COORDINATE CHECK ===\")\n",
    "print(f\"Keys in results: {results.keys()}\")\n",
    "print(f\"D_edm shape: {results['D_edm'].shape}\")\n",
    "print(f\"D_edm min/max: {results['D_edm'].min():.4f} / {results['D_edm'].max():.4f}\")\n",
    "\n",
    "if 'coords_canon' in results:\n",
    "    coords = results['coords_canon'].cpu().numpy()\n",
    "    print(f\"\\nCoordinates shape: {coords.shape}\")\n",
    "    print(f\"X range: [{coords[:, 0].min():.4f}, {coords[:, 0].max():.4f}]\")\n",
    "    print(f\"Y range: [{coords[:, 1].min():.4f}, {coords[:, 1].max():.4f}]\")\n",
    "    print(f\"\\nFirst 5 coordinates:\\n{coords[:5]}\")\n",
    "    \n",
    "    # Save as CSV to check\n",
    "    import pandas as pd\n",
    "    pd.DataFrame(coords, columns=['X', 'Y']).to_csv('coords_check.csv', index=False)\n",
    "    print(\"\\nSaved to coords_check.csv\")\n",
    "else:\n",
    "    print(\"WARNING: No coords_canon in results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehtesamenv_gains",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
