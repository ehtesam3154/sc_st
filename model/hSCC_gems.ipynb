{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# TRAIN STAGE A: VICReg + Domain Adversary (3 ST slides + SC)\n",
    "# ===================================================================\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ehtesamul/sc_st/model')\n",
    "\n",
    "from core_models_et_p1 import SharedEncoder, train_encoder\n",
    "import utils_et as uet\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAIN STAGE A: VICReg + Domain Adversary (3 ST + SC)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def subsample_domain(X, n_max):\n",
    "    \"\"\"Subsample a domain to n_max samples.\"\"\"\n",
    "    n = X.shape[0]\n",
    "    if n <= n_max:\n",
    "        return X\n",
    "    else:\n",
    "        idx = torch.randperm(n, device=device)[:n_max]\n",
    "        return X[idx]\n",
    "\n",
    "# ===================================================================\n",
    "# 1) LOAD DATA\n",
    "# ===================================================================\n",
    "print(\"\\n--- Loading HSCC data ---\")\n",
    "scadata = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP2.h5ad')\n",
    "stadata1 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2.h5ad')\n",
    "stadata2 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep2.h5ad')\n",
    "stadata3 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep3.h5ad')\n",
    "\n",
    "# Normalize\n",
    "for adata in [scadata, stadata1, stadata2, stadata3]:\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "# Get common genes\n",
    "common = sorted(list(set(scadata.var_names) & set(stadata1.var_names) & \n",
    "                     set(stadata2.var_names) & set(stadata3.var_names)))\n",
    "n_genes = len(common)\n",
    "print(f\"✓ Common genes: {n_genes}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2) PREPARE TRAINING DATA - ALL 3 ST SLIDES + SC\n",
    "# ===================================================================\n",
    "# SC expression\n",
    "X_sc = scadata[:, common].X\n",
    "if hasattr(X_sc, \"toarray\"):\n",
    "    X_sc = X_sc.toarray()\n",
    "sc_expr = torch.tensor(X_sc, dtype=torch.float32, device=device)\n",
    "\n",
    "# ST expression from ALL 3 slides\n",
    "X_st1 = stadata1[:, common].X\n",
    "X_st2 = stadata2[:, common].X\n",
    "X_st3 = stadata3[:, common].X\n",
    "if hasattr(X_st1, \"toarray\"):\n",
    "    X_st1 = X_st1.toarray()\n",
    "if hasattr(X_st2, \"toarray\"):\n",
    "    X_st2 = X_st2.toarray()\n",
    "if hasattr(X_st3, \"toarray\"):\n",
    "    X_st3 = X_st3.toarray()\n",
    "\n",
    "st_expr = torch.tensor(np.vstack([X_st1, X_st2, X_st3]), dtype=torch.float32, device=device)\n",
    "\n",
    "# ST coordinates (required for function signature, but not used by VICReg)\n",
    "st_coords1 = stadata1.obsm['spatial']\n",
    "st_coords2 = stadata2.obsm['spatial']\n",
    "st_coords3 = stadata3.obsm['spatial']\n",
    "st_coords_raw = torch.tensor(np.vstack([st_coords1, st_coords2, st_coords3]),\n",
    "                             dtype=torch.float32, device=device)\n",
    "\n",
    "# Slide IDs - 3 ST SLIDES\n",
    "slide_ids = torch.tensor(\n",
    "    np.concatenate([\n",
    "        np.zeros(X_st1.shape[0], dtype=int),    # slide 0\n",
    "        np.ones(X_st2.shape[0], dtype=int),     # slide 1\n",
    "        np.full(X_st3.shape[0], 2, dtype=int)   # slide 2\n",
    "    ]),\n",
    "    dtype=torch.long, device=device\n",
    ")\n",
    "\n",
    "# Canonicalize coordinates (for function signature)\n",
    "st_coords, st_mu, st_scale = uet.canonicalize_st_coords_per_slide(st_coords_raw, slide_ids)\n",
    "\n",
    "print(f\"✓ SC expr: {sc_expr.shape}\")\n",
    "print(f\"✓ ST expr: {st_expr.shape}\")\n",
    "print(f\"✓ ST coords: {st_coords.shape}\")\n",
    "print(f\"✓ Slide IDs: {slide_ids.shape} (slides: {torch.unique(slide_ids).tolist()})\")\n",
    "print(f\"✓ Training will use 4 domains: ST-slide0, ST-slide1, ST-slide2, SC\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3) CREATE AND TRAIN ENCODER WITH VICREG + DOMAIN ADVERSARY\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING STAGE A ENCODER (VICReg + Domain Adversary)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "encoder_vicreg = SharedEncoder(\n",
    "    n_genes=n_genes,\n",
    "    n_embedding=[512, 256, 128],\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "encoder_vicreg, projector, discriminator, hist = train_encoder(\n",
    "    model=encoder_vicreg,\n",
    "    st_gene_expr=st_expr,\n",
    "    st_coords=st_coords,\n",
    "    sc_gene_expr=sc_expr,\n",
    "    slide_ids=slide_ids,\n",
    "    n_epochs=1000,  # Shorter to test fix quickly\n",
    "    batch_size=256,\n",
    "    lr=1e-3,\n",
    "    device=device,\n",
    "    outf='/home/ehtesamul/sc_st/model/gems_hscc_vicreg_output/run41_fixed',\n",
    "    # ========== VICReg Mode ==========\n",
    "    stageA_obj='vicreg_adv',\n",
    "    vicreg_lambda_inv=25.0,\n",
    "    vicreg_lambda_var=25.0,\n",
    "    vicreg_lambda_cov=1.0,\n",
    "    vicreg_gamma=1.0,\n",
    "    vicreg_eps=1e-4,\n",
    "    vicreg_project_dim=256,\n",
    "    vicreg_use_projector=True,\n",
    "    vicreg_float32_stats=True,\n",
    "    vicreg_ddp_gather=False,\n",
    "    # Expression augmentations (SAME)\n",
    "    aug_gene_dropout=0.5,\n",
    "    aug_gauss_std=0.05,\n",
    "    aug_scale_jitter=0.4,\n",
    "    # Domain adversary (INCREASED WEIGHT)\n",
    "    adv_slide_weight=50.0,  # ← INCREASED from 20.0\n",
    "    adv_warmup_epochs=50,\n",
    "    adv_ramp_epochs=200,\n",
    "    grl_alpha_max=1.0,\n",
    "    disc_hidden=256,\n",
    "    disc_dropout=0.1,\n",
    "    # Balanced domain sampling\n",
    "    stageA_balanced_slides=True,\n",
    "    # ========== FIX FROM RUN 1 ==========\n",
    "    adv_representation_mode='clean',\n",
    "    adv_use_layernorm=False,  # Don't use LayerNorm\n",
    "    adv_log_diagnostics=True,\n",
    "    adv_log_grad_norms=False,\n",
    "    # ========== LOCAL ALIGNMENT (optional - try without first) ==========\n",
    "    use_local_align=False,  # ← Disable for now, test adversary fix first\n",
    "    return_aux=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ VICReg Stage A training complete!\")\n",
    "\n",
    "# Save encoder\n",
    "import os\n",
    "os.makedirs('/home/ehtesamul/sc_st/model/gems_hscc_vicreg_output', exist_ok=True)\n",
    "torch.save(encoder_vicreg.state_dict(), \n",
    "           '/home/ehtesamul/sc_st/model/gems_hscc_vicreg_output/encoder_vicreg.pt')\n",
    "print(\"✓ Encoder saved to: encoder_vicreg.pt\")\n",
    "\n",
    "# ===================================================================\n",
    "# 4) EVALUATE DOMAIN MIXING (ALL 4 DOMAINS: 3 ST + SC)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION: Domain Mixing (3 ST slides + SC)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "N_MAX = 2000\n",
    "\n",
    "# Subsample all 4 domains\n",
    "X1 = torch.tensor(X_st1, dtype=torch.float32, device=device)\n",
    "X2 = torch.tensor(X_st2, dtype=torch.float32, device=device)\n",
    "X3 = torch.tensor(X_st3, dtype=torch.float32, device=device)\n",
    "X_sc_torch = torch.tensor(X_sc, dtype=torch.float32, device=device)\n",
    "\n",
    "X1_sub = subsample_domain(X1, N_MAX)\n",
    "X2_sub = subsample_domain(X2, N_MAX)\n",
    "X3_sub = subsample_domain(X3, N_MAX)\n",
    "X_sc_sub = subsample_domain(X_sc_torch, N_MAX)\n",
    "\n",
    "# Compute embeddings\n",
    "encoder_vicreg.eval()\n",
    "with torch.no_grad():\n",
    "    Z1 = encoder_vicreg(X1_sub)\n",
    "    Z2 = encoder_vicreg(X2_sub)\n",
    "    Z3 = encoder_vicreg(X3_sub)\n",
    "    Z_sc = encoder_vicreg(X_sc_sub)\n",
    "\n",
    "print(f\"Z1 (ST-slide0): {Z1.shape}\")\n",
    "print(f\"Z2 (ST-slide1): {Z2.shape}\")\n",
    "print(f\"Z3 (ST-slide2): {Z3.shape}\")\n",
    "print(f\"Z_sc (SC):      {Z_sc.shape}\")\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 1: Expression Mixing (baseline)\n",
    "# ===================================================================\n",
    "print(\"\\n[EXPR-MIXING] Expression space kNN domain distribution:\")\n",
    "X_all = torch.cat([X1_sub, X2_sub, X3_sub, X_sc_sub], dim=0)\n",
    "X_all_norm = F.normalize(X_all, dim=1)\n",
    "\n",
    "n1, n2, n3, n_sc = X1_sub.shape[0], X2_sub.shape[0], X3_sub.shape[0], X_sc_sub.shape[0]\n",
    "n_total = n1 + n2 + n3 + n_sc\n",
    "\n",
    "# Domain labels: 0=ST1, 1=ST2, 2=ST3, 3=SC\n",
    "labels = torch.cat([\n",
    "    torch.zeros(n1, dtype=torch.long, device=device),\n",
    "    torch.ones(n2, dtype=torch.long, device=device),\n",
    "    torch.full((n3,), 2, dtype=torch.long, device=device),\n",
    "    torch.full((n_sc,), 3, dtype=torch.long, device=device)\n",
    "])\n",
    "\n",
    "K_mix = 20\n",
    "\n",
    "# Check SC mixing in expression space\n",
    "sc_start = n1 + n2 + n3\n",
    "D_expr_sc = torch.cdist(X_all_norm[sc_start:], X_all_norm)\n",
    "\n",
    "# Exclude self\n",
    "for i in range(n_sc):\n",
    "    D_expr_sc[i, sc_start + i] = float('inf')\n",
    "\n",
    "_, knn_expr_sc = torch.topk(D_expr_sc, k=K_mix, dim=1, largest=False)\n",
    "\n",
    "frac_same_expr = []\n",
    "for i in range(n_sc):\n",
    "    neighbor_labels = labels[knn_expr_sc[i]]\n",
    "    frac = (neighbor_labels == 3).float().mean().item()\n",
    "    frac_same_expr.append(frac)\n",
    "\n",
    "frac_same_expr = np.array(frac_same_expr)\n",
    "base_rate = n_sc / n_total\n",
    "\n",
    "print(f\"  SC neighbors (K={K_mix}):\")\n",
    "print(f\"    Same-domain fraction: {frac_same_expr.mean():.4f}\")\n",
    "print(f\"    Base rate (chance):   {base_rate:.4f}\")\n",
    "print(f\"    → Expression space shows domain clustering (expected)\")\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 2: Z Mixing (should approach base_rate if working)\n",
    "# ===================================================================\n",
    "print(\"\\n[Z-MIXING] Embedding space kNN domain distribution:\")\n",
    "Z_all = torch.cat([Z1, Z2, Z3, Z_sc], dim=0)\n",
    "Z_all_norm = F.normalize(Z_all, dim=1)\n",
    "\n",
    "D_emb_sc = torch.cdist(Z_all_norm[sc_start:], Z_all_norm)\n",
    "\n",
    "# Exclude self\n",
    "for i in range(n_sc):\n",
    "    D_emb_sc[i, sc_start + i] = float('inf')\n",
    "\n",
    "_, knn_emb_sc = torch.topk(D_emb_sc, k=K_mix, dim=1, largest=False)\n",
    "\n",
    "frac_same_z = []\n",
    "for i in range(n_sc):\n",
    "    neighbor_labels = labels[knn_emb_sc[i]]\n",
    "    frac = (neighbor_labels == 3).float().mean().item()\n",
    "    frac_same_z.append(frac)\n",
    "\n",
    "frac_same_z = np.array(frac_same_z)\n",
    "\n",
    "print(f\"  SC neighbors (K={K_mix}):\")\n",
    "print(f\"    Same-domain fraction: {frac_same_z.mean():.4f}\")\n",
    "print(f\"    Base rate (chance):   {base_rate:.4f}\")\n",
    "\n",
    "improvement = (frac_same_expr.mean() - frac_same_z.mean()) / (frac_same_expr.mean() - base_rate)\n",
    "\n",
    "\n",
    "print(f\"  → Mixing improvement: {improvement*100:.1f}%\")\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 3: All-vs-All Domain Mixing Matrix\n",
    "# ===================================================================\n",
    "print(\"\\n[MIXING-MATRIX] Cross-domain neighbor fractions:\")\n",
    "domain_names = ['ST-slide0', 'ST-slide1', 'ST-slide2', 'SC']\n",
    "domain_sizes = [n1, n2, n3, n_sc]\n",
    "domain_starts = [0, n1, n1+n2, n1+n2+n3]\n",
    "\n",
    "print(\"\\nQuery → Neighbors (mean fraction of K=20 neighbors):\")\n",
    "print(\"         ST-s0  ST-s1  ST-s2    SC\")\n",
    "\n",
    "for query_idx, query_name in enumerate(domain_names):\n",
    "    start_idx = domain_starts[query_idx]\n",
    "    end_idx = start_idx + domain_sizes[query_idx]\n",
    "    \n",
    "    # kNN for this domain\n",
    "    D_query = torch.cdist(Z_all_norm[start_idx:end_idx], Z_all_norm)\n",
    "    \n",
    "    # Exclude self\n",
    "    for i in range(domain_sizes[query_idx]):\n",
    "        D_query[i, start_idx + i] = float('inf')\n",
    "    \n",
    "    _, knn_query = torch.topk(D_query, k=K_mix, dim=1, largest=False)\n",
    "    \n",
    "    # Count neighbors from each domain\n",
    "    fracs = []\n",
    "    for target_idx in range(4):\n",
    "        neighbor_labels = labels[knn_query.flatten()]\n",
    "        frac = (neighbor_labels == target_idx).float().mean().item()\n",
    "        fracs.append(frac)\n",
    "    \n",
    "    print(f\"{query_name:8s}  {fracs[0]:.3f}  {fracs[1]:.3f}  {fracs[2]:.3f}  {fracs[3]:.3f}\")\n",
    "\n",
    "print(\"\\nIdeal (perfect mixing): uniform fractions matching domain sizes\")\n",
    "print(f\"Expected: ST-s0={n1/n_total:.3f}, ST-s1={n2/n_total:.3f}, ST-s2={n3/n_total:.3f}, SC={n_sc/n_total:.3f}\")\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 4: Domain Linear Probe (should be near chance)\n",
    "# ===================================================================\n",
    "print(\"\\n[DOMAIN-PROBE] Linear probe accuracy on Z:\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Z_all_cpu = Z_all.cpu().numpy()\n",
    "labels_cpu = labels.cpu().numpy()\n",
    "\n",
    "probe = LogisticRegression(max_iter=1000, random_state=42)\n",
    "Z_all_n = F.normalize(Z_all, dim=1).cpu().numpy()\n",
    "probe.fit(Z_all_n, labels_cpu)\n",
    "acc = probe.score(Z_all_n, labels_cpu)\n",
    "chance = 1.0 / 4.0\n",
    "\n",
    "print(f\"  Accuracy: {acc:.4f} (chance={chance:.3f})\")\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 5: Per-dimension statistics (detect collapse)\n",
    "# ===================================================================\n",
    "print(\"\\n[COLLAPSE-CHECK] Per-dimension statistics:\")\n",
    "std_per_dim = Z_all.std(dim=0)\n",
    "print(f\"  Mean std:   {std_per_dim.mean().item():.4f}\")\n",
    "print(f\"  Min std:    {std_per_dim.min().item():.4f}\")\n",
    "print(f\"  Max std:    {std_per_dim.max().item():.4f}\")\n",
    "print(f\"  Dead dims:  {(std_per_dim < 0.1).sum().item()}/{std_per_dim.shape[0]}\")\n",
    "\n",
    "if std_per_dim.min().item() < 0.01:\n",
    "    print(\"  ⚠️  COLLAPSE DETECTED (some dims dead)\")\n",
    "elif std_per_dim.mean().item() < 0.5:\n",
    "    print(\"  ⚠️  LOW VARIANCE (increase vicreg_gamma or reduce adversary)\")\n",
    "else:\n",
    "    print(\"  ✓  Healthy variance\")\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 6: ST↔SC CORAL distance (should be low)\n",
    "# ===================================================================\n",
    "print(\"\\n[ST-SC-ALIGNMENT] CORAL distance between ST and SC:\")\n",
    "\n",
    "# Pool all ST\n",
    "Z_st_all = torch.cat([Z1, Z2, Z3], dim=0)\n",
    "\n",
    "# Compute CORAL\n",
    "mu_st = Z_st_all.mean(dim=0)\n",
    "mu_sc = Z_sc.mean(dim=0)\n",
    "mean_diff = (mu_st - mu_sc).pow(2).mean().item()\n",
    "\n",
    "z_st_c = Z_st_all - mu_st\n",
    "z_sc_c = Z_sc - mu_sc\n",
    "cov_st = (z_st_c.T @ z_st_c) / max(z_st_c.shape[0] - 1, 1)\n",
    "cov_sc = (z_sc_c.T @ z_sc_c) / max(z_sc_c.shape[0] - 1, 1)\n",
    "cov_diff = (cov_st - cov_sc).pow(2).mean().item()\n",
    "\n",
    "coral_dist = mean_diff + cov_diff\n",
    "\n",
    "print(f\"  Mean difference:       {mean_diff:.6f}\")\n",
    "print(f\"  Covariance difference: {cov_diff:.6f}\")\n",
    "print(f\"  Total CORAL distance:  {coral_dist:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# DECISIVE TEST: Train Stage A on SLIDE3 ALONE\n",
    "# ===================================================================\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ehtesamul/sc_st/model')\n",
    "\n",
    "from core_models_et_p1 import SharedEncoder, train_encoder\n",
    "import utils_et as uet\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DECISIVE TEST: Train Stage A on SLIDE3 ALONE\")\n",
    "print(\"=\"*70)\n",
    "print(\"This tests if slide3 expression→space is intrinsically learnable\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# 1) LOAD SLIDE3 DATA ONLY\n",
    "# ===================================================================\n",
    "print(\"\\n--- Loading slide3 data ---\")\n",
    "stadata3 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep3.h5ad')\n",
    "\n",
    "# Load other slides just to get common genes\n",
    "stadata1 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2.h5ad')\n",
    "stadata2 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep2.h5ad')\n",
    "scadata = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP2.h5ad')\n",
    "\n",
    "# Normalize\n",
    "for adata in [stadata1, stadata2, stadata3, scadata]:\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "# Get common genes\n",
    "common = sorted(list(set(scadata.var_names) & set(stadata1.var_names) & \n",
    "                     set(stadata2.var_names) & set(stadata3.var_names)))\n",
    "n_genes = len(common)\n",
    "print(f\"✓ Common genes: {n_genes}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2) PREPARE SLIDE3 DATA\n",
    "# ===================================================================\n",
    "# ST expression (use slide3 for both st_expr and sc_expr to avoid SC dependency)\n",
    "X_st3 = stadata3[:, common].X\n",
    "if hasattr(X_st3, \"toarray\"):\n",
    "    X_st3 = X_st3.toarray()\n",
    "st3_expr = torch.tensor(X_st3, dtype=torch.float32, device=device)\n",
    "\n",
    "# Canonicalize slide3 coords\n",
    "st3_coords_raw = torch.tensor(stadata3.obsm['spatial'], dtype=torch.float32, device=device)\n",
    "slide_ids_st3 = torch.zeros(st3_coords_raw.shape[0], dtype=torch.long, device=device)\n",
    "st3_coords, st3_mu, st3_scale = uet.canonicalize_st_coords_per_slide(st3_coords_raw, slide_ids_st3)\n",
    "\n",
    "print(f\"✓ Slide3 expr: {st3_expr.shape}\")\n",
    "print(f\"✓ Slide3 coords: {st3_coords.shape}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3) TRAIN ENCODER ON SLIDE3 ALONE\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING ON SLIDE3 ONLY (local minisets)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "encoder_st3 = SharedEncoder(\n",
    "    n_genes=n_genes,\n",
    "    n_embedding=[512, 256, 128],\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "encoder_st3 = train_encoder(\n",
    "    model=encoder_st3,\n",
    "    st_gene_expr=st3_expr,\n",
    "    st_coords=st3_coords,\n",
    "    sc_gene_expr=st3_expr,  # Use same as ST to avoid SC dependency\n",
    "    slide_ids=slide_ids_st3,\n",
    "    n_epochs=1000,\n",
    "    batch_size=256,\n",
    "    lr=1e-4,\n",
    "    sigma=None,\n",
    "    alpha=0.0,  # No MMD (only 1 slide)\n",
    "    ratio_start=0.0,\n",
    "    ratio_end=0.0,  # No circular loss\n",
    "    mmdbatch=0.0,\n",
    "    device=device,\n",
    "    outf='/home/ehtesamul/sc_st/model/gems_hscc_output_anchored_new',\n",
    "    local_miniset_mode=True,\n",
    "    n_min=128,\n",
    "    n_max=384,\n",
    "    pool_mult=4.0,\n",
    "    stochastic_tau=1.0,\n",
    "    slide_align_mode='none',  # No alignment (only 1 slide)\n",
    "    slide_align_weight=0.0,\n",
    "    use_circle=False,\n",
    "    use_mmd_sc=False,\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Slide3-only training complete!\")\n",
    "\n",
    "# ===================================================================\n",
    "# 4) EVALUATE ON SLIDE3\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION: Slide3 Learnability\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Subsample if too large\n",
    "N_MAX = 2000\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def subsample_slide(X, C, n_max):\n",
    "    n = X.shape[0]\n",
    "    if n <= n_max:\n",
    "        return X, C\n",
    "    else:\n",
    "        idx = torch.randperm(n, device=device)[:n_max]\n",
    "        return X[idx], C[idx]\n",
    "\n",
    "X3_sub, C3_sub = subsample_slide(st3_expr, st3_coords, N_MAX)\n",
    "\n",
    "# Compute embeddings\n",
    "encoder_st3.eval()\n",
    "with torch.no_grad():\n",
    "    Z3 = encoder_st3(X3_sub)\n",
    "\n",
    "print(f\"Z3 shape: {Z3.shape}\")\n",
    "\n",
    "# kNN Overlap\n",
    "def compute_knn_overlap(Z, C, k=10):\n",
    "    n = Z.shape[0]\n",
    "    D_emb = torch.cdist(Z, Z)\n",
    "    D_emb.fill_diagonal_(float('inf'))\n",
    "    _, knn_emb = torch.topk(D_emb, k=k, dim=1, largest=False)\n",
    "    \n",
    "    D_coord = torch.cdist(C, C)\n",
    "    D_coord.fill_diagonal_(float('inf'))\n",
    "    _, knn_coord = torch.topk(D_coord, k=k, dim=1, largest=False)\n",
    "    \n",
    "    overlaps = []\n",
    "    for i in range(n):\n",
    "        emb_set = set(knn_emb[i].cpu().numpy())\n",
    "        coord_set = set(knn_coord[i].cpu().numpy())\n",
    "        overlap = len(emb_set & coord_set) / k\n",
    "        overlaps.append(overlap)\n",
    "    \n",
    "    return np.mean(overlaps)\n",
    "\n",
    "overlap_k10 = compute_knn_overlap(Z3, C3_sub, k=10)\n",
    "overlap_k20 = compute_knn_overlap(Z3, C3_sub, k=20)\n",
    "\n",
    "print(f\"\\n[SLIDE3-ALONE] kNN Overlap:\")\n",
    "print(f\"  k=10: {overlap_k10:.4f}\")\n",
    "print(f\"  k=20: {overlap_k20:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# RETRAIN STAGE A: Fixed Local Minisets + Slide Alignment\n",
    "# ===================================================================\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ehtesamul/sc_st/model')\n",
    "\n",
    "from core_models_et_p1 import SharedEncoder, train_encoder\n",
    "import utils_et as uet\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RETRAIN STAGE A: FIXED Local Minisets + Slide Alignment\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# 1) LOAD DATA\n",
    "# ===================================================================\n",
    "print(\"\\n--- Loading HSCC data ---\")\n",
    "scadata = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP2.h5ad')\n",
    "stadata3 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2.h5ad')\n",
    "stadata1 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep2.h5ad')\n",
    "stadata2 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep3.h5ad')\n",
    "\n",
    "# Normalize\n",
    "for adata in [scadata, stadata1, stadata2, stadata3]:\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "# Get common genes\n",
    "common = sorted(list(set(scadata.var_names) & set(stadata1.var_names) & \n",
    "                     set(stadata2.var_names) & set(stadata3.var_names)))\n",
    "n_genes = len(common)\n",
    "print(f\"✓ Common genes: {n_genes}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2) PREPARE TRAINING DATA\n",
    "# ===================================================================\n",
    "# SC expression\n",
    "X_sc = scadata[:, common].X\n",
    "if hasattr(X_sc, \"toarray\"):\n",
    "    X_sc = X_sc.toarray()\n",
    "sc_expr = torch.tensor(X_sc, dtype=torch.float32, device=device)\n",
    "\n",
    "# ST expression from 2 training slides\n",
    "X_st1 = stadata1[:, common].X\n",
    "X_st2 = stadata2[:, common].X\n",
    "if hasattr(X_st1, \"toarray\"):\n",
    "    X_st1 = X_st1.toarray()\n",
    "if hasattr(X_st2, \"toarray\"):\n",
    "    X_st2 = X_st2.toarray()\n",
    "\n",
    "st_expr = torch.tensor(np.vstack([X_st1, X_st2]), dtype=torch.float32, device=device)\n",
    "\n",
    "# ST coordinates\n",
    "st_coords1 = stadata1.obsm['spatial']\n",
    "st_coords2 = stadata2.obsm['spatial']\n",
    "st_coords_raw = torch.tensor(np.vstack([st_coords1, st_coords2]), \n",
    "                             dtype=torch.float32, device=device)\n",
    "\n",
    "# Slide IDs\n",
    "slide_ids = torch.tensor(\n",
    "    np.concatenate([\n",
    "        np.zeros(X_st1.shape[0], dtype=int),\n",
    "        np.ones(X_st2.shape[0], dtype=int)\n",
    "    ]),\n",
    "    dtype=torch.long, device=device\n",
    ")\n",
    "\n",
    "# Canonicalize coordinates per-slide\n",
    "st_coords, st_mu, st_scale = uet.canonicalize_st_coords_per_slide(st_coords_raw, slide_ids)\n",
    "\n",
    "print(f\"✓ SC expr: {sc_expr.shape}\")\n",
    "print(f\"✓ ST expr: {st_expr.shape}\")\n",
    "print(f\"✓ ST coords: {st_coords.shape}\")\n",
    "print(f\"✓ Slide IDs: {slide_ids.shape} (slides: {torch.unique(slide_ids).tolist()})\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3) CREATE AND TRAIN ENCODER\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING STAGE A ENCODER (FIXED)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "encoder = SharedEncoder(\n",
    "    n_genes=n_genes,\n",
    "    n_embedding=[512, 256, 128],\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "encoder = train_encoder(\n",
    "    model=encoder,\n",
    "    st_gene_expr=st_expr,\n",
    "    st_coords=st_coords,\n",
    "    sc_gene_expr=sc_expr,\n",
    "    slide_ids=slide_ids,\n",
    "    n_epochs=2000,\n",
    "    batch_size=256,\n",
    "    lr=1e-4,\n",
    "    sigma=None,  # Auto-compute\n",
    "    alpha=0.0,   # Disable MMD (ST-only)\n",
    "    ratio_start=0.0,\n",
    "    ratio_end=0.0,  # Disable circular (ST-only)\n",
    "    mmdbatch=0.0,\n",
    "    device=device,\n",
    "    outf='/home/ehtesamul/sc_st/model/gems_hscc_output_anchored_new',\n",
    "    # LOCAL MINISET MODE\n",
    "    local_miniset_mode=True,\n",
    "    n_min=96,\n",
    "    n_max=384,\n",
    "    pool_mult=2.0,\n",
    "    stochastic_tau=1.0,\n",
    "    # INFONCE ALIGNMENT\n",
    "    slide_align_mode='infonce',\n",
    "    slide_align_weight=1.0,  # Start with 1.0; reduce to 0.5 if unstable\n",
    "    infonce_tau=0.07,\n",
    "    infonce_match='expr',\n",
    "    infonce_topk=5,  # Sample from top-5 expression matches\n",
    "    infonce_sym=True,\n",
    "    # DISABLE SC LOSSES\n",
    "    use_circle=False,\n",
    "    use_mmd_sc=False,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n✓ Stage A training complete!\")\n",
    "\n",
    "# Save encoder\n",
    "import os\n",
    "os.makedirs('/home/ehtesamul/sc_st/model/gems_hscc_output_anchored_new', exist_ok=True)\n",
    "torch.save(encoder.state_dict(), \n",
    "           '/home/ehtesamul/sc_st/model/gems_hscc_output_anchored_new/encoder_final_fixed.pt')\n",
    "print(\"✓ Encoder saved to: encoder_final_fixed.pt\")\n",
    "\n",
    "# ===================================================================\n",
    "# 4) EVALUATE ON ALL SLIDES\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION: Learnability + OOD (ALL SLIDES)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get canonicalized coords for all slides\n",
    "st1_coords_canon = st_coords[slide_ids == 0]\n",
    "st2_coords_canon = st_coords[slide_ids == 1]\n",
    "\n",
    "st3_coords_raw = torch.tensor(stadata3.obsm['spatial'], dtype=torch.float32, device=device)\n",
    "slide_ids_st3 = torch.zeros(st3_coords_raw.shape[0], dtype=torch.long, device=device)\n",
    "st3_coords_canon, _, _ = uet.canonicalize_st_coords_per_slide(st3_coords_raw, slide_ids_st3)\n",
    "\n",
    "# Extract expression\n",
    "X1 = torch.tensor(X_st1, dtype=torch.float32, device=device)\n",
    "X2 = torch.tensor(X_st2, dtype=torch.float32, device=device)\n",
    "\n",
    "X3 = stadata3[:, common].X\n",
    "if hasattr(X3, \"toarray\"):\n",
    "    X3 = X3.toarray()\n",
    "X3 = torch.tensor(X3, dtype=torch.float32, device=device)\n",
    "\n",
    "# Subsample\n",
    "N_MAX = 2000\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def subsample_slide(X, C, n_max):\n",
    "    n = X.shape[0]\n",
    "    if n <= n_max:\n",
    "        return X, C\n",
    "    else:\n",
    "        idx = torch.randperm(n, device=device)[:n_max]\n",
    "        return X[idx], C[idx]\n",
    "\n",
    "X1_sub, C1_sub = subsample_slide(X1, st1_coords_canon, N_MAX)\n",
    "X2_sub, C2_sub = subsample_slide(X2, st2_coords_canon, N_MAX)\n",
    "X3_sub, C3_sub = subsample_slide(X3, st3_coords_canon, N_MAX)\n",
    "\n",
    "# Compute embeddings\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    Z1 = encoder(X1_sub)\n",
    "    Z2 = encoder(X2_sub)\n",
    "    Z3 = encoder(X3_sub)\n",
    "\n",
    "print(f\"Z1 shape: {Z1.shape}\")\n",
    "print(f\"Z2 shape: {Z2.shape}\")\n",
    "print(f\"Z3 shape: {Z3.shape}\")\n",
    "\n",
    "# kNN Overlap\n",
    "def compute_knn_overlap(Z, C, k=10):\n",
    "    n = Z.shape[0]\n",
    "    D_emb = torch.cdist(Z, Z)\n",
    "    D_emb.fill_diagonal_(float('inf'))\n",
    "    _, knn_emb = torch.topk(D_emb, k=k, dim=1, largest=False)\n",
    "    \n",
    "    D_coord = torch.cdist(C, C)\n",
    "    D_coord.fill_diagonal_(float('inf'))\n",
    "    _, knn_coord = torch.topk(D_coord, k=k, dim=1, largest=False)\n",
    "    \n",
    "    overlaps = []\n",
    "    for i in range(n):\n",
    "        emb_set = set(knn_emb[i].cpu().numpy())\n",
    "        coord_set = set(knn_coord[i].cpu().numpy())\n",
    "        overlap = len(emb_set & coord_set) / k\n",
    "        overlaps.append(overlap)\n",
    "    \n",
    "    return np.mean(overlaps)\n",
    "\n",
    "print(\"\\n[EMB-LEARN-FIXED] kNN Overlap:\")\n",
    "for name, Z, C in [(\"slide1\", Z1, C1_sub), (\"slide2\", Z2, C2_sub), (\"slide3\", Z3, C3_sub)]:\n",
    "    overlap_k10 = compute_knn_overlap(Z, C, k=10)\n",
    "    overlap_k20 = compute_knn_overlap(Z, C, k=20)\n",
    "    print(f\"  {name} k=10: {overlap_k10:.4f}  k=20: {overlap_k20:.4f}\")\n",
    "\n",
    "# OOD Mixing\n",
    "Z_all = torch.cat([Z1, Z2, Z3], dim=0)\n",
    "n1, n2, n3 = Z1.shape[0], Z2.shape[0], Z3.shape[0]\n",
    "labels = torch.cat([\n",
    "    torch.zeros(n1, dtype=torch.long, device=device),\n",
    "    torch.ones(n2, dtype=torch.long, device=device),\n",
    "    torch.full((n3,), 2, dtype=torch.long, device=device)\n",
    "])\n",
    "\n",
    "K_mix = 20\n",
    "st3_start = n1 + n2\n",
    "D_st3 = torch.cdist(Z3, Z_all)\n",
    "\n",
    "for i in range(n3):\n",
    "    D_st3[i, st3_start + i] = float('inf')\n",
    "\n",
    "_, knn_st3 = torch.topk(D_st3, k=K_mix, dim=1, largest=False)\n",
    "\n",
    "frac_same = []\n",
    "for i in range(n3):\n",
    "    neighbor_labels = labels[knn_st3[i]]\n",
    "    frac = (neighbor_labels == 2).float().mean().item()\n",
    "    frac_same.append(frac)\n",
    "\n",
    "frac_same = np.array(frac_same)\n",
    "base_rate = n3 / (n1 + n2 + n3)\n",
    "\n",
    "print(f\"\\n[EMB-OOD-FIXED] K={K_mix} slide3_frac_same:\")\n",
    "print(f\"  mean={frac_same.mean():.4f} p50={np.percentile(frac_same, 50):.4f} p90={np.percentile(frac_same, 90):.4f}\")\n",
    "print(f\"  base_rate={base_rate:.4f}\")\n",
    "\n",
    "if frac_same.mean() > 0.7:\n",
    "    print(\"  ⚠️  HIGH OOD\")\n",
    "elif frac_same.mean() > base_rate * 2:\n",
    "    print(\"  ⚠️  MODERATE OOD\")\n",
    "else:\n",
    "    print(\"  ✓  WELL-MIXED\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPECTED RESULTS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"Slide1/2 overlap should RECOVER to ~0.60-0.70 (was ~0.46-0.53)\")\n",
    "print(\"Slide3 overlap depends on DECISIVE TEST result:\")\n",
    "print(\"  - If slide3-alone was high: slide3 should improve here too\")\n",
    "print(\"  - If slide3-alone was low: slide3 will stay ~0.18-0.26\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# TRAIN STAGE A: VICReg + Domain Adversary (3 ST slides + SC)\n",
    "# ===================================================================\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ehtesamul/sc_st/model')\n",
    "\n",
    "from core_models_et_p1 import SharedEncoder, train_encoder\n",
    "import utils_et as uet\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAIN STAGE A: VICReg + Domain Adversary (3 ST + SC)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def subsample_domain(X, n_max):\n",
    "    \"\"\"Subsample a domain to n_max samples.\"\"\"\n",
    "    n = X.shape[0]\n",
    "    if n <= n_max:\n",
    "        return X\n",
    "    else:\n",
    "        idx = torch.randperm(n, device=device)[:n_max]\n",
    "        return X[idx]\n",
    "\n",
    "# ===================================================================\n",
    "# 1) LOAD DATA\n",
    "# ===================================================================\n",
    "print(\"\\n--- Loading HSCC data ---\")\n",
    "scadata = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP2.h5ad')\n",
    "stadata1 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2.h5ad')\n",
    "stadata2 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep2.h5ad')\n",
    "stadata3 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep3.h5ad')\n",
    "\n",
    "# Normalize\n",
    "for adata in [scadata, stadata1, stadata2, stadata3]:\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "# Get common genes\n",
    "common = sorted(list(set(scadata.var_names) & set(stadata1.var_names) & \n",
    "                     set(stadata2.var_names) & set(stadata3.var_names)))\n",
    "n_genes = len(common)\n",
    "print(f\"✓ Common genes: {n_genes}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2) PREPARE TRAINING DATA - ALL 3 ST SLIDES + SC\n",
    "# ===================================================================\n",
    "# SC expression\n",
    "X_sc = scadata[:, common].X\n",
    "if hasattr(X_sc, \"toarray\"):\n",
    "    X_sc = X_sc.toarray()\n",
    "sc_expr = torch.tensor(X_sc, dtype=torch.float32, device=device)\n",
    "\n",
    "# ST expression from ALL 3 slides\n",
    "X_st1 = stadata1[:, common].X\n",
    "X_st2 = stadata2[:, common].X\n",
    "X_st3 = stadata3[:, common].X\n",
    "if hasattr(X_st1, \"toarray\"):\n",
    "    X_st1 = X_st1.toarray()\n",
    "if hasattr(X_st2, \"toarray\"):\n",
    "    X_st2 = X_st2.toarray()\n",
    "if hasattr(X_st3, \"toarray\"):\n",
    "    X_st3 = X_st3.toarray()\n",
    "\n",
    "st_expr = torch.tensor(np.vstack([X_st1, X_st2, X_st3]), dtype=torch.float32, device=device)\n",
    "\n",
    "# ST coordinates (required for function signature, but not used by VICReg)\n",
    "st_coords1 = stadata1.obsm['spatial']\n",
    "st_coords2 = stadata2.obsm['spatial']\n",
    "st_coords3 = stadata3.obsm['spatial']\n",
    "st_coords_raw = torch.tensor(np.vstack([st_coords1, st_coords2, st_coords3]),\n",
    "                             dtype=torch.float32, device=device)\n",
    "\n",
    "# Slide IDs - 3 ST SLIDES\n",
    "slide_ids = torch.tensor(\n",
    "    np.concatenate([\n",
    "        np.zeros(X_st1.shape[0], dtype=int),    # slide 0\n",
    "        np.ones(X_st2.shape[0], dtype=int),     # slide 1\n",
    "        np.full(X_st3.shape[0], 2, dtype=int)   # slide 2\n",
    "    ]),\n",
    "    dtype=torch.long, device=device\n",
    ")\n",
    "\n",
    "# Canonicalize coordinates (for function signature)\n",
    "st_coords, st_mu, st_scale = uet.canonicalize_st_coords_per_slide(st_coords_raw, slide_ids)\n",
    "\n",
    "print(f\"✓ SC expr: {sc_expr.shape}\")\n",
    "print(f\"✓ ST expr: {st_expr.shape}\")\n",
    "print(f\"✓ ST coords: {st_coords.shape}\")\n",
    "print(f\"✓ Slide IDs: {slide_ids.shape} (slides: {torch.unique(slide_ids).tolist()})\")\n",
    "print(f\"✓ Training will use 4 domains: ST-slide0, ST-slide1, ST-slide2, SC\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3) CREATE AND TRAIN ENCODER WITH VICREG + DOMAIN ADVERSARY\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING STAGE A ENCODER (VICReg + Domain Adversary)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "encoder_vicreg = SharedEncoder(\n",
    "    n_genes=n_genes,\n",
    "    n_embedding=[512, 256, 128],\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "encoder_vicreg, projector, discriminator, hist = train_encoder(\n",
    "    model=encoder_vicreg,\n",
    "    st_gene_expr=st_expr,\n",
    "    st_coords=st_coords,\n",
    "    sc_gene_expr=sc_expr,  # ← SC DATA INCLUDED\n",
    "    slide_ids=slide_ids,\n",
    "    n_epochs=1000,\n",
    "    batch_size=256,  # Divisible by 4 (perfect for 4 domains)\n",
    "    lr=1e-3,\n",
    "    device=device,\n",
    "    outf='/home/ehtesamul/sc_st/model/gems_hscc_vicreg_output',\n",
    "    # ========== VICReg Mode ==========\n",
    "    stageA_obj='vicreg_adv',\n",
    "    # VICReg loss weights\n",
    "    vicreg_lambda_inv=25.0,\n",
    "    vicreg_lambda_var=25.0,\n",
    "    vicreg_lambda_cov=1.0,\n",
    "    vicreg_gamma=1.0,\n",
    "    vicreg_eps=1e-4,\n",
    "    vicreg_project_dim=256,\n",
    "    vicreg_use_projector=True,\n",
    "    vicreg_float32_stats=True,\n",
    "    vicreg_ddp_gather=False,\n",
    "    # Expression augmentations\n",
    "    aug_gene_dropout=0.5,\n",
    "    aug_gauss_std=0.05,\n",
    "    aug_scale_jitter=0.4,\n",
    "    # Domain adversary\n",
    "    adv_slide_weight=20.0,\n",
    "    adv_warmup_epochs=50,\n",
    "    adv_ramp_epochs=200,\n",
    "    grl_alpha_max=1.0,\n",
    "    disc_hidden=256,\n",
    "    disc_dropout=0.1,\n",
    "    # Balanced domain sampling\n",
    "    stageA_balanced_slides=True,\n",
    "    return_aux=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ VICReg Stage A training complete!\")\n",
    "\n",
    "# Save encoder\n",
    "import os\n",
    "os.makedirs('/home/ehtesamul/sc_st/model/gems_hscc_vicreg_output', exist_ok=True)\n",
    "torch.save(encoder_vicreg.state_dict(), \n",
    "           '/home/ehtesamul/sc_st/model/gems_hscc_vicreg_output/encoder_vicreg.pt')\n",
    "print(\"✓ Encoder saved to: encoder_vicreg.pt\")\n",
    "\n",
    "# ===================================================================\n",
    "# 4) EVALUATE DOMAIN MIXING (ALL 4 DOMAINS: 3 ST + SC)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION: Domain Mixing (3 ST slides + SC)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "N_MAX = 2000\n",
    "\n",
    "# Subsample all 4 domains\n",
    "X1 = torch.tensor(X_st1, dtype=torch.float32, device=device)\n",
    "X2 = torch.tensor(X_st2, dtype=torch.float32, device=device)\n",
    "X3 = torch.tensor(X_st3, dtype=torch.float32, device=device)\n",
    "X_sc_torch = torch.tensor(X_sc, dtype=torch.float32, device=device)\n",
    "\n",
    "X1_sub = subsample_domain(X1, N_MAX)\n",
    "X2_sub = subsample_domain(X2, N_MAX)\n",
    "X3_sub = subsample_domain(X3, N_MAX)\n",
    "X_sc_sub = subsample_domain(X_sc_torch, N_MAX)\n",
    "\n",
    "# Compute embeddings\n",
    "encoder_vicreg.eval()\n",
    "with torch.no_grad():\n",
    "    Z1 = encoder_vicreg(X1_sub)\n",
    "    Z2 = encoder_vicreg(X2_sub)\n",
    "    Z3 = encoder_vicreg(X3_sub)\n",
    "    Z_sc = encoder_vicreg(X_sc_sub)\n",
    "\n",
    "print(f\"Z1 (ST-slide0): {Z1.shape}\")\n",
    "print(f\"Z2 (ST-slide1): {Z2.shape}\")\n",
    "print(f\"Z3 (ST-slide2): {Z3.shape}\")\n",
    "print(f\"Z_sc (SC):      {Z_sc.shape}\")\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 1: Expression Mixing (baseline)\n",
    "# ===================================================================\n",
    "print(\"\\n[EXPR-MIXING] Expression space kNN domain distribution:\")\n",
    "X_all = torch.cat([X1_sub, X2_sub, X3_sub, X_sc_sub], dim=0)\n",
    "X_all_norm = F.normalize(X_all, dim=1)\n",
    "\n",
    "n1, n2, n3, n_sc = X1_sub.shape[0], X2_sub.shape[0], X3_sub.shape[0], X_sc_sub.shape[0]\n",
    "n_total = n1 + n2 + n3 + n_sc\n",
    "\n",
    "# Domain labels: 0=ST1, 1=ST2, 2=ST3, 3=SC\n",
    "labels = torch.cat([\n",
    "    torch.zeros(n1, dtype=torch.long, device=device),\n",
    "    torch.ones(n2, dtype=torch.long, device=device),\n",
    "    torch.full((n3,), 2, dtype=torch.long, device=device),\n",
    "    torch.full((n_sc,), 3, dtype=torch.long, device=device)\n",
    "])\n",
    "\n",
    "K_mix = 20\n",
    "\n",
    "# Check SC mixing in expression space\n",
    "sc_start = n1 + n2 + n3\n",
    "D_expr_sc = torch.cdist(X_all_norm[sc_start:], X_all_norm)\n",
    "\n",
    "# Exclude self\n",
    "for i in range(n_sc):\n",
    "    D_expr_sc[i, sc_start + i] = float('inf')\n",
    "\n",
    "_, knn_expr_sc = torch.topk(D_expr_sc, k=K_mix, dim=1, largest=False)\n",
    "\n",
    "frac_same_expr = []\n",
    "for i in range(n_sc):\n",
    "    neighbor_labels = labels[knn_expr_sc[i]]\n",
    "    frac = (neighbor_labels == 3).float().mean().item()\n",
    "    frac_same_expr.append(frac)\n",
    "\n",
    "frac_same_expr = np.array(frac_same_expr)\n",
    "base_rate = n_sc / n_total\n",
    "\n",
    "print(f\"  SC neighbors (K={K_mix}):\")\n",
    "print(f\"    Same-domain fraction: {frac_same_expr.mean():.4f}\")\n",
    "print(f\"    Base rate (chance):   {base_rate:.4f}\")\n",
    "print(f\"    → Expression space shows domain clustering (expected)\")\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 2: Z Mixing (should approach base_rate if working)\n",
    "# ===================================================================\n",
    "print(\"\\n[Z-MIXING] Embedding space kNN domain distribution:\")\n",
    "Z_all = torch.cat([Z1, Z2, Z3, Z_sc], dim=0)\n",
    "Z_all_norm = F.normalize(Z_all, dim=1)\n",
    "\n",
    "D_emb_sc = torch.cdist(Z_all_norm[sc_start:], Z_all_norm)\n",
    "\n",
    "# Exclude self\n",
    "for i in range(n_sc):\n",
    "    D_emb_sc[i, sc_start + i] = float('inf')\n",
    "\n",
    "_, knn_emb_sc = torch.topk(D_emb_sc, k=K_mix, dim=1, largest=False)\n",
    "\n",
    "frac_same_z = []\n",
    "for i in range(n_sc):\n",
    "    neighbor_labels = labels[knn_emb_sc[i]]\n",
    "    frac = (neighbor_labels == 3).float().mean().item()\n",
    "    frac_same_z.append(frac)\n",
    "\n",
    "frac_same_z = np.array(frac_same_z)\n",
    "\n",
    "print(f\"  SC neighbors (K={K_mix}):\")\n",
    "print(f\"    Same-domain fraction: {frac_same_z.mean():.4f}\")\n",
    "print(f\"    Base rate (chance):   {base_rate:.4f}\")\n",
    "\n",
    "improvement = (frac_same_expr.mean() - frac_same_z.mean()) / (frac_same_expr.mean() - base_rate)\n",
    "\n",
    "\n",
    "print(f\"  → Mixing improvement: {improvement*100:.1f}%\")\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 3: All-vs-All Domain Mixing Matrix\n",
    "# ===================================================================\n",
    "print(\"\\n[MIXING-MATRIX] Cross-domain neighbor fractions:\")\n",
    "domain_names = ['ST-slide0', 'ST-slide1', 'ST-slide2', 'SC']\n",
    "domain_sizes = [n1, n2, n3, n_sc]\n",
    "domain_starts = [0, n1, n1+n2, n1+n2+n3]\n",
    "\n",
    "print(\"\\nQuery → Neighbors (mean fraction of K=20 neighbors):\")\n",
    "print(\"         ST-s0  ST-s1  ST-s2    SC\")\n",
    "\n",
    "for query_idx, query_name in enumerate(domain_names):\n",
    "    start_idx = domain_starts[query_idx]\n",
    "    end_idx = start_idx + domain_sizes[query_idx]\n",
    "    \n",
    "    # kNN for this domain\n",
    "    D_query = torch.cdist(Z_all_norm[start_idx:end_idx], Z_all_norm)\n",
    "    \n",
    "    # Exclude self\n",
    "    for i in range(domain_sizes[query_idx]):\n",
    "        D_query[i, start_idx + i] = float('inf')\n",
    "    \n",
    "    _, knn_query = torch.topk(D_query, k=K_mix, dim=1, largest=False)\n",
    "    \n",
    "    # Count neighbors from each domain\n",
    "    fracs = []\n",
    "    for target_idx in range(4):\n",
    "        neighbor_labels = labels[knn_query.flatten()]\n",
    "        frac = (neighbor_labels == target_idx).float().mean().item()\n",
    "        fracs.append(frac)\n",
    "    \n",
    "    print(f\"{query_name:8s}  {fracs[0]:.3f}  {fracs[1]:.3f}  {fracs[2]:.3f}  {fracs[3]:.3f}\")\n",
    "\n",
    "print(\"\\nIdeal (perfect mixing): uniform fractions matching domain sizes\")\n",
    "print(f\"Expected: ST-s0={n1/n_total:.3f}, ST-s1={n2/n_total:.3f}, ST-s2={n3/n_total:.3f}, SC={n_sc/n_total:.3f}\")\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 4: Domain Linear Probe (should be near chance)\n",
    "# ===================================================================\n",
    "print(\"\\n[DOMAIN-PROBE] Linear probe accuracy on Z:\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Z_all_cpu = Z_all.cpu().numpy()\n",
    "labels_cpu = labels.cpu().numpy()\n",
    "\n",
    "probe = LogisticRegression(max_iter=1000, random_state=42)\n",
    "Z_all_n = F.normalize(Z_all, dim=1).cpu().numpy()\n",
    "probe.fit(Z_all_n, labels_cpu)\n",
    "acc = probe.score(Z_all_n, labels_cpu)\n",
    "chance = 1.0 / 4.0\n",
    "\n",
    "print(f\"  Accuracy: {acc:.4f} (chance={chance:.3f})\")\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 5: Per-dimension statistics (detect collapse)\n",
    "# ===================================================================\n",
    "print(\"\\n[COLLAPSE-CHECK] Per-dimension statistics:\")\n",
    "std_per_dim = Z_all.std(dim=0)\n",
    "print(f\"  Mean std:   {std_per_dim.mean().item():.4f}\")\n",
    "print(f\"  Min std:    {std_per_dim.min().item():.4f}\")\n",
    "print(f\"  Max std:    {std_per_dim.max().item():.4f}\")\n",
    "print(f\"  Dead dims:  {(std_per_dim < 0.1).sum().item()}/{std_per_dim.shape[0]}\")\n",
    "\n",
    "if std_per_dim.min().item() < 0.01:\n",
    "    print(\"  ⚠️  COLLAPSE DETECTED (some dims dead)\")\n",
    "elif std_per_dim.mean().item() < 0.5:\n",
    "    print(\"  ⚠️  LOW VARIANCE (increase vicreg_gamma or reduce adversary)\")\n",
    "else:\n",
    "    print(\"  ✓  Healthy variance\")\n",
    "\n",
    "# ===================================================================\n",
    "# TEST 6: ST↔SC CORAL distance (should be low)\n",
    "# ===================================================================\n",
    "print(\"\\n[ST-SC-ALIGNMENT] CORAL distance between ST and SC:\")\n",
    "\n",
    "# Pool all ST\n",
    "Z_st_all = torch.cat([Z1, Z2, Z3], dim=0)\n",
    "\n",
    "# Compute CORAL\n",
    "mu_st = Z_st_all.mean(dim=0)\n",
    "mu_sc = Z_sc.mean(dim=0)\n",
    "mean_diff = (mu_st - mu_sc).pow(2).mean().item()\n",
    "\n",
    "z_st_c = Z_st_all - mu_st\n",
    "z_sc_c = Z_sc - mu_sc\n",
    "cov_st = (z_st_c.T @ z_st_c) / max(z_st_c.shape[0] - 1, 1)\n",
    "cov_sc = (z_sc_c.T @ z_sc_c) / max(z_sc_c.shape[0] - 1, 1)\n",
    "cov_diff = (cov_st - cov_sc).pow(2).mean().item()\n",
    "\n",
    "coral_dist = mean_diff + cov_diff\n",
    "\n",
    "print(f\"  Mean difference:       {mean_diff:.6f}\")\n",
    "print(f\"  Covariance difference: {cov_diff:.6f}\")\n",
    "print(f\"  Total CORAL distance:  {coral_dist:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# DIAGNOSTIC: Per-Domain Embedding Analysis (3 ST + SC)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DIAGNOSTIC: Per-Domain Embedding Statistics (3 ST + SC)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Compute embeddings for all 4 domains\n",
    "encoder_vicreg.eval()\n",
    "with torch.no_grad():\n",
    "    Z1_full = encoder_vicreg(torch.tensor(X_st1, dtype=torch.float32, device=device))\n",
    "    Z2_full = encoder_vicreg(torch.tensor(X_st2, dtype=torch.float32, device=device))\n",
    "    Z3_full = encoder_vicreg(torch.tensor(X_st3, dtype=torch.float32, device=device))\n",
    "    Z_sc_full = encoder_vicreg(torch.tensor(X_sc, dtype=torch.float32, device=device))\n",
    "\n",
    "# Per-domain statistics\n",
    "def domain_stats(Z, name):\n",
    "    mean = Z.mean(dim=0)\n",
    "    std = Z.std(dim=0)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Shape: {Z.shape}\")\n",
    "    print(f\"  Mean norm: {mean.norm().item():.4f}\")\n",
    "    print(f\"  Mean of stds: {std.mean().item():.4f}\")\n",
    "    print(f\"  First 5 dims mean: {mean[:5].cpu().numpy()}\")\n",
    "    return mean\n",
    "\n",
    "mean_st1 = domain_stats(Z1_full, \"ST Slide 1\")\n",
    "mean_st2 = domain_stats(Z2_full, \"ST Slide 2\")\n",
    "mean_st3 = domain_stats(Z3_full, \"ST Slide 3\")\n",
    "mean_sc = domain_stats(Z_sc_full, \"SC\")\n",
    "\n",
    "# Distance between all domain centroids\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Centroid Distances (all pairs):\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "dist_12 = (mean_st1 - mean_st2).norm().item()\n",
    "dist_13 = (mean_st1 - mean_st3).norm().item()\n",
    "dist_23 = (mean_st2 - mean_st3).norm().item()\n",
    "dist_1sc = (mean_st1 - mean_sc).norm().item()\n",
    "dist_2sc = (mean_st2 - mean_sc).norm().item()\n",
    "dist_3sc = (mean_st3 - mean_sc).norm().item()\n",
    "\n",
    "print(f\"  ST1 ↔ ST2:  {dist_12:.4f}\")\n",
    "print(f\"  ST1 ↔ ST3:  {dist_13:.4f}\")\n",
    "print(f\"  ST2 ↔ ST3:  {dist_23:.4f}\")\n",
    "print(f\"  ST1 ↔ SC:   {dist_1sc:.4f}\")\n",
    "print(f\"  ST2 ↔ SC:   {dist_2sc:.4f}\")\n",
    "print(f\"  ST3 ↔ SC:   {dist_3sc:.4f}\")\n",
    "\n",
    "# Within-ST vs ST-SC distances\n",
    "st_dists = [dist_12, dist_13, dist_23]\n",
    "st_sc_dists = [dist_1sc, dist_2sc, dist_3sc]\n",
    "\n",
    "print(f\"\\nWithin-ST distances:\")\n",
    "print(f\"  Mean: {np.mean(st_dists):.4f}\")\n",
    "print(f\"  Max:  {np.max(st_dists):.4f}\")\n",
    "\n",
    "print(f\"\\nST ↔ SC distances:\")\n",
    "print(f\"  Mean: {np.mean(st_sc_dists):.4f}\")\n",
    "print(f\"  Max:  {np.max(st_sc_dists):.4f}\")\n",
    "\n",
    "if np.mean(st_sc_dists) > 2.0 * np.mean(st_dists):\n",
    "    print(\"  ⚠️  SC centroid is FAR from ST centroids (poor alignment!)\")\n",
    "elif np.mean(st_sc_dists) > 1.5 * np.mean(st_dists):\n",
    "    print(\"  ⚠️  SC centroid is separated from ST (moderate misalignment)\")\n",
    "else:\n",
    "    print(\"  ✓  SC and ST centroids are reasonably close (good alignment!)\")\n",
    "\n",
    "# ===================================================================\n",
    "# Linear Separability Check - ALL 4 DOMAINS\n",
    "# ===================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Linear Separability Test (4-class: ST1, ST2, ST3, SC)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Subsample for faster probe (optional)\n",
    "N_PROBE = 2000\n",
    "Z1_probe = Z1_full if Z1_full.shape[0] <= N_PROBE else Z1_full[torch.randperm(Z1_full.shape[0])[:N_PROBE]]\n",
    "Z2_probe = Z2_full if Z2_full.shape[0] <= N_PROBE else Z2_full[torch.randperm(Z2_full.shape[0])[:N_PROBE]]\n",
    "Z3_probe = Z3_full if Z3_full.shape[0] <= N_PROBE else Z3_full[torch.randperm(Z3_full.shape[0])[:N_PROBE]]\n",
    "Z_sc_probe = Z_sc_full if Z_sc_full.shape[0] <= N_PROBE else Z_sc_full[torch.randperm(Z_sc_full.shape[0])[:N_PROBE]]\n",
    "\n",
    "Z_all_probe = torch.cat([Z1_probe, Z2_probe, Z3_probe, Z_sc_probe], dim=0)\n",
    "labels_probe = torch.cat([\n",
    "    torch.zeros(Z1_probe.shape[0], dtype=torch.long),\n",
    "    torch.ones(Z2_probe.shape[0], dtype=torch.long),\n",
    "    torch.full((Z3_probe.shape[0],), 2, dtype=torch.long),\n",
    "    torch.full((Z_sc_probe.shape[0],), 3, dtype=torch.long)\n",
    "])\n",
    "\n",
    "Z_all_probe_np = Z_all_probe.cpu().numpy()\n",
    "labels_probe_np = labels_probe.cpu().numpy()\n",
    "\n",
    "# Train probe with balanced class weights\n",
    "probe = LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced')\n",
    "probe.fit(Z_all_probe_np, labels_probe_np)\n",
    "\n",
    "# Predictions\n",
    "pred = probe.predict(Z_all_probe_np)\n",
    "\n",
    "# Metrics\n",
    "acc = probe.score(Z_all_probe_np, labels_probe_np)\n",
    "bal_acc = balanced_accuracy_score(labels_probe_np, pred)\n",
    "chance = 0.25\n",
    "\n",
    "print(f\"  Standard Accuracy:  {acc:.4f}\")\n",
    "print(f\"  Balanced Accuracy:  {bal_acc:.4f} (chance={chance:.3f})\")\n",
    "\n",
    "if bal_acc > 0.45:\n",
    "    print(\"  ⚠️  Domains are VERY separable (adversary failed!)\")\n",
    "elif bal_acc > 0.35:\n",
    "    print(\"  ⚠️  Domains are moderately separable\")\n",
    "else:\n",
    "    print(\"  ✓  Domains are well-mixed (near chance!)\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(labels_probe_np, pred)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(f\"\\nConfusion Matrix (normalized by row):\")\n",
    "print(\"       ST1   ST2   ST3    SC\")\n",
    "for i, label in enumerate(['ST1', 'ST2', 'ST3', 'SC ']):\n",
    "    row_str = f\"{label}  \"\n",
    "    for j in range(4):\n",
    "        row_str += f\"{cm_norm[i, j]:.3f} \"\n",
    "    print(row_str)\n",
    "\n",
    "# ===================================================================\n",
    "# PCA Visualization - ALL 4 DOMAINS\n",
    "# ===================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PCA Visualization\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Subsample for cleaner visualization\n",
    "N_VIS = 3000\n",
    "Z1_vis = Z1_full if Z1_full.shape[0] <= N_VIS else Z1_full[torch.randperm(Z1_full.shape[0])[:N_VIS]]\n",
    "Z2_vis = Z2_full if Z2_full.shape[0] <= N_VIS else Z2_full[torch.randperm(Z2_full.shape[0])[:N_VIS]]\n",
    "Z3_vis = Z3_full if Z3_full.shape[0] <= N_VIS else Z3_full[torch.randperm(Z3_full.shape[0])[:N_VIS]]\n",
    "Z_sc_vis = Z_sc_full if Z_sc_full.shape[0] <= N_VIS else Z_sc_full[torch.randperm(Z_sc_full.shape[0])[:N_VIS]]\n",
    "\n",
    "Z_all_vis = torch.cat([Z1_vis, Z2_vis, Z3_vis, Z_sc_vis], dim=0).cpu().numpy()\n",
    "labels_vis = torch.cat([\n",
    "    torch.zeros(Z1_vis.shape[0]),\n",
    "    torch.ones(Z2_vis.shape[0]),\n",
    "    torch.full((Z3_vis.shape[0],), 2),\n",
    "    torch.full((Z_sc_vis.shape[0],), 3)\n",
    "]).cpu().numpy()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "Z_pca = pca.fit_transform(Z_all_vis)\n",
    "\n",
    "# Create figure with 2 subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: All 4 domains with different colors\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12']  # red, blue, green, orange\n",
    "labels_str = ['ST Slide 1', 'ST Slide 2', 'ST Slide 3', 'SC']\n",
    "markers = ['o', 'o', 'o', 's']  # circles for ST, square for SC\n",
    "\n",
    "for i in range(4):\n",
    "    mask = labels_vis == i\n",
    "    axes[0].scatter(Z_pca[mask, 0], Z_pca[mask, 1], \n",
    "                    c=colors[i], label=labels_str[i], \n",
    "                    alpha=0.4, s=15, marker=markers[i], edgecolors='none')\n",
    "\n",
    "axes[0].legend(loc='best', framealpha=0.9)\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)\n",
    "axes[0].set_title('All 4 Domains (3 ST + SC)', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: ST vs SC only (binary view)\n",
    "is_st = labels_vis < 3\n",
    "axes[1].scatter(Z_pca[is_st, 0], Z_pca[is_st, 1], \n",
    "                c='#3498db', label='ST (all slides)', \n",
    "                alpha=0.4, s=15, edgecolors='none')\n",
    "axes[1].scatter(Z_pca[~is_st, 0], Z_pca[~is_st, 1], \n",
    "                c='#f39c12', label='SC', \n",
    "                alpha=0.4, s=20, marker='s', edgecolors='none')\n",
    "\n",
    "axes[1].legend(loc='best', framealpha=0.9)\n",
    "axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)\n",
    "axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)\n",
    "axes[1].set_title('ST vs SC (Binary View)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('/home/ehtesamul/sc_st/model/gems_hscc_vicreg_output/pca_embeddings_4domains.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ PCA shows explained variance: PC1={pca.explained_variance_ratio_[0]*100:.1f}%, PC2={pca.explained_variance_ratio_[1]*100:.1f}%\")\n",
    "\n",
    "# ===================================================================\n",
    "# FINAL DIAGNOSTIC SUMMARY\n",
    "# ===================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"DIAGNOSTIC SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"✓ Within-ST centroid dist:  {np.mean(st_dists):.4f}\")\n",
    "print(f\"✓ ST-SC centroid dist:      {np.mean(st_sc_dists):.4f}\")\n",
    "print(f\"✓ Balanced accuracy (probe): {bal_acc:.4f} (chance=0.25)\")\n",
    "\n",
    "if np.mean(st_sc_dists) < 1.5 * np.mean(st_dists) and bal_acc < 0.35:\n",
    "    print(\"\\n🎉 EXCELLENT: SC is well-aligned with ST!\")\n",
    "elif np.mean(st_sc_dists) < 2.0 * np.mean(st_dists) and bal_acc < 0.40:\n",
    "    print(\"\\n✓ GOOD: Moderate alignment, but could improve\")\n",
    "else:\n",
    "    print(\"\\n⚠️  POOR: SC is still separated from ST (needs tuning)\")\n",
    "    print(\"\\nSuggestions:\")\n",
    "    print(\"  - Switch to 2-class adversary (ST vs SC)\")\n",
    "    print(\"  - Add MMD loss with higher weight\")\n",
    "    print(\"  - Increase disc_steps from 10 → 20\")\n",
    "    print(\"  - Reduce adv_slide_weight from 20 → 10\")\n",
    "    \n",
    "print(f\"{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "def make_repr(Z, mode: str):\n",
    "    # mode: 'raw', 'ln', 'ln_norm', 'norm'\n",
    "    if mode == 'raw':\n",
    "        return Z\n",
    "    if mode == 'norm':\n",
    "        return F.normalize(Z, dim=1)\n",
    "    if mode == 'ln':\n",
    "        return F.layer_norm(Z, (Z.shape[1],))\n",
    "    if mode == 'ln_norm':\n",
    "        Z = F.layer_norm(Z, (Z.shape[1],))\n",
    "        return F.normalize(Z, dim=1)\n",
    "    raise ValueError(mode)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_knn_and_probe(Z1, Z2, Z3, Zsc, K=20, mode='ln_norm'):\n",
    "    # Build representations\n",
    "    Z1r = make_repr(Z1, mode)\n",
    "    Z2r = make_repr(Z2, mode)\n",
    "    Z3r = make_repr(Z3, mode)\n",
    "    Zscr = make_repr(Zsc, mode)\n",
    "\n",
    "    Z_all = torch.cat([Z1r, Z2r, Z3r, Zscr], dim=0)\n",
    "    Z_all = make_repr(Z_all, mode)  # ensure consistent transform\n",
    "\n",
    "    n1, n2, n3, nsc = Z1r.shape[0], Z2r.shape[0], Z3r.shape[0], Zscr.shape[0]\n",
    "    sc_start = n1 + n2 + n3\n",
    "    n_total = n1 + n2 + n3 + nsc\n",
    "\n",
    "    labels = torch.cat([\n",
    "        torch.zeros(n1, dtype=torch.long, device=Z_all.device),\n",
    "        torch.ones(n2, dtype=torch.long, device=Z_all.device),\n",
    "        torch.full((n3,), 2, dtype=torch.long, device=Z_all.device),\n",
    "        torch.full((nsc,), 3, dtype=torch.long, device=Z_all.device),\n",
    "    ])\n",
    "\n",
    "    # --- kNN: query SC vs all ---\n",
    "    D = torch.cdist(Z_all[sc_start:], Z_all)\n",
    "    for i in range(nsc):\n",
    "        D[i, sc_start + i] = float('inf')\n",
    "\n",
    "    _, knn = torch.topk(D, k=K, dim=1, largest=False)\n",
    "\n",
    "    frac_same_sc = (labels[knn] == 3).float().mean().item()\n",
    "    base_rate_sc = nsc / n_total\n",
    "\n",
    "    # --- probe: balanced accuracy (important because SC is ~50%) ---\n",
    "    Z_np = Z_all.cpu().numpy()\n",
    "    y_np = labels.cpu().numpy()\n",
    "\n",
    "    clf = LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced')\n",
    "    clf.fit(Z_np, y_np)\n",
    "    pred = clf.predict(Z_np)\n",
    "    bal_acc = balanced_accuracy_score(y_np, pred)\n",
    "    cm = confusion_matrix(y_np, pred, labels=[0,1,2,3])\n",
    "    cmn = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    pred = clf.predict(Z_np)  # from Exp 1\n",
    "    print(\"Accuracy:\", accuracy_score(y_np, pred))\n",
    "    print(\"Balanced accuracy:\", balanced_accuracy_score(y_np, pred))\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"mode\": mode,\n",
    "        \"sc_knn_same\": frac_same_sc,\n",
    "        \"sc_base_rate\": base_rate_sc,\n",
    "        \"probe_bal_acc\": bal_acc,\n",
    "        \"cm_norm\": cmn\n",
    "    }\n",
    "\n",
    "# ---- compute embeddings once (full) ----\n",
    "encoder_vicreg.eval()\n",
    "with torch.no_grad():\n",
    "    Z1_full = encoder_vicreg(X1)\n",
    "    Z2_full = encoder_vicreg(X2)\n",
    "    Z3_full = encoder_vicreg(X3)\n",
    "    Zsc_full = encoder_vicreg(torch.tensor(X_sc, dtype=torch.float32, device=device))\n",
    "\n",
    "for mode in [\"raw\", \"norm\", \"ln\", \"ln_norm\"]:\n",
    "    out = eval_knn_and_probe(Z1_full, Z2_full, Z3_full, Zsc_full, K=20, mode=mode)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODE:\", out[\"mode\"])\n",
    "    print(f\"SC kNN same-domain: {out['sc_knn_same']:.4f} | base-rate: {out['sc_base_rate']:.4f}\")\n",
    "    print(f\"Probe balanced acc: {out['probe_bal_acc']:.4f} (chance=0.25)\")\n",
    "    print(\"Confusion matrix (row-normalized) rows=[ST1,ST2,ST3,SC]:\")\n",
    "    print(np.round(out[\"cm_norm\"], 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def disc_eval(discriminator, Z, y, mode=\"ln_norm\"):\n",
    "    # mode should mirror what discriminator saw during training:\n",
    "    # in your code: discriminator sees F.normalize(z_bar_raw) [file:3]\n",
    "    if mode == \"norm\":\n",
    "        Z_in = F.normalize(Z, dim=1)\n",
    "    elif mode == \"ln_norm\":\n",
    "        Z_in = F.layer_norm(Z, (Z.shape[1],))\n",
    "        Z_in = F.normalize(Z_in, dim=1)\n",
    "    else:\n",
    "        raise ValueError(mode)\n",
    "\n",
    "    logits = discriminator(Z_in)\n",
    "    pred = logits.argmax(dim=1)\n",
    "    acc = (pred == y).float().mean().item()\n",
    "    return acc, logits.softmax(dim=1).mean(dim=0).cpu().numpy()\n",
    "\n",
    "# Build a combined eval set\n",
    "Z_all = torch.cat([Z1_full, Z2_full, Z3_full, Zsc_full], dim=0)\n",
    "y_all = torch.cat([\n",
    "    torch.zeros(Z1_full.shape[0], dtype=torch.long, device=device),\n",
    "    torch.ones(Z2_full.shape[0], dtype=torch.long, device=device),\n",
    "    torch.full((Z3_full.shape[0],), 2, dtype=torch.long, device=device),\n",
    "    torch.full((Zsc_full.shape[0],), 3, dtype=torch.long, device=device),\n",
    "])\n",
    "\n",
    "acc_norm, mean_p_norm = disc_eval(discriminator, Z_all, y_all, mode=\"norm\")\n",
    "acc_ln_norm, mean_p_ln_norm = disc_eval(discriminator, Z_all, y_all, mode=\"ln_norm\")\n",
    "\n",
    "print(\"Disc acc (norm):    \", acc_norm)\n",
    "print(\"Mean predicted probs (norm):   \", np.round(mean_p_norm, 3))\n",
    "print(\"Disc acc (ln_norm): \", acc_ln_norm)\n",
    "print(\"Mean predicted probs (ln_norm):\", np.round(mean_p_ln_norm, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT 1: SC → ST Distance Ratio\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use the embeddings we already have\n",
    "encoder_vicreg.eval()\n",
    "with torch.no_grad():\n",
    "    Z1 = encoder_vicreg(X1)\n",
    "    Z2 = encoder_vicreg(X2)\n",
    "    Z3 = encoder_vicreg(X3)\n",
    "    Zsc = encoder_vicreg(torch.tensor(X_sc, dtype=torch.float32, device=device))\n",
    "\n",
    "# Subsample for speed\n",
    "N_TEST = 2000\n",
    "if Zsc.shape[0] > N_TEST:\n",
    "    idx = torch.randperm(Zsc.shape[0])[:N_TEST]\n",
    "    Zsc_test = Zsc[idx]\n",
    "else:\n",
    "    Zsc_test = Zsc\n",
    "\n",
    "# Concatenate all ST\n",
    "Zst_all = torch.cat([Z1, Z2, Z3], dim=0)\n",
    "\n",
    "# Subsample ST too\n",
    "if Zst_all.shape[0] > N_TEST * 2:\n",
    "    idx_st = torch.randperm(Zst_all.shape[0])[:N_TEST * 2]\n",
    "    Zst_test = Zst_all[idx_st]\n",
    "else:\n",
    "    Zst_test = Zst_all\n",
    "\n",
    "# Normalize (this is what you used in kNN)\n",
    "Zsc_norm = F.normalize(Zsc_test, dim=1)\n",
    "Zst_norm = F.normalize(Zst_test, dim=1)\n",
    "Zsc_pool_norm = F.normalize(Zsc_test, dim=1)  # for SC→SC\n",
    "\n",
    "# Distance from each SC to nearest ST\n",
    "D_sc_to_st = torch.cdist(Zsc_norm, Zst_norm)\n",
    "dist_to_nearest_st = D_sc_to_st.min(dim=1)[0]\n",
    "\n",
    "# Distance from each SC to nearest other SC\n",
    "D_sc_to_sc = torch.cdist(Zsc_norm, Zsc_pool_norm)\n",
    "# Mask self\n",
    "for i in range(D_sc_to_sc.shape[0]):\n",
    "    if i < D_sc_to_sc.shape[1]:\n",
    "        D_sc_to_sc[i, i] = float('inf')\n",
    "dist_to_nearest_sc = D_sc_to_sc.min(dim=1)[0]\n",
    "\n",
    "# Ratio\n",
    "ratio = (dist_to_nearest_st / (dist_to_nearest_sc + 1e-8)).cpu().numpy()\n",
    "\n",
    "print(f\"SC → nearest ST distance:  {dist_to_nearest_st.mean().item():.4f} ± {dist_to_nearest_st.std().item():.4f}\")\n",
    "print(f\"SC → nearest SC distance:  {dist_to_nearest_sc.mean().item():.4f} ± {dist_to_nearest_sc.std().item():.4f}\")\n",
    "print(f\"Ratio (ST/SC):             {ratio.mean():.4f} ± {ratio.std():.4f}\")\n",
    "print(f\"Median ratio:              {np.median(ratio):.4f}\")\n",
    "\n",
    "if ratio.mean() > 2.0:\n",
    "    print(\"\\n⚠️  SC is FAR from ST (ratio > 2 means SC forms tight cluster away from ST)\")\n",
    "elif ratio.mean() > 1.3:\n",
    "    print(\"\\n⚠️  SC is moderately separated from ST\")\n",
    "else:\n",
    "    print(\"\\n✓  SC and ST are locally overlapping (ratio near 1)\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT 2: Binary Probe (ST vs SC)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build binary labels: 0 = ST, 1 = SC\n",
    "n1, n2, n3 = Z1.shape[0], Z2.shape[0], Z3.shape[0]\n",
    "nsc = Zsc.shape[0]\n",
    "\n",
    "Z_all = torch.cat([Z1, Z2, Z3, Zsc], dim=0)\n",
    "y_binary = torch.cat([\n",
    "    torch.zeros(n1 + n2 + n3, dtype=torch.long),\n",
    "    torch.ones(nsc, dtype=torch.long)\n",
    "])\n",
    "\n",
    "Z_np = F.normalize(Z_all, dim=1).cpu().numpy()\n",
    "y_np = y_binary.cpu().numpy()\n",
    "\n",
    "# Train probe with SAGA solver (more stable)\n",
    "clf = LogisticRegression(max_iter=5000, random_state=42, \n",
    "                         class_weight='balanced', solver='saga')\n",
    "clf.fit(Z_np, y_np)\n",
    "\n",
    "# Predictions\n",
    "pred = clf.predict(Z_np)\n",
    "pred_proba = clf.predict_proba(Z_np)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "bal_acc = balanced_accuracy_score(y_np, pred)\n",
    "auc = roc_auc_score(y_np, pred_proba)\n",
    "\n",
    "# Per-class accuracy\n",
    "acc_st = (pred[y_np == 0] == 0).mean()\n",
    "acc_sc = (pred[y_np == 1] == 1).mean()\n",
    "\n",
    "print(f\"Balanced Accuracy: {bal_acc:.4f} (chance=0.50)\")\n",
    "print(f\"ROC-AUC:           {auc:.4f} (chance=0.50)\")\n",
    "print(f\"ST accuracy:       {acc_st:.4f} (how many ST predicted as ST)\")\n",
    "print(f\"SC accuracy:       {acc_sc:.4f} (how many SC predicted as SC)\")\n",
    "\n",
    "if bal_acc > 0.85:\n",
    "    print(\"\\n⚠️  ST and SC are VERY separable (adversary failed)\")\n",
    "elif bal_acc > 0.70:\n",
    "    print(\"\\n⚠️  ST and SC are moderately separable\")\n",
    "elif bal_acc > 0.60:\n",
    "    print(\"\\n⚠️  ST and SC are slightly separable\")\n",
    "else:\n",
    "    print(\"\\n✓  ST and SC are mixed (near chance)\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT 3: Discriminator Eval (2-class: ST vs SC)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build binary labels\n",
    "y_binary_disc = torch.cat([\n",
    "    torch.zeros(n1 + n2 + n3, dtype=torch.long, device=device),\n",
    "    torch.ones(nsc, dtype=torch.long, device=device)\n",
    "])\n",
    "\n",
    "# Check discriminator output shape\n",
    "with torch.no_grad():\n",
    "    test_out = discriminator(F.normalize(Z1[:10], dim=1))\n",
    "    n_classes = test_out.shape[1]\n",
    "    print(f\"Discriminator outputs {n_classes} classes\")\n",
    "\n",
    "if n_classes == 2:\n",
    "    print(\"✓ Discriminator is 2-class (ST vs SC)\")\n",
    "    \n",
    "    # Evaluate on normalized embeddings (what training used)\n",
    "    Z_all_norm = F.normalize(Z_all, dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = discriminator(Z_all_norm)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        probs = logits.softmax(dim=1)\n",
    "    \n",
    "    acc = (pred == y_binary_disc).float().mean().item()\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    acc_st = (pred[y_binary_disc == 0] == 0).float().mean().item()\n",
    "    acc_sc = (pred[y_binary_disc == 1] == 1).float().mean().item()\n",
    "    \n",
    "    # Mean predicted probabilities\n",
    "    mean_probs = probs.mean(dim=0).cpu().numpy()\n",
    "    \n",
    "    print(f\"\\nDiscriminator Accuracy: {acc:.4f}\")\n",
    "    print(f\"  ST correctly classified: {acc_st:.4f}\")\n",
    "    print(f\"  SC correctly classified: {acc_sc:.4f}\")\n",
    "    print(f\"  Mean predicted probs [ST, SC]: {np.round(mean_probs, 3)}\")\n",
    "    \n",
    "    if acc > 0.85:\n",
    "        print(\"\\n⚠️  Discriminator EASILY separates ST/SC (adversary didn't work)\")\n",
    "    elif acc > 0.70:\n",
    "        print(\"\\n⚠️  Discriminator can separate ST/SC (adversary partially worked)\")\n",
    "    elif acc > 0.60:\n",
    "        print(\"\\n✓  Discriminator is somewhat confused\")\n",
    "    else:\n",
    "        print(\"\\n✓  Discriminator is very confused (near chance)\")\n",
    "else:\n",
    "    print(f\"⚠️  Discriminator is {n_classes}-class (not binary)\")\n",
    "    print(\"Cannot run binary eval - discriminator architecture mismatch\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT 4: Discriminator sanity check on training-style batch\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build the exact same pooled data you use in training\n",
    "X_ssl_eval = torch.cat([st_expr, sc_expr], dim=0)\n",
    "y_ssl_eval = torch.cat([\n",
    "    torch.zeros(st_expr.shape[0], dtype=torch.long, device=device),  # ST=0\n",
    "    torch.ones(sc_expr.shape[0], dtype=torch.long, device=device)    # SC=1\n",
    "], dim=0)\n",
    "\n",
    "# Take a balanced batch\n",
    "B = 512\n",
    "idx_st = torch.randperm(st_expr.shape[0], device=device)[:B//2]\n",
    "idx_sc = torch.randperm(sc_expr.shape[0], device=device)[:B//2] + st_expr.shape[0]\n",
    "idx = torch.cat([idx_st, idx_sc], dim=0)\n",
    "idx = idx[torch.randperm(idx.shape[0], device=device)]\n",
    "\n",
    "Xb = X_ssl_eval[idx]\n",
    "yb = y_ssl_eval[idx]\n",
    "\n",
    "encoder_vicreg.eval()\n",
    "discriminator.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = encoder_vicreg(Xb)\n",
    "    z_in = F.normalize(z, dim=1)   # training-style discriminator input\n",
    "    logits = discriminator(z_in)\n",
    "    pred = logits.argmax(dim=1)\n",
    "    acc = (pred == yb).float().mean().item()\n",
    "    acc_st = (pred[yb==0] == 0).float().mean().item()\n",
    "    acc_sc = (pred[yb==1] == 1).float().mean().item()\n",
    "    pmean = logits.softmax(dim=1).mean(dim=0).cpu().numpy()\n",
    "\n",
    "print(f\"Batch disc acc: {acc:.4f} | ST acc: {acc_st:.4f} | SC acc: {acc_sc:.4f}\")\n",
    "print(\"Mean predicted probs [ST, SC]:\", np.round(pmean, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT 5: SC kNN ST-neighbor rate\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "K = 20\n",
    "Zst = torch.cat([Z1_full, Z2_full, Z3_full], dim=0)\n",
    "Zsc = Zsc_full\n",
    "\n",
    "Zst_n = F.normalize(Zst, dim=1)\n",
    "Zsc_n = F.normalize(Zsc, dim=1)\n",
    "\n",
    "Z_all = torch.cat([Zst_n, Zsc_n], dim=0)\n",
    "labels = torch.cat([\n",
    "    torch.zeros(Zst_n.shape[0], dtype=torch.long, device=device),  # ST=0\n",
    "    torch.ones(Zsc_n.shape[0], dtype=torch.long, device=device)    # SC=1\n",
    "], dim=0)\n",
    "\n",
    "sc_start = Zst_n.shape[0]\n",
    "D = torch.cdist(Z_all[sc_start:], Z_all)\n",
    "\n",
    "# exclude self among SC points\n",
    "for i in range(Zsc_n.shape[0]):\n",
    "    D[i, sc_start + i] = float('inf')\n",
    "\n",
    "_, knn = torch.topk(D, k=K, largest=False, dim=1)\n",
    "\n",
    "frac_st_neighbors = (labels[knn] == 0).float().mean().item()\n",
    "print(f\"SC → fraction of ST neighbors (K={K}): {frac_st_neighbors:.4f}\")\n",
    "print(f\"SC base-rate ST fraction:              {Zst_n.shape[0] / (Zst_n.shape[0] + Zsc_n.shape[0]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT 6: Density-controlled kNN (downsample SC)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "Zst = torch.cat([Z1_full, Z2_full, Z3_full], dim=0)\n",
    "Zsc = Zsc_full\n",
    "\n",
    "# Downsample SC to match ST count\n",
    "n_st = Zst.shape[0]\n",
    "n_sc = Zsc.shape[0]\n",
    "m = min(n_st, n_sc)\n",
    "\n",
    "idx_st = torch.randperm(n_st, device=device)[:m]\n",
    "idx_sc = torch.randperm(n_sc, device=device)[:m]\n",
    "\n",
    "Zst_m = F.normalize(Zst[idx_st], dim=1)\n",
    "Zsc_m = F.normalize(Zsc[idx_sc], dim=1)\n",
    "\n",
    "Z_all = torch.cat([Zst_m, Zsc_m], dim=0)\n",
    "labels = torch.cat([\n",
    "    torch.zeros(m, dtype=torch.long, device=device),  # ST=0\n",
    "    torch.ones(m, dtype=torch.long, device=device)    # SC=1\n",
    "], dim=0)\n",
    "\n",
    "K = 20\n",
    "sc_start = m\n",
    "D = torch.cdist(Z_all[sc_start:], Z_all)\n",
    "for i in range(m):\n",
    "    D[i, sc_start + i] = float('inf')\n",
    "\n",
    "_, knn = torch.topk(D, k=K, dim=1, largest=False)\n",
    "frac_st_neighbors = (labels[knn] == 0).float().mean().item()\n",
    "\n",
    "print(f\"Balanced pool size: ST={m}, SC={m}\")\n",
    "print(f\"SC → fraction of ST neighbors (K={K}): {frac_st_neighbors:.4f} (ideal ~0.50)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT 7: Fresh discriminator on frozen embeddings\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class SmallDisc(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "# Build dataset (subsample for speed)\n",
    "N = 5000\n",
    "Zst = torch.cat([Z1_full, Z2_full, Z3_full], dim=0)\n",
    "Zsc = Zsc_full\n",
    "idx_st = torch.randperm(Zst.shape[0], device=device)[:min(N, Zst.shape[0])]\n",
    "idx_sc = torch.randperm(Zsc.shape[0], device=device)[:min(N, Zsc.shape[0])]\n",
    "\n",
    "X = torch.cat([Zst[idx_st], Zsc[idx_sc]], dim=0).detach()\n",
    "y = torch.cat([\n",
    "    torch.zeros(idx_st.shape[0], dtype=torch.long, device=device),\n",
    "    torch.ones(idx_sc.shape[0], dtype=torch.long, device=device)\n",
    "], dim=0)\n",
    "\n",
    "# Match training-style input to disc\n",
    "X = F.normalize(X, dim=1)\n",
    "\n",
    "disc = SmallDisc(X.shape[1]).to(device)\n",
    "opt = torch.optim.Adam(disc.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "for t in range(200):\n",
    "    perm = torch.randperm(X.shape[0], device=device)[:512]\n",
    "    xb, yb = X[perm], y[perm]\n",
    "    logits = disc(xb)\n",
    "    loss = F.cross_entropy(logits, yb)\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = disc(X)\n",
    "    pred = logits.argmax(dim=1)\n",
    "    acc = (pred == y).float().mean().item()\n",
    "    acc_st = (pred[y==0] == 0).float().mean().item()\n",
    "    acc_sc = (pred[y==1] == 1).float().mean().item()\n",
    "\n",
    "print(f\"Fresh disc acc: {acc:.4f} | ST acc: {acc_st:.4f} | SC acc: {acc_sc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# DIAGNOSTIC: Discriminator Analysis\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DIAGNOSTIC: Discriminator Confusion Matrix\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "encoder_vicreg.eval()\n",
    "discriminator.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Sample balanced batch from ALL 3 SLIDES\n",
    "    idx_s0 = torch.where(slide_ids == 0)[0]\n",
    "    idx_s1 = torch.where(slide_ids == 1)[0]\n",
    "    idx_s2 = torch.where(slide_ids == 2)[0]  # ← Added slide 3\n",
    "    \n",
    "    n_test = 200  # 200 per slide\n",
    "    idx_test = torch.cat([\n",
    "        idx_s0[torch.randperm(len(idx_s0))[:n_test]],\n",
    "        idx_s1[torch.randperm(len(idx_s1))[:n_test]],\n",
    "        idx_s2[torch.randperm(len(idx_s2))[:n_test]]  # ← Added\n",
    "    ])\n",
    "    \n",
    "    X_test = st_expr[idx_test]\n",
    "    s_test = slide_ids[idx_test]\n",
    "    \n",
    "    # Forward\n",
    "    z_test = encoder_vicreg(X_test)\n",
    "    z_test = F.normalize(z_test, dim=1)  # Match training\n",
    "    logits_test = discriminator(z_test)\n",
    "    preds_test = logits_test.argmax(dim=1)\n",
    "    \n",
    "    # Confusion matrix - NOW 3x3\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(s_test.cpu().numpy(), preds_test.cpu().numpy())\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"              Predicted\")\n",
    "    print(\"              S0    S1    S2\")  # ← 3 columns\n",
    "    print(f\"Actual  S0   {cm[0,0]:4d}  {cm[0,1]:4d}  {cm[0,2]:4d}\")\n",
    "    print(f\"        S1   {cm[1,0]:4d}  {cm[1,1]:4d}  {cm[1,2]:4d}\")\n",
    "    print(f\"        S2   {cm[2,0]:4d}  {cm[2,1]:4d}  {cm[2,2]:4d}\")  # ← Row 3\n",
    "    \n",
    "    acc_s0 = cm[0,0] / cm[0].sum() if cm[0].sum() > 0 else 0\n",
    "    acc_s1 = cm[1,1] / cm[1].sum() if cm[1].sum() > 0 else 0\n",
    "    acc_s2 = cm[2,2] / cm[2].sum() if cm[2].sum() > 0 else 0  # ← Added\n",
    "    acc_total = np.trace(cm) / cm.sum()  # Diagonal sum / total\n",
    "    \n",
    "    print(f\"\\nPer-slide accuracy:\")\n",
    "    print(f\"  Slide 0: {acc_s0:.3f}\")\n",
    "    print(f\"  Slide 1: {acc_s1:.3f}\")\n",
    "    print(f\"  Slide 2: {acc_s2:.3f}\")  # ← Added\n",
    "    print(f\"  Overall: {acc_total:.3f}\")\n",
    "    \n",
    "    chance = 1.0 / 3.0  # ← Changed from 0.5\n",
    "    print(f\"  Chance: {chance:.3f}\")\n",
    "    \n",
    "    if acc_total < chance + 0.05:\n",
    "        print(\"  ✓ Discriminator is failing (good for us!)\")\n",
    "    elif acc_total < chance + 0.15:\n",
    "        print(\"  ⚠️  Discriminator is learning slowly\")\n",
    "    else:\n",
    "        print(\"  ⚠️  Discriminator is succeeding (encoder not fighting back)\")\n",
    "    \n",
    "    # Check logit magnitudes - for 3-class, check entropy\n",
    "    probs_test = torch.softmax(logits_test, dim=1)\n",
    "    entropy = -(probs_test * torch.log(probs_test + 1e-10)).sum(dim=1)\n",
    "    max_entropy = np.log(3)  # ← log(num_classes)\n",
    "    \n",
    "    print(f\"\\nLogit confidence:\")\n",
    "    print(f\"  Mean entropy: {entropy.mean().item():.4f} (max={max_entropy:.4f})\")\n",
    "    print(f\"  Mean max prob: {probs_test.max(dim=1)[0].mean().item():.4f} (uniform={chance:.3f})\")\n",
    "    \n",
    "    if entropy.mean().item() > 0.9 * max_entropy:\n",
    "        print(\"  ✓ Predictions are uniform (discriminator confused)\")\n",
    "    else:\n",
    "        print(\"  ⚠️  Predictions are confident\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehtesamenv_gains",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
