{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "from sklearn.preprocessing import normalize\n",
    "import ot \n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph_torch(X, k, mode='connectivity', metric = 'minkowski', p=2, device='cuda'):\n",
    "    '''construct knn graph with torch and gpu\n",
    "    args:\n",
    "        X: input data containing features (torch tensor)\n",
    "        k: number of neighbors for each data point\n",
    "        mode: 'connectivity' or 'distance'\n",
    "        metric: distance metric (now euclidean supported for gpu knn)\n",
    "        p: param for minkowski (not used if metric is euclidean)\n",
    "    \n",
    "    Returns:\n",
    "        knn graph as a pytorch sparse tensor (coo format) or dense tensor depending on mode     \n",
    "    '''\n",
    "\n",
    "    assert mode in ['connectivity', 'distance'], \"mode must be 'connectivity' or 'distance'.\"\n",
    "    assert metric == 'euclidean', \"for gpu knn, only 'euclidean' metric is currently supported in this implementation\"\n",
    "\n",
    "    if mode == 'connectivity':\n",
    "        include_self = True\n",
    "        mode_knn = 'connectivity'\n",
    "    else:\n",
    "        include_self = False\n",
    "        mode_knn = 'distance'\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "    knn = NearestNeighbors(n_neighbors=k, metric=metric, algorithm='auto')\n",
    "\n",
    "    if device == 'cuda' and torch.cuda.is_available():\n",
    "        X_cpu = X.cpu().numpy()\n",
    "    else:\n",
    "        X_cpu = X.numpy()\n",
    "\n",
    "    knn.fit(X_cpu)\n",
    "    knn_graph_cpu = kneighbors_graph(knn, k, mode=mode_knn, include_self=include_self, metric=metric) #scipy sparse matrix on cpu\n",
    "    knn_graph_coo = knn_graph_cpu.tocoo()\n",
    "\n",
    "    if mode == 'connectivity':\n",
    "        knn_graph = torch.sparse_coo_tensor(torch.LongTensor([knn_graph_coo.row, knn_graph_coo.col]),\n",
    "                                            torch.FloatTensor(knn_graph_coo.data),\n",
    "                                            size = knn_graph_coo.shape).to(device)\n",
    "    elif mode == 'distance':\n",
    "        knn_graph_dense = torch.tensor(knn_graph_cpu.toarray(), dtype=torch.float32, device=device) #move to gpu as dense tensor\n",
    "        knn_graph = knn_graph_dense\n",
    "    \n",
    "    return knn_graph\n",
    "    \n",
    "def distances_cal_torch(graph, type_aware=None, aware_power =2, device='cuda'):\n",
    "    '''\n",
    "    calculate distance matrix from graph using dijkstra's algo\n",
    "    args:\n",
    "        graph: knn graph (pytorch sparse or dense tensor)\n",
    "        type_aware: not implemented in this torch version for simplicity\n",
    "        aware_power: same ^^\n",
    "        device (str): 'cpu' or 'cuda' device to use\n",
    "    Returns:\n",
    "        distance matrix as a torch tensor\n",
    "    '''\n",
    "\n",
    "    if isinstance(graph, torch.Tensor) and graph.is_sparse:\n",
    "        graph_cpu_csr = csr_matrix(graph.cpu().to_dense().numpy())\n",
    "    elif isinstance(graph, torch.Tensor) and not graph.is_sparse:\n",
    "        graph_cpu_csr = csr_matrix(graph.cpu().numpy())\n",
    "    else:\n",
    "        graph_cpu_csr = csr_matrix(graph) #assume scipy sparse matrix if not torch tensor\n",
    "\n",
    "    shortestPath_cpu = dijkstra(csgraph = graph_cpu_csr, directed=False, return_predecessors=False) #dijkstra on cpu\n",
    "    shortestPath = torch.tensor(shortestPath_cpu, dtype=torch.float32, device=device)\n",
    "\n",
    "    # the_max = torch.nanmax(shortestPath[shortestPath != float('inf')])\n",
    "    # shortestPath[shortestPath > the_max] = the_max\n",
    "\n",
    "    #mask out infinite distances\n",
    "    mask = shortestPath != float('inf')\n",
    "    if mask.any():\n",
    "        the_max = torch.max(shortestPath[mask])\n",
    "        shortestPath[~mask] = the_max #replace inf with max value\n",
    "    else:\n",
    "        the_max = 1.0 #fallback if all are inf (should not happen in connected graphs)\n",
    "\n",
    "    C_dis = shortestPath / the_max\n",
    "    C_dis -= torch.mean(C_dis)\n",
    "    return C_dis\n",
    "\n",
    "def calculate_D_sc_torch(X_sc, k_neighbors=10, graph_mode='connectivity', device='cpu'):\n",
    "    '''calculate distance matrix from graph using dijkstra's algo\n",
    "    args:\n",
    "        graph: knn graph (torch sparse or dense tensor)\n",
    "        type_aware: not implemented\n",
    "        aware_power: same ^^\n",
    "        \n",
    "    returns:\n",
    "        distanced matrix as torch tensor'''\n",
    "    \n",
    "    if not isinstance(X_sc, torch.Tensor):\n",
    "        raise TypeError('Input X_sc must be a pytorch tensor')\n",
    "    \n",
    "    if device == 'cuda' and torch.cuda.is_available():\n",
    "        X_sc = X_sc.cuda(device=device)\n",
    "    else:\n",
    "        X_sc = X_sc.cpu()\n",
    "        device= 'cpu'\n",
    "\n",
    "    print(f'using device: {device}')\n",
    "    print(f'constructing knn graph...')\n",
    "    # X_normalized = normalize(X_sc.cpu().numpy(), norm='l2') #normalize on cpu for sklearn knn\n",
    "    X_normalized = X_sc\n",
    "    X_normalized_torch = torch.tensor(X_normalized, dtype=torch.float32, device=device)\n",
    "\n",
    "    Xgraph = construct_graph_torch(X_normalized_torch, k=k_neighbors, mode=graph_mode, metric='euclidean', device=device)\n",
    "\n",
    "    print('calculating distances from graph....')\n",
    "    D_sc = distances_cal_torch(Xgraph, device=device)\n",
    "\n",
    "    print('D_sc calculation complete')\n",
    "    \n",
    "    return D_sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph, NearestNeighbors\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "from sklearn.preprocessing import normalize\n",
    "import ot\n",
    "\n",
    "def construct_graph_spatial(location_array, k, mode='distance', metric='euclidean', p=2):\n",
    "    '''construct KNN graph based on spatial coordinates\n",
    "    args:\n",
    "        location_array: spatial coordinates of spots (n-spots * 2)\n",
    "        k: number of neighbors for each spot\n",
    "        mode: 'connectivity' or 'distance'\n",
    "        metric: distance metric for knn (p=2 is euclidean)\n",
    "        p: param for minkowski if connectivity\n",
    "        \n",
    "    returns:\n",
    "        scipy.sparse.csr_matrix: knn graph in csr format\n",
    "    '''\n",
    "\n",
    "    assert mode in ['connectivity', 'distance'], \"mode must be 'connectivity' or 'distance'\"\n",
    "    if mode == 'connectivity':\n",
    "        include_self = True\n",
    "    else:\n",
    "        include_self = False\n",
    "    \n",
    "    c_graph = kneighbors_graph(location_array, k, mode=mode, metric=metric, include_self=include_self, p=p)\n",
    "    return c_graph\n",
    "\n",
    "def distances_cal_spatial(graph, spot_ids=None, spot_types=None, aware_power=2):\n",
    "    '''calculate spatial distance matrix from knn graph\n",
    "    args:\n",
    "        graph (scipy.sparse.csr_matrix): knn graph\n",
    "        spot_ids (list, optional): list of spot ids corresponding to the rows/cols of the graph. required if type_aware is used\n",
    "        spot_types (pd.Series, optinal): pandas series of spot types for type aware distance adjustment. required if type_aware is used\n",
    "        aware_power (int): power for type-aware distance adjustment\n",
    "        \n",
    "    returns:\n",
    "        sptial distance matrix'''\n",
    "    shortestPath = dijkstra(csgraph = csr_matrix(graph), directed=False, return_predecessors=False)\n",
    "    shortestPath = np.nan_to_num(shortestPath, nan=np.inf) #handle potential inf valyes after dijkstra\n",
    "\n",
    "    if spot_types is not None and spot_ids is not None:\n",
    "        shortestPath_df = pd.DataFrame(shortestPath, index=spot_ids, columns=spot_ids)\n",
    "        shortestPath_df['id1'] = shortestPath_df.index\n",
    "        shortestPath_melted = shortestPath_df.melt(id_vars=['id1'], var_name='id2', value_name='value')\n",
    "\n",
    "        type_aware_df = pd.DataFrame({'spot': spot_ids, 'spot_type': spot_types}, index=spot_ids)\n",
    "        meta1 = type_aware_df.copy()\n",
    "        meta1.columns = ['id1', 'type1']\n",
    "        meta2 = type_aware_df.copy()\n",
    "        meta2.columns = ['id2', 'type2']\n",
    "\n",
    "        shortestPath_melted = pd.merge(shortestPath_melted, meta1, on='id1', how='left')\n",
    "        shortestPath_melted = pd.merge(shortestPath_melted, meta2, on='id2', how='left')\n",
    "\n",
    "        shortestPath_melted['same_type'] = shortestPath_melted['type1'] == shortestPath_melted['type2']\n",
    "        shortestPath_melted.loc[(~shortestPath_melted.smae_type), 'value'] = shortestPath_melted.loc[(~shortestPath_melted.same_type),\n",
    "                                                                                                     'value'] * aware_power\n",
    "        shortestPath_melted.drop(['type1', 'type2', 'same_type'], axis=1, inplace=True)\n",
    "        shortestPath_pivot = shortestPath_melted.pivot(index='id1', columns='id2', values='value')\n",
    "\n",
    "        order = spot_ids\n",
    "        shortestPath = shortestPath_pivot[order].loc[order].values\n",
    "    else:\n",
    "        shortestPath = np.asarray(shortestPath) #ensure it's a numpy array\n",
    "\n",
    "    #mask out infinite distances\n",
    "    mask = shortestPath != float('inf')\n",
    "    if mask.any():\n",
    "        the_max = np.max(shortestPath[mask])\n",
    "        shortestPath[~mask] = the_max #replace inf with max value\n",
    "    else:\n",
    "        the_max = 1.0 #fallback if all are inf (should not happen in connected graphs)\n",
    "\n",
    "    C_dis = shortestPath / the_max\n",
    "    C_dis -= np.mean(C_dis)\n",
    "\n",
    "    return C_dis\n",
    "\n",
    "def calculate_D_st_from_coords(spatial_coords, X_st=None, k_neighbors=10, graph_mode='distance', aware_st=False, \n",
    "                               spot_types=None, aware_power_st=2, spot_ids=None):\n",
    "    '''calculates the spatial distance matrix D_st for spatial transcriptomics data directly from coordinates and optional spot types\n",
    "    args:\n",
    "        spatial_coords: spatial coordinates of spots (n_spots * 2)\n",
    "        X_st: St gene expression data (not used for D_st calculation itself)\n",
    "        k_neighbors: number of neighbors for knn graph\n",
    "        graph_mode: 'connectivity or 'distance' for knn graph\n",
    "        aware_st: whether to use type-aware distance adjustment\n",
    "        spot_types: pandas series of spot types for type-aware adjustment\n",
    "        aware_power_st: power for type-aware distance adjustment\n",
    "        spot_ids: list or index of spot ids, required if spot_ids is provided\n",
    "        \n",
    "    returns:\n",
    "        np.ndarray: spatial disance matrix D_st'''\n",
    "    \n",
    "    if isinstance(spatial_coords, pd.DataFrame):\n",
    "        location_array = spatial_coords.values\n",
    "        if spot_ids is None:\n",
    "            spot_ids = spatial_coords.index.tolist() #use index of dataframe if available\n",
    "    elif isinstance(spatial_coords, np.ndarray):\n",
    "        location_array = spatial_coords\n",
    "        if spot_ids is None:\n",
    "            spot_ids = list(range(location_array.shape[0])) #generate default ids if not provided\n",
    "\n",
    "    else:\n",
    "        raise TypeError('spatial_coords must be a pandas dataframe or a numpy array')\n",
    "    \n",
    "    print(f'constructing {graph_mode} graph for ST data with k={k_neighbors}.....')\n",
    "    Xgraph_st = construct_graph_spatial(location_array, k=k_neighbors, mode=graph_mode)\n",
    "    \n",
    "    if aware_st:\n",
    "        if spot_types is None or spot_ids is None:\n",
    "            raise ValueError('spot_types and spot_ids must be provided when aware_st=True')\n",
    "        if not isinstance(spot_types, pd.Series):\n",
    "            spot_types = pd.Series(spot_types, idnex=spot_ids) \n",
    "        print('applying type aware distance adjustment for ST data')\n",
    "        print(f'aware power for ST: {aware_power_st}')\n",
    "    else:\n",
    "        spot_types = None \n",
    "\n",
    "    print(f'calculating spatial distances.....')\n",
    "    D_st = distances_cal_spatial(Xgraph_st, spot_ids=spot_ids, spot_types=spot_types, aware_power=aware_power_st)\n",
    "\n",
    "    print('D_st calculation complete')\n",
    "    return D_st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fused_gw_torch(X_sc, X_st, Y_st, alpha, k=100, G0=None, max_iter = 100, tol=1e-9, device='cuda', n_iter = 1):\n",
    "    n = X_sc.shape[0]\n",
    "    m = X_st.shape[0]\n",
    "\n",
    "    X_sc = X_sc.to(device)\n",
    "    X_st = X_st.to(device)\n",
    "\n",
    "    if not torch.is_tensor(Y_st):\n",
    "        Y_st_tensor = torch.tensor(Y_st, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        Y_st_tensor = Y_st.to(device, dtype=torch.float32)\n",
    "\n",
    "    #calculate distance matrices\n",
    "    print('calculating SC distances with knn-dijkstra.....')\n",
    "    D_sc = calculate_D_sc_torch(X_sc, k_neighbors=k, device=device)\n",
    "\n",
    "    print('Calculating ST distances.....')\n",
    "    D_st = calculate_D_st_from_coords(spatial_coords=Y_st, k_neighbors=15, graph_mode=\"distance\") # Using calculate_D_st_from_coords\n",
    "    D_st = torch.tensor(D_st, dtype=torch.float32, device=device) # Convert D_st to tensor and move to device\n",
    "\n",
    "    #get expression distance matrix\n",
    "    C_exp = torch.cdist(X_sc, X_st, p=2) #euclidean distance\n",
    "    C_exp = C_exp / (torch.max(C_exp) + 1e-16) #normalize\n",
    "\n",
    "    #ensure distance matries are C-contiguouse numpy arrays for POT\n",
    "    D_sc_np = D_sc.cpu().numpy()\n",
    "    D_st_np = D_st.cpu().numpy()\n",
    "    C_exp_np = C_exp.cpu().numpy()\n",
    "    D_sc_np = np.ascontiguousarray(D_sc_np)\n",
    "    D_st_np = np.ascontiguousarray(D_st_np)\n",
    "    C_exp_np = np.ascontiguousarray(C_exp_np)\n",
    "\n",
    "    #uniform distributions\n",
    "    p = ot.unif(n)\n",
    "    q = ot.unif(m)\n",
    "\n",
    "    #anneal the reg param over several steps\n",
    "    T_np = None\n",
    "    for i in range(n_iter):\n",
    "        #run fused gw with POT\n",
    "        T_np, log = ot.gromov.fused_gromov_wasserstein(\n",
    "            M=C_exp_np, C1=D_sc_np, C2=D_st_np,\n",
    "            p=p, q=q, loss_fun='square_loss',\n",
    "            alpha=alpha,\n",
    "            G0=T_np if T_np is not None else (G0.cpu().numpy() if G0 is not None else None),\n",
    "            log=True,\n",
    "            verbose=True,\n",
    "            max_iter = max_iter,\n",
    "            tol_abs=tol\n",
    "        )\n",
    "\n",
    "    fgw_dist = log['fgw_dist']\n",
    "\n",
    "    print(f'fgw distance: {fgw_dist}')\n",
    "\n",
    "    T = torch.tensor(T_np, dtype=torch.float32, device=device)\n",
    "\n",
    "    return T, D_sc, D_st, fgw_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scdata = pd.read_csv('./data/mousedata_2020/E1z2/simu_sc_counts.csv',index_col=0)\n",
    "scdata = scdata.T\n",
    "stdata = pd.read_csv('data/mousedata_2020/E1z2/simu_st_counts.csv',index_col=0)\n",
    "stdata = stdata.T\n",
    "stgtcelltype = pd.read_csv('./data/mousedata_2020/E1z2/simu_st_celltype.csv',index_col=0)\n",
    "spcoor = pd.read_csv('./data/mousedata_2020/E1z2/simu_st_metadata.csv',index_col=0)\n",
    "scmetadata = pd.read_csv('./data/mousedata_2020/E1z2/metadata.csv',index_col=0)\n",
    "\n",
    "adata = sc.AnnData(scdata,obs=scmetadata)\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)\n",
    "scdata = pd.DataFrame(adata.X,index=adata.obs_names,columns=adata.var_names)\n",
    "stadata = sc.AnnData(stdata)\n",
    "sc.pp.normalize_total(stadata)\n",
    "sc.pp.log1p(stadata)\n",
    "stdata = pd.DataFrame(stadata.X,index=stadata.obs_names,columns=stadata.var_names)\n",
    "\n",
    "adata.obsm['spatial'] = scmetadata[['x_global','y_global']].values\n",
    "stadata.obsm['spatial'] = spcoor\n",
    "\n",
    "# Preprocess data (normalize, log transform)\n",
    "adata = sc.AnnData(scdata, obs=scmetadata)\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)\n",
    "scdata_processed = pd.DataFrame(adata.X, index=adata.obs_names, columns=adata.var_names)\n",
    "X_sc = torch.tensor(scdata_processed.values, dtype=torch.float32)\n",
    "\n",
    "stadata = sc.AnnData(stdata)\n",
    "sc.pp.normalize_total(stadata)\n",
    "sc.pp.log1p(stadata)\n",
    "stdata_processed = pd.DataFrame(stadata.X, index=stadata.obs_names, columns=stadata.var_names)\n",
    "X_st = torch.tensor(stdata_processed.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "Y_st = spcoor.values\n",
    "# --- Run FGW using POT ---\n",
    "T, D_sc, D_st, fgw_dist = fused_gw_torch(\n",
    "    X_sc=X_sc, X_st=X_st, Y_st=Y_st,\n",
    "    alpha=0.3, # Example: balance expression and structure equally\n",
    "    k=300,      # k for SC graph\n",
    "    max_iter=200,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_st = D_st.to(device)\n",
    "D_induced = T @ D_st @ T.t()\n",
    "D_induced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the diffusion model with the simplified parameters\n",
    "if isinstance(Y_st, torch.Tensor):\n",
    "    Y_st = Y_st.cpu().numpy()\n",
    "if isinstance(X_st, torch.Tensor):\n",
    "    X_st = X_st.cpu().numpy()\n",
    "if isinstance(X_sc, torch.Tensor):\n",
    "    X_sc = X_sc.cpu().numpy()\n",
    "if isinstance(D_induced, torch.Tensor):\n",
    "    D_induced = D_induced.cpu().numpy()\n",
    "\n",
    "\n",
    "diffusion = CoordinateDiffusion(\n",
    "    st_gene_expr=X_st,\n",
    "    st_coords=Y_st,\n",
    "    sc_gene_expr=X_sc,\n",
    "    D_induced=D_induced,\n",
    "    device=\"cuda\",\n",
    "    n_timesteps=800,  # Increased timesteps for better quality\n",
    "    beta_start=1e-4,   # Standard DDPM values\n",
    "    beta_end=0.02\n",
    ")\n",
    "\n",
    "print(\"Training diffusion model...\")\n",
    "\n",
    "# 4. Training with adjusted parameters\n",
    "# First phase - coordinate denoising\n",
    "diffusion.pretrain_denoising(\n",
    "    n_epochs=2000,    # More epochs for better convergence\n",
    "    batch_size=192     # Larger batch size for stability\n",
    ")\n",
    "\n",
    "# Second phase - conditional training\n",
    "diffusion.train_conditional(\n",
    "    n_epochs=3000,    # More epochs for conditional training\n",
    "    batch_size=192   # Keep batch size consistent\n",
    ")\n",
    "\n",
    "# 5. Sample coordinates with proper parameters\n",
    "sc_coords = diffusion.sample_coordinates(\n",
    "    timesteps=800     # Can use fewer timesteps for sampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_sc_coords = np.column_stack([\n",
    "    adata.obs['x_global'].values,\n",
    "    adata.obs['y_global'].values\n",
    "])\n",
    "\n",
    "gt_sc_coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "class SinusoidalEmbedding(nn.Module):\n",
    "    \"\"\"Sinusoidal embeddings for diffusion timesteps\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.log(torch.tensor(10000.0)) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t * emb[None, :]\n",
    "        emb = torch.cat((torch.sin(emb), torch.cos(emb)), dim=-1)\n",
    "        if self.dim % 2 == 1:\n",
    "            emb = F.pad(emb, (0, 1, 0, 0))\n",
    "        return emb\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with skip connections\"\"\"\n",
    "    def __init__(self, in_dim, hidden_dim=None):\n",
    "        super().__init__()\n",
    "        hidden_dim = hidden_dim or in_dim\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, in_dim),\n",
    "            nn.LayerNorm(in_dim),\n",
    "        )\n",
    "        self.activation = nn.SiLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.block1(x)\n",
    "        h = self.block2(h)\n",
    "        return self.activation(x + h)\n",
    "    \n",
    "class GraphSageModel(nn.Module):\n",
    "    \"\"\"GraphSAGE model that scales better to large graphs\"\"\"\n",
    "    def __init__(self, in_dim, hidden_dim=256, out_dim=128, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # First layer\n",
    "        self.conv_layers = nn.ModuleList([SAGEConv(in_dim, hidden_dim)])\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(n_layers - 2):\n",
    "            self.conv_layers.append(SAGEConv(hidden_dim, hidden_dim))\n",
    "            \n",
    "        # Output layer\n",
    "        self.conv_layers.append(SAGEConv(hidden_dim, out_dim))\n",
    "        \n",
    "        self.norm_layers = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim if i < n_layers - 1 else out_dim)\n",
    "            for i in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.conv_layers):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.norm_layers[i](x)\n",
    "            if i < self.n_layers - 1:\n",
    "                x = F.silu(x)\n",
    "        return x\n",
    "    \n",
    "class CoordinateDenoiser(nn.Module):\n",
    "    \"\"\"Enhanced denoiser model with GNN embeddings\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        coord_dim=2,\n",
    "        feature_dim=None,\n",
    "        time_dim=256,\n",
    "        hidden_dim=256,\n",
    "        gnn_dim=128,\n",
    "        n_blocks=4\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Time embedding\n",
    "        self.time_embed = nn.Sequential(\n",
    "            SinusoidalEmbedding(time_dim),\n",
    "            nn.Linear(time_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Feature embedding network\n",
    "        self.feature_encoder = None\n",
    "        if feature_dim is not None:\n",
    "            self.feature_encoder = nn.Sequential(\n",
    "                nn.Linear(feature_dim, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.SiLU()\n",
    "            )\n",
    "        \n",
    "        # Coordinate embedding\n",
    "        self.coord_encoder = nn.Sequential(\n",
    "            nn.Linear(coord_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        # GNN embedding projection\n",
    "        self.gnn_encoder = nn.Sequential(\n",
    "            nn.Linear(gnn_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        # Main network with residual blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResidualBlock(hidden_dim) for _ in range(n_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Final output\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim//2, coord_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, coords, t, features=None, gnn_emb=None):\n",
    "        # Time embedding\n",
    "        t_emb = self.time_embed(t)\n",
    "        \n",
    "        # Coordinate embedding\n",
    "        h = self.coord_encoder(coords)\n",
    "        \n",
    "        # Add time embedding\n",
    "        h = h + t_emb\n",
    "        \n",
    "        # Add gene expression features\n",
    "        if features is not None and self.feature_encoder is not None:\n",
    "            feat_emb = self.feature_encoder(features)\n",
    "            h = h + feat_emb\n",
    "            \n",
    "        # Add GNN embedding if provided\n",
    "        if gnn_emb is not None:\n",
    "            gnn_emb_proj = self.gnn_encoder(gnn_emb)\n",
    "            h = h + gnn_emb_proj\n",
    "        \n",
    "        # Process through blocks\n",
    "        for block in self.blocks:\n",
    "            h = block(h)\n",
    "        \n",
    "        # Predict noise\n",
    "        return self.final(h)\n",
    "\n",
    "class CoordinateDiffusion:\n",
    "    def __init__(\n",
    "        self, \n",
    "        st_gene_expr,\n",
    "        st_coords,\n",
    "        sc_gene_expr,\n",
    "        D_induced,\n",
    "        device='cuda',\n",
    "        n_timesteps = 1000,\n",
    "        beta_start = 1e-4,\n",
    "        beta_end = 0.02,\n",
    "        gnn_dim = 128\n",
    "    ):\n",
    "        self.device = torch.device(device)\n",
    "\n",
    "        # Store data\n",
    "        self.st_gene_expr = torch.tensor(st_gene_expr, dtype=torch.float32).to(self.device)\n",
    "        self.st_coords_init = torch.tensor(st_coords, dtype=torch.float32).to(self.device)\n",
    "        self.sc_gene_expr = torch.tensor(sc_gene_expr, dtype=torch.float32).to(self.device)\n",
    "        self.D_induced = torch.tensor(D_induced, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        coords_min = self.st_coords_init.min(dim=0)[0]\n",
    "        coords_max = self.st_coords_init.max(dim=0)[0]\n",
    "        coords_range = coords_max - coords_min\n",
    "        self.st_coords = 2 * (self.st_coords_init - coords_min) / coords_range -1 \n",
    "        self.coords_min, self.coords_max = coords_min, coords_max\n",
    "        self.coords_range = coords_range \n",
    "\n",
    "        # Model dimensions\n",
    "        self.n_genes = st_gene_expr.shape[1]\n",
    "        self.gnn_dim = gnn_dim\n",
    "        \n",
    "        # Setup noise schedule (from Code 1 - improved diffusion process)\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.noise_schedule = self.get_noise_schedule(n_timesteps, beta_start, beta_end)\n",
    "        \n",
    "        # Initialize GraphSAGE model for gene expression embedding\n",
    "        self.gnn_model = GraphSageModel(\n",
    "            in_dim=self.n_genes,\n",
    "            hidden_dim=256,\n",
    "            out_dim=self.gnn_dim,\n",
    "            n_layers=2\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize denoiser model\n",
    "        self.model = CoordinateDenoiser(\n",
    "            coord_dim=2,\n",
    "            feature_dim=self.n_genes,\n",
    "            time_dim=256,\n",
    "            hidden_dim=256,\n",
    "            gnn_dim=self.gnn_dim,\n",
    "            n_blocks=4\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "        \n",
    "        # Calculate ST distances matrix (used for training/evaluation)\n",
    "        self.st_distances = torch.cdist(self.st_coords, self.st_coords, p=2)\n",
    "        \n",
    "        # Precompute GNN embeddings (will be done in training)\n",
    "        self.st_gnn_embeddings = None\n",
    "\n",
    "    def get_noise_schedule(self, timesteps=1000, beta1=1e-4, beta2=0.02):\n",
    "        \"\"\"Returns DDPM noise schedule parameters (from Code 1)\"\"\"\n",
    "        # Linear schedule\n",
    "        betas = torch.linspace(beta1, beta2, timesteps, device=self.device)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "        sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
    "        \n",
    "        # Fix posterior variance calculation\n",
    "        posterior_variance = torch.zeros_like(betas)\n",
    "        posterior_variance[1:] = betas[1:] * (1. - alphas_cumprod[:-1]) / (1. - alphas_cumprod[1:])\n",
    "        posterior_variance[0] = betas[0]\n",
    "        \n",
    "        return {\n",
    "            'betas': betas,\n",
    "            'alphas': alphas,\n",
    "            'alphas_cumprod': alphas_cumprod,\n",
    "            'sqrt_alphas_cumprod': sqrt_alphas_cumprod,\n",
    "            'sqrt_one_minus_alphas_cumprod': sqrt_one_minus_alphas_cumprod,\n",
    "            'posterior_variance': posterior_variance\n",
    "        }\n",
    "    \n",
    "    def add_noise(self, x_0, t, noise_schedule):\n",
    "        \"\"\"Add noise to coordinates according to timestep t (from Code 1)\"\"\"\n",
    "        noise = torch.randn_like(x_0)\n",
    "        sqrt_alphas_cumprod_t = noise_schedule['sqrt_alphas_cumprod'][t].view(-1, 1)\n",
    "        sqrt_one_minus_alphas_cumprod_t = noise_schedule['sqrt_one_minus_alphas_cumprod'][t].view(-1, 1)\n",
    "        \n",
    "        # Add noise according to schedule\n",
    "        x_t = sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "        \n",
    "        return x_t, noise\n",
    "    \n",
    "    def pretrain_gnn(self, epochs=100, lr=1e-3):\n",
    "        \"\"\"Pretrain the GraphSAGE model in unsupervised manner\"\"\"\n",
    "        print(\"Pretraining GraphSAGE on ST data...\")\n",
    "        \n",
    "        # Build a k-NN graph for ST data based on gene expression similarity\n",
    "        similarity = F.normalize(self.st_gene_expr, p=2, dim=1) @ F.normalize(self.st_gene_expr, p=2, dim=1).t()\n",
    "        k = min(20, self.st_gene_expr.shape[0]-1)\n",
    "        _, indices = torch.topk(similarity, k+1, dim=1)\n",
    "        indices = indices[:, 1:]  # Remove self-loops\n",
    "        rows = torch.arange(self.st_gene_expr.shape[0], device=self.device).repeat_interleave(k)\n",
    "        cols = indices.reshape(-1)\n",
    "        edge_index = torch.stack([rows, cols], dim=0).to(self.device)\n",
    "        edge_index = to_undirected(edge_index)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.gnn_model.parameters(), lr=lr)\n",
    "        for epoch in range(epochs):\n",
    "            self.gnn_model.train()\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = self.gnn_model(self.st_gene_expr, edge_index)\n",
    "            \n",
    "            # For each edge, compute cosine similarity\n",
    "            src = edge_index[0]\n",
    "            dst = edge_index[1]\n",
    "            pos_sim = F.cosine_similarity(embeddings[src], embeddings[dst])\n",
    "            \n",
    "            # Sample negative nodes randomly for each source\n",
    "            neg_indices = torch.randint(0, self.st_gene_expr.shape[0], (src.size(0),), device=self.device)\n",
    "            neg_sim = F.cosine_similarity(embeddings[src], embeddings[neg_indices])\n",
    "\n",
    "            # Loss: encourage high similarity for positive pairs and lower for negatives\n",
    "            loss = -torch.mean(pos_sim) + torch.mean(neg_sim)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'GNN pretraining epoch {epoch}/{epochs}, loss: {loss.item():.4f}')\n",
    "        \n",
    "        # After training, compute final embeddings\n",
    "        self.gnn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            self.st_gnn_embeddings = self.gnn_model(self.st_gene_expr, edge_index)\n",
    "        \n",
    "        print(\"GraphSAGE pretraining complete!\")\n",
    "        return self.st_gnn_embeddings\n",
    "    \n",
    "    def compute_sc_gnn_embeddings(self, batch_size=1000):\n",
    "        \"\"\"Compute GNN embeddings for SC data in batches to prevent OOM\"\"\"\n",
    "        print(\"Computing SC GNN embeddings...\")\n",
    "        \n",
    "        # Build a k-NN graph for SC data\n",
    "        # Process in batches to avoid OOM\n",
    "        n_sc = self.sc_gene_expr.shape[0]\n",
    "        all_embeddings = torch.zeros(n_sc, self.gnn_dim, device=self.device)\n",
    "        \n",
    "        # For very large datasets, process in chunks\n",
    "        chunk_size = min(10000, n_sc)  # Maximum chunk size to process at once\n",
    "        \n",
    "        for start_idx in range(0, n_sc, chunk_size):\n",
    "            end_idx = min(start_idx + chunk_size, n_sc)\n",
    "            chunk = self.sc_gene_expr[start_idx:end_idx]\n",
    "            \n",
    "            # Build k-NN graph for this chunk\n",
    "            similarity = F.normalize(chunk, p=2, dim=1) @ F.normalize(chunk, p=2, dim=1).t()\n",
    "            k = min(20, chunk.shape[0] - 1)\n",
    "            _, indices = torch.topk(similarity, k + 1, dim=1)\n",
    "            indices = indices[:, 1:]  # Remove self-loops\n",
    "            rows = torch.arange(chunk.shape[0], device=self.device).repeat_interleave(k)\n",
    "            cols = indices.reshape(-1)\n",
    "            edge_index = torch.stack([rows, cols], dim=0).to(self.device)\n",
    "            edge_index = to_undirected(edge_index)\n",
    "            \n",
    "            # Get embeddings\n",
    "            self.gnn_model.eval()\n",
    "            with torch.no_grad():\n",
    "                chunk_embeddings = self.gnn_model(chunk, edge_index)\n",
    "                all_embeddings[start_idx:end_idx] = chunk_embeddings\n",
    "        \n",
    "        return all_embeddings\n",
    "    \n",
    "    def compute_multi_scale_adjacency(self, coords, sigma=0.1, alpha=0.5):\n",
    "        \"\"\"Compute a multi-scale adjacency matrix for structural constraint\"\"\"\n",
    "        # Compute pairwise euclidean distances\n",
    "        distances = torch.cdist(coords, coords, p=2)\n",
    "        \n",
    "        # Local adjacency using Gaussian kernel\n",
    "        weights = torch.exp(-(distances ** 2) / (2 * sigma ** 2))\n",
    "        identity_mask = torch.eye(weights.shape[0], device=self.device)\n",
    "        local_adj = weights * (1 - identity_mask)\n",
    "        local_adj = local_adj / (local_adj.sum(dim=1, keepdim=True) + 1e-8)\n",
    "        \n",
    "        # Global adjacency via random walk (4-hop)\n",
    "        rw_adj = torch.matrix_power(local_adj, 4)\n",
    "        rw_adj = rw_adj / (rw_adj.sum(dim=1, keepdim=True) + 1e-8)\n",
    "        \n",
    "        # Combine two scales\n",
    "        multi_scale = alpha * local_adj + (1 - alpha) * rw_adj\n",
    "        multi_scale = multi_scale / (multi_scale.sum(dim=1, keepdim=True) + 1e-8)\n",
    "        \n",
    "        return multi_scale\n",
    "    \n",
    "    def _calculate_adjacency_from_distances(self, distances, sigma=3.0):\n",
    "        '''convert dstances to adj matrix using gaussian kernel'''\n",
    "        weights = torch.exp(-(distances ** 2) / (2* sigma ** 2))\n",
    "        #zero out self connections to avoid numerical issues\n",
    "        identity_mask = torch.eye(weights.shape[0], device=weights.device)\n",
    "        weights = weights * (1- identity_mask)\n",
    "        #normalzie rows to sum to 1\n",
    "        row_sums = weights.sum(dim=1, keepdim=True)\n",
    "        adjacecny = weights / (row_sums + 1e-8)\n",
    "        return adjacecny\n",
    "    \n",
    "    def pretrain_denoising(self, n_epochs=1000, batch_size=128, lambda_structure=1.0):\n",
    "        '''first phase: train on st coords denoising (without conditioning)'''\n",
    "        print('starting first training phase: coordinate denosiing pretraining....')\n",
    "\n",
    "        #if gnn embeddings are not computed yet, compute\n",
    "        # if self.st_gnn_embeddings is None:\n",
    "        #     self.pretrain_gnn(epochs=1000)\n",
    "\n",
    "        #compute multi scale adj matrix for structural constraints\n",
    "        st_adj_matrix = self.compute_multi_scale_adjacency(self.st_coords, sigma=3.0, alpha=0.5)\n",
    "\n",
    "        running_loss = 0\n",
    "        running_diffusion_loss = 0\n",
    "        running_structure_loss = 0\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max = n_epochs)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            #random batch of st coords\n",
    "            idx = torch.randint(0, len(self.st_coords), (batch_size,))\n",
    "            coords = self.st_coords[idx]\n",
    "\n",
    "            #random timesteps\n",
    "            t = torch.randint(0, self.n_timesteps, (batch_size,)).to(self.device)\n",
    "\n",
    "            #add noise\n",
    "            noisy_coords, target_noise = self.add_noise(coords, t, self.noise_schedule)\n",
    "\n",
    "            #predict noise (without conditioning)\n",
    "            pred_noise = self.model(noisy_coords, t.unsqueeze(1).float() / self.n_timesteps)\n",
    "\n",
    "            #diffusion loss\n",
    "            diffusion_loss = F.mse_loss(pred_noise, target_noise)\n",
    "\n",
    "            #estimate one step denoise coordinates\n",
    "            sqrt_alphas_cumprod_t = self.noise_schedule['sqrt_alphas_cumprod'][t].view(-1, 1)\n",
    "            sqrt_one_minus_alphas_cumprod_t = self.noise_schedule['sqrt_one_minus_alphas_cumprod'][t].view(-1, 1)\n",
    "            pred_coords = (noisy_coords - sqrt_one_minus_alphas_cumprod_t * pred_noise) / sqrt_alphas_cumprod_t\n",
    "\n",
    "            #compute structure loss based on distances\n",
    "            pred_distances = torch.cdist(pred_coords, pred_coords, p=2)\n",
    "            true_distances = torch.cdist(coords, coords, p=2)\n",
    "            structure_loss = F.mse_loss(pred_distances, true_distances)\n",
    "\n",
    "            #total loss\n",
    "            # loss = diffusion_loss + lambda_structure * structure_loss?\n",
    "            loss = diffusion_loss\n",
    "\n",
    "            #update \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_diffusion_loss += diffusion_loss.item()\n",
    "            running_structure_loss += structure_loss.item()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                avg_loss = running_loss / (epoch + 1 if epoch > 0 else 1)\n",
    "                avg_diff_loss = running_diffusion_loss / (epoch + 1 if epoch > 0 else 1)\n",
    "                avg_struct_loss = running_structure_loss / (epoch + 1 if epoch > 0 else 1)\n",
    "                print(f'pretrain epoch {epoch},'\n",
    "                      f'Loss: {loss.item():.6f},'\n",
    "                      f'diff loss: {diffusion_loss.item():.6f},'\n",
    "                      f'struct loss: {structure_loss.item():.6f},'\n",
    "                      f'LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "                \n",
    "        print('first training phase complete!')\n",
    "\n",
    "    def train_conditional(self, n_epochs=2000, batch_size=128, lambda_structure=5.0):\n",
    "        '''second phase: train with gene expression and gnn conditioning'''\n",
    "        print('starting second training phase: conditional training with GNN.....')\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, n_epochs, eta_min=1e-6)\n",
    "        running_loss = 0\n",
    "        running_diffusion_loss = 0\n",
    "        running_structure_loss = 0\n",
    "        running_adj_loss = 0\n",
    "\n",
    "        #compute multi scale adj matrix for structural constraints\n",
    "        st_adj_matrix = self.compute_multi_scale_adjacency(self.st_coords, sigma=3.0, alpha=0.5)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            #random batch\n",
    "            idx = torch.randint(0, len(self.st_coords), (batch_size,))\n",
    "            coords = self.st_coords[idx]\n",
    "            features = self.st_gene_expr[idx]\n",
    "            # gnn_emb = self.st_gnn_embeddings[idx] \n",
    "            gnn_emb = None\n",
    "\n",
    "            #get sub-adj matrix for this batch\n",
    "            sub_adj = st_adj_matrix[idx, :][:, idx]\n",
    "\n",
    "            #random timesteps\n",
    "            t = torch.randint(0, self.n_timesteps, (batch_size,)).to(self.device)\n",
    "\n",
    "            noisy_coords, target_noise = self.add_noise(coords, t, self.noise_schedule)\n",
    "\n",
    "            #predict noise with conditioning\n",
    "            pred_noise = self.model(\n",
    "                noisy_coords,\n",
    "                t.unsqueeze(1).float() / self.n_timesteps,\n",
    "                features,\n",
    "                gnn_emb\n",
    "            )\n",
    "\n",
    "            #diffusion loss\n",
    "            diffusion_loss = F.mse_loss(pred_noise, target_noise)\n",
    "\n",
    "            #estimate one-step denoised coordinates\n",
    "            sqrt_alphas_cumprod_t = self.noise_schedule['sqrt_alphas_cumprod'][t].view(-1, 1)\n",
    "            sqrt_one_minus_alphas_cumprod_t = self.noise_schedule['sqrt_one_minus_alphas_cumprod'][t].view(-1, 1)\n",
    "            pred_coords = (noisy_coords - sqrt_one_minus_alphas_cumprod_t * pred_noise)/ sqrt_alphas_cumprod_t\n",
    "\n",
    "            #structure loss based on distances\n",
    "            pred_distances = torch.cdist(pred_coords, pred_coords, p=2)\n",
    "            true_distances = torch.cdist(coords, coords, p=2)\n",
    "            structure_loss = F.mse_loss(pred_distances, true_distances)\n",
    "\n",
    "            #adj loss\n",
    "            pred_adj = self.compute_multi_scale_adjacency(pred_coords, sigma=3.0, alpha=0.5)\n",
    "            adj_loss = F.kl_div(\n",
    "                torch.log(pred_adj + 1e-8),\n",
    "                sub_adj,\n",
    "                reduction='batchmean'\n",
    "            )\n",
    "\n",
    "            #total loss\n",
    "            # loss = 5 * diffusion_loss + lambda_structure * structure_loss + lambda_structure * adj_loss\n",
    "            loss = 5 * diffusion_loss + lambda_structure * adj_loss\n",
    "\n",
    "\n",
    "            #update\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_diffusion_loss += diffusion_loss.item()\n",
    "            running_structure_loss + structure_loss.item()\n",
    "            running_adj_loss += adj_loss.item()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                avg_loss = running_loss / (epoch + 1 if epoch > 0 else 1)\n",
    "                avg_diff_loss = running_diffusion_loss / (epoch + 1 if epoch > 0 else 1)\n",
    "                avg_struct_loss = running_structure_loss / (epoch + 1 if epoch > 0 else 1)\n",
    "                avg_adj_loss = running_adj_loss / (epoch + 1 if epoch > 0 else 1)\n",
    "                print(f'conditional train epoch {epoch},'\n",
    "                      f'loss: {loss.item(): .6f},'\n",
    "                      f'diff loss: {diffusion_loss.item(): .6f},'\n",
    "                      f'struct loss: {structure_loss.item(): .6f},'\n",
    "                      f'adj loss: {adj_loss.item(): .6f},'\n",
    "                      f'LR: {scheduler.get_last_lr()[0]: .6f}')\n",
    "                \n",
    "        print('second training phase comeplete!')\n",
    "\n",
    "    def train(self, n_epochs=2000, batch_size=64, timesteps=500, beta1=1e-4, beta2=0.02, \n",
    "            lambda_start=1.0, lambda_end=5.0, save_every=100, checkpoint_dir=\"./checkpoints\"):\n",
    "        \"\"\"Train the diffusion model with GNN conditioning - single stage approach\"\"\"\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        # Setup noise schedule\n",
    "        noise_schedule = self.get_noise_schedule(timesteps, beta1, beta2)\n",
    "        \n",
    "        # Create a simple dataloader for training\n",
    "        indices = torch.arange(len(self.st_coords))\n",
    "        dataloader = DataLoader(indices, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "        \n",
    "        # Training metrics\n",
    "        diffusion_losses = []\n",
    "        structure_losses = []\n",
    "        total_losses = []\n",
    "        \n",
    "        # Linear lambda schedule\n",
    "        lambda_scheduler = lambda epoch: lambda_start + (lambda_end - lambda_start) * min(epoch / (n_epochs * 0.8), 1.0)\n",
    "        \n",
    "        # Optimizer and LR scheduler\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=1e-6)\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_diffusion_loss = 0\n",
    "            epoch_structure_loss = 0\n",
    "            epoch_total_loss = 0\n",
    "            \n",
    "            # Current lambda value\n",
    "            lambda_structure = lambda_scheduler(epoch)\n",
    "            \n",
    "            for batch_idx in dataloader:\n",
    "                # Get batch data\n",
    "                coords = self.st_coords[batch_idx]\n",
    "                gene_expr = self.st_gene_expr[batch_idx]\n",
    "                gnn_emb = self.st_gnn_embeddings[batch_idx]\n",
    "                \n",
    "                # Sample random timesteps\n",
    "                t = torch.randint(0, timesteps, (len(batch_idx),), device=self.device)\n",
    "                \n",
    "                # Add noise to coordinates\n",
    "                noisy_coords, noise = self.add_noise(coords, t, noise_schedule)\n",
    "                \n",
    "                # Predict noise\n",
    "                predicted_noise = self.model(noisy_coords, t.unsqueeze(1).float() / timesteps, gene_expr, gnn_emb)\n",
    "                \n",
    "                # Diffusion loss (MSE between predicted and actual noise)\n",
    "                diffusion_loss = F.mse_loss(predicted_noise, noise)\n",
    "                \n",
    "                # One-step denoising to get estimated coordinates\n",
    "                sqrt_alphas_cumprod_t = noise_schedule['sqrt_alphas_cumprod'][t].view(-1, 1)\n",
    "                sqrt_one_minus_alphas_cumprod_t = noise_schedule['sqrt_one_minus_alphas_cumprod'][t].view(-1, 1)\n",
    "                \n",
    "                # Estimate the clean coordinates using the predicted noise\n",
    "                pred_coords = (noisy_coords - sqrt_one_minus_alphas_cumprod_t * predicted_noise) / sqrt_alphas_cumprod_t\n",
    "                \n",
    "                # Calculate structure loss using KL divergence\n",
    "                pred_distances = torch.cdist(pred_coords, pred_coords, p=2)\n",
    "                true_distances = torch.cdist(coords, coords, p=2)\n",
    "                \n",
    "                # Normalize distances to probabilities for KL divergence\n",
    "                pred_distances = pred_distances / (pred_distances.sum(dim=1, keepdim=True) + 1e-8)\n",
    "                true_distances = true_distances / (true_distances.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "                #calc adj matrices\n",
    "                pred_adj = self._calculate_adjacency_from_distances(pred_distances)\n",
    "                true_adj = self._calculate_adjacency_from_distances(true_distances)\n",
    "                \n",
    "                # KL divergence for structural loss (more stable than MSE)\n",
    "                # structure_loss = F.kl_div(\n",
    "                #     torch.log(pred_distances + 1e-8),\n",
    "                #     true_distances,\n",
    "                #     reduction='batchmean'\n",
    "                # )\n",
    "\n",
    "                structure_loss = F.kl_div(\n",
    "                    torch.log(pred_adj + 1e-8),\n",
    "                    true_adj,\n",
    "                    reduction='batchmean'\n",
    "                )\n",
    "                \n",
    "                # Total loss with scheduled lambda\n",
    "                total_loss = diffusion_loss + lambda_structure * structure_loss\n",
    "                \n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                \n",
    "                # Gradient clipping for stability\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                # Accumulate losses\n",
    "                epoch_diffusion_loss += diffusion_loss.item()\n",
    "                epoch_structure_loss += structure_loss.item()\n",
    "                epoch_total_loss += total_loss.item()\n",
    "            \n",
    "            # Step scheduler\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Average losses over batches\n",
    "            n_batches = len(dataloader)\n",
    "            epoch_diffusion_loss /= n_batches\n",
    "            epoch_structure_loss /= n_batches\n",
    "            epoch_total_loss /= n_batches\n",
    "            \n",
    "            # Store metrics\n",
    "            diffusion_losses.append(epoch_diffusion_loss)\n",
    "            structure_losses.append(epoch_structure_loss)\n",
    "            total_losses.append(epoch_total_loss)\n",
    "            \n",
    "            # Print progress\n",
    "            if (epoch + 1) % (n_epochs // 20) == 0 or epoch == 0:\n",
    "                print(f\"Epoch {epoch+1}/{n_epochs}, \"\n",
    "                    f\"Diffusion Loss: {epoch_diffusion_loss:.6f}, \"\n",
    "                    f\"Structure Loss: {epoch_structure_loss:.6f}, \"\n",
    "                    f\"Total Loss: {epoch_total_loss:.6f}, \"\n",
    "                    f\"Lambda: {lambda_structure:.2f}, \"\n",
    "                    f\"LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "                        \n",
    "            # Save checkpoint\n",
    "            if (epoch + 1) % save_every == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'diffusion_loss': epoch_diffusion_loss,\n",
    "                    'structure_loss': epoch_structure_loss,\n",
    "                    'total_loss': epoch_total_loss\n",
    "                }, f\"{checkpoint_dir}/model_epoch_{epoch+1}.pt\")\n",
    "        \n",
    "        return {\n",
    "            'diffusion_losses': diffusion_losses,\n",
    "            'structure_losses': structure_losses,\n",
    "            'total_losses': total_losses\n",
    "        }\n",
    "\n",
    "    def denormalize_coordinates(self, normalized_coords):\n",
    "        # if isinstance(normalized_coords, torch.Tensor):\n",
    "        #     normalized_coords = normalized_coords.cpu().numpy()\n",
    "\n",
    "        # #apply inverse norm\n",
    "        # og_coords = (normalized_coords + 1) / 2 * self.coords_range + self.coords_min\n",
    "\n",
    "        if isinstance(normalized_coords, np.ndarray):\n",
    "            coords_range = self.coords_range.cpu().numpy() if isinstance(self.coords_range, torch.Tensor) else self.coords_range\n",
    "            coords_min = self.coords_min.cpu().numpy() if isinstance(self.coords_min, torch.Tensor) else self.coords_min\n",
    "            og_coords = (normalized_coords + 1) / 2 * coords_range + coords_min\n",
    "        else:\n",
    "            # If normalized_coords is a tensor\n",
    "            coords_range = self.coords_range if isinstance(self.coords_range, torch.Tensor) else torch.tensor(self.coords_range, device=normalized_coords.device)\n",
    "            coords_min = self.coords_min if isinstance(self.coords_min, torch.Tensor) else torch.tensor(self.coords_min, device=normalized_coords.device)\n",
    "            og_coords = (normalized_coords + 1) / 2 * coords_range + coords_min\n",
    "\n",
    "        return og_coords\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample_without_D_induced(self, timesteps=None):\n",
    "        \"\"\"Generate coordinates for all SC cells at once without using D_induced\"\"\"\n",
    "        print(\"Sampling coordinates for SC cells without structure guidance...\")\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Compute GNN embeddings for SC data\n",
    "        sc_gnn_embeddings = self.compute_sc_gnn_embeddings()\n",
    "        \n",
    "        # If no timesteps specified, use default\n",
    "        timesteps = timesteps or self.n_timesteps\n",
    "        \n",
    "        # Start from random noise for all cells\n",
    "        x = torch.randn(len(self.sc_gene_expr), 2, device=self.device)\n",
    "        \n",
    "        # Gradually denoise\n",
    "        for t in tqdm(range(timesteps-1, -1, -1), desc=\"Sampling coordinates\"):\n",
    "            # Create timestep tensor\n",
    "            time_tensor = torch.ones(len(x), 1, device=self.device) * t / timesteps\n",
    "            \n",
    "            # Predict noise using gene expression and GNN embeddings as conditioning\n",
    "            pred_noise = self.model(x, time_tensor, self.sc_gene_emxpr, sc_gnn_embeddings)\n",
    "            \n",
    "            # Get parameters for this timestep\n",
    "            alpha_t = self.noise_schedule['alphas'][t]\n",
    "            alpha_cumprod_t = self.noise_schedule['alphas_cumprod'][t]\n",
    "            beta_t = self.noise_schedule['betas'][t]\n",
    "            \n",
    "            # Apply noise (except for last step)\n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x)\n",
    "            else:\n",
    "                noise = 0\n",
    "            \n",
    "            # Update sample with reverse diffusion step\n",
    "            x = (1 / torch.sqrt(alpha_t)) * (\n",
    "                x - ((1 - alpha_t) / torch.sqrt(1 - alpha_cumprod_t)) * pred_noise\n",
    "            ) + torch.sqrt(beta_t) * noise\n",
    "        \n",
    "        return x.cpu().numpy()\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_coordinates(self, timesteps=None, batch_size=None):\n",
    "        '''generate coords for al SC cells at once with structure constraints'''\n",
    "        print('sampling coords for SC cells....')\n",
    "        self.model.eval()\n",
    "\n",
    "        #compute gnn embeddings for sc data\n",
    "        sc_gnn_embeddings = self.compute_sc_gnn_embeddings()\n",
    "\n",
    "        timesteps = timesteps or self.n_timesteps\n",
    "\n",
    "        #proecss all cells at once if batch_size is None and gpu memroy alows\n",
    "        #otherwise, process in batches\n",
    "        if batch_size is None:\n",
    "            return self._sample_all_coordinates(timesteps, sc_gnn_embeddings)\n",
    "        else:\n",
    "            return self._sample_batch_coordinates(timesteps, sc_gnn_embeddings, batch_size)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _sample_all_coordinates(self, timesteps, sc_gnn_embeddings):\n",
    "        '''sa,ple coordinates for all cells at once'''\n",
    "        #start from random noise\n",
    "        x = torch.randn(len(self.sc_gene_expr), 2, device=self.device)\n",
    "\n",
    "        #gradual denoise\n",
    "        for t in tqdm(range(timesteps-1, -1, -1), desc='sampling coordinates'):\n",
    "            #create timestep tensor\n",
    "            time_tensor = torch.ones(len(x), 1, device=self.device) * t / timesteps\n",
    "\n",
    "            #predict noise using gene expression and gnn embeddings as condition\n",
    "            # pred_noise = self.model(x, time_tensor, self.sc_gene_expr, sc_gnn_embeddings)\n",
    "            pred_noise = self.model(x, time_tensor, self.sc_gene_expr)\n",
    "\n",
    "\n",
    "            #get params for this timestep\n",
    "            alpha_t = self.noise_schedule['alphas'][t]\n",
    "            alpha_cumprod_t = self.noise_schedule['alphas_cumprod'][t]\n",
    "            beta_t = self.noise_schedule['betas'][t]\n",
    "\n",
    "            #apply noise \n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x)\n",
    "            else:\n",
    "                noise = 0\n",
    "\n",
    "            #update sample with reverse diffusion step\n",
    "            x = (1/ torch.sqrt(alpha_t)) * (\n",
    "                x - ((1-alpha_t) / torch.sqrt(1- alpha_cumprod_t)) * pred_noise\n",
    "            ) + torch.sqrt(beta_t) * noise\n",
    "\n",
    "            sc_coords = x.cpu().numpy()\n",
    "\n",
    "            sc_coords = self.denormalize_coordinates(sc_coords)\n",
    "\n",
    "            # #appl structure constraint after sometime\n",
    "            # if t < timesteps * 0.8 and t % 3 == 0:\n",
    "            #     #adjust coordinates to match D_induced\n",
    "            #     #do periodically to avoid over correction\n",
    "            #     x = self._adjust_to_match_distances(x, scale=0.05)\n",
    "\n",
    "        return sc_coords\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _sample_batch_coordinates(self, timesteps, sc_gnn_embeddings, batch_size):\n",
    "        '''sample coordinates in batches to save memory'''\n",
    "        n_cells = len(self.sc_gene_expr)\n",
    "        coordinates = np.zeros((n_cells, 2))\n",
    "\n",
    "        #process in batches\n",
    "        for start_idx in range(0, n_cells, batch_size):\n",
    "            end_idx = min(start_idx+ batch_size, n_cells)\n",
    "            batch_size_actual = end_idx - start_idx\n",
    "\n",
    "            #get batch data\n",
    "            batch_genes = self.sc_gene_expr[start_idx: end_idx]\n",
    "            batch_gnn = sc_gnn_embeddings[start_idx: end_idx]\n",
    "\n",
    "            #start from random noise\n",
    "            x = torch.randn(batch_size_actual, 2, device=self.device)\n",
    "\n",
    "            #gradually denoise\n",
    "            for t in tqdm(range(timesteps-1, -1, -1), desc=f'sampling batch {start_idx//batch_size +1} / {(n_cells-1)// batch_size+1}'):\n",
    "                #create timestep tensor\n",
    "                time_tensor = torch.ones(batch_size_actual, 1, device=self.device) * t / timesteps\n",
    "\n",
    "                #predict nosie using gene expression and gnn embeddinsg as conditioning\n",
    "                # pred_noise = self.model(x, time_tensor, batch_genes, batch_gnn)\n",
    "                pred_noise = self.model(x, time_tensor, batch_genes)\n",
    "\n",
    "                #gete params for this timestep\n",
    "                alpha_t = self.noise_schedule['alphas'][t]\n",
    "                alpha_cumprod_t = self.noise_schedule['alphas_cumprod'][t]\n",
    "                beta_t = self.noise_schedule['betas'][t]\n",
    "\n",
    "                #apply noise \n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = 0\n",
    "\n",
    "                #update sample with reverse diffusion step\n",
    "                x = (1/ torch.sqrt(alpha_t)) * (\n",
    "                    x - ((1-alpha_t)/ torch.sqrt(1- alpha_cumprod_t)) * pred_noise \n",
    "                ) + torch.sqrt(beta_t) * noise\n",
    "\n",
    "            #store batch results\n",
    "            coordinates[start_idx: end_idx] = x.cpu().numpy()\n",
    "\n",
    "        return coordinates\n",
    "        \n",
    "\n",
    "    def _adjust_to_match_distances(self, coords, scale=0.05):\n",
    "        '''adjust coordinates to better match D_induced during sampling'''\n",
    "        #compute cuurent distances\n",
    "        current_dist = torch.cdist(coords, coords)\n",
    "\n",
    "        #process in batches for large matrices\n",
    "        if self.D_induced.shape[0] > 10000:\n",
    "            current_dist_norm = current_dist / current_dist.max()\n",
    "            target_dist_norm = self.D_induced / self.D_induced.max()\n",
    "\n",
    "\n",
    "            #calculate gradient direction (in batches if needed)\n",
    "            batch_size = 512\n",
    "            n_coords = coords.shape[0]\n",
    "            grad_sum = torch.zeros_like(coords)\n",
    "\n",
    "            for i in range(0, n_coords, batch_size):\n",
    "                end_i = min(i + batch_size, n_coords)\n",
    "\n",
    "                for j in range(0, n_coords, batch_size):\n",
    "                    end_j = min(j+batch_size, n_coords)\n",
    "\n",
    "                    #extract submatrices\n",
    "                    curr_dist_sub = current_dist_norm[i:end_i, j:end_j]\n",
    "                    # target_dist_sub = self.D_induced[i:end_i, j:end_j]\n",
    "                    target_dist_sub = target_dist_norm[i:end_i, j:end_j]\n",
    "\n",
    "\n",
    "                    #compute difference\n",
    "                    diff_sub = curr_dist_sub - target_dist_sub\n",
    "\n",
    "                    #accumulate gradients for coordinates i:end_i\n",
    "                    #this compues how each coordinate should move to better match the target\n",
    "                    for idx in range(i, end_i):\n",
    "                        rel_idx = idx - i\n",
    "                        #calculate direction vectors from this point to all others\n",
    "                        if idx < coords.shape[0]:\n",
    "                            directions = coords[idx].unsqueeze(0) - coords\n",
    "                            #normalize directions\n",
    "                            norms = torch.norm(directions, dim=1, keepdim=True)\n",
    "                            normalized_dirs = directions / (norms + 1e-8)\n",
    "                            #weight by distance differences\n",
    "                            row_diff = diff_sub[rel_idx] if rel_idx < diff_sub.shape[0] else torch.zeros(diff_sub.shape[1], device=self.device)\n",
    "                            weighted_dirs = normalized_dirs * row_diff.unsqueeze(1)\n",
    "                            #sum contributions\n",
    "                            grad_sum[idx] += weighted_dirs.sum(dim=0)\n",
    "\n",
    "            else:\n",
    "                #for smaller datasets we can do this in one go\n",
    "                #normalize distances\n",
    "                current_dist_norm = current_dist / current_dist.max()\n",
    "                target_dist_norm = self.D_induced / self.D_induced.max()\n",
    "\n",
    "                #compute difference\n",
    "                diff = current_dist_norm - target_dist_norm\n",
    "\n",
    "                #rehsape for broadcasting\n",
    "                diff_expanded = diff.unsqueeze(-1) #[n, n, 1]\n",
    "\n",
    "                #compute direction vectors between all pairs\n",
    "                coords_expnaded_i = coords.unsqueeze(1) #[n, 1, 2]\n",
    "                coords_expnaded_j = coords.unsqueeze(0) #[1, n, 2]\n",
    "                directions = coords_expnaded_i - coords_expnaded_j #[n, n, 2]\n",
    "\n",
    "                #normalize directions\n",
    "                norms = torch.norm(directions, dim=2, keepdim=True)\n",
    "                normalized_dirs = directions / (norms + 1e-8)\n",
    "\n",
    "                #weigh by distance difference\n",
    "                weighted_dirs = normalized_dirs * diff_expanded\n",
    "\n",
    "                #sum along j dimension to get gradient for each point\n",
    "                grad_sum = weighted_dirs.sum(dim=1)\n",
    "\n",
    "            #apply gradients with scaling\n",
    "            coords_adj = coords - scale * grad_sum\n",
    "\n",
    "            return coords_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_induced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the diffusion model with the required parameters\n",
    "if isinstance(Y_st, torch.Tensor):\n",
    "    Y_st = Y_st.cpu().numpy()\n",
    "if isinstance(X_st, torch.Tensor):\n",
    "    X_st = X_st.cpu().numpy()\n",
    "if isinstance(X_sc, torch.Tensor):\n",
    "    X_sc = X_sc.cpu().numpy()\n",
    "if isinstance(D_induced, torch.Tensor):\n",
    "    D_induced = D_induced.cpu().numpy()\n",
    "\n",
    "# Initialize the diffusion model\n",
    "diffusion = CoordinateDiffusion(\n",
    "    st_gene_expr=X_st,\n",
    "    st_coords=Y_st,\n",
    "    sc_gene_expr=X_sc,\n",
    "    D_induced=D_induced,\n",
    "    device=\"cuda\",\n",
    "    n_timesteps=800,  # Increased timesteps for better quality\n",
    "    beta_start=1e-4,  # Standard DDPM values\n",
    "    beta_end=0.02,\n",
    "    gnn_dim=128  # Dimension for GNN embeddings\n",
    ")\n",
    "\n",
    "print(\"Pretraining GNN model...\")\n",
    "# Pretrain the GNN model to get better embeddings\n",
    "diffusion.pretrain_gnn(epochs=500)\n",
    "\n",
    "print(\"Training diffusion model...\")\n",
    "\n",
    "# First phase - coordinate denoising with structure preservation\n",
    "# diffusion.pretrain_denoising(\n",
    "#     n_epochs=2000,     # More epochs for better convergence\n",
    "#     batch_size=192,    # Larger batch size for stability\n",
    "#     lambda_structure=1.0  # Weight for structure preservation loss\n",
    "# )\n",
    "\n",
    "# # Second phase - conditional training with gene expression and GNN embeddings\n",
    "# diffusion.train_conditional(\n",
    "#     n_epochs=3000,     # More epochs for conditional training\n",
    "#     batch_size=192,    # Keep batch size consistent\n",
    "#     lambda_structure=5.0  # Increased weight for structure in second phase\n",
    "# )\n",
    "# Single-stage training with structural constraints\n",
    "diffusion.train(\n",
    "    n_epochs=3000,\n",
    "    batch_size=256,\n",
    "    timesteps=800,\n",
    "    beta1=1e-4,\n",
    "    beta2=0.02,\n",
    "    lambda_start=10,  # Start with low structure weight\n",
    "    lambda_end=50,    # Gradually increase to moderate weight\n",
    "    save_every=500,\n",
    "    checkpoint_dir=\"./checkpoints\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_coords = diffusion.sample_without_D_induced(timesteps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample coordinates with structure enforcement\n",
    "# If you have a very large SC dataset, you can use batching\n",
    "if X_sc.shape[0] > 11000:\n",
    "    sc_coords = diffusion.sample_coordinates(\n",
    "        timesteps=800,    # Can use fewer timesteps for sampling\n",
    "        batch_size=11000   # Process in batches to save memory\n",
    "    )\n",
    "else:\n",
    "    # Process all cells at once for better global structure\n",
    "    sc_coords = diffusion.sample_coordinates(\n",
    "        timesteps=800     # Can use fewer timesteps for sampling\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc_coords = diffusion.sample_sc_coordinates(timesteps=1000, lambda_structure=2.0)\n",
    "\n",
    "adata.obsm['diffusion_coords'] = sc_coords\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sc.settings.set_figure_params(figsize=(10, 10))\n",
    "\n",
    "\n",
    "#plot using scanypy's spatial plotting function with cell types as colors\n",
    "sc.pl.embedding(adata, basis='diffusion_coords', color = 'celltype_mapped_refined',\n",
    "                size=75, title='SC spatial coordinates (Diffusion Model)',\n",
    "                palette='tab20', legend_loc='right margin', legend_fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After loading your data\n",
    "if isinstance(Y_st, torch.Tensor):\n",
    "    Y_st = Y_st.cpu().numpy()\n",
    "if isinstance(X_st, torch.Tensor):\n",
    "    X_st = X_st.cpu().numpy()\n",
    "if isinstance(X_sc, torch.Tensor):\n",
    "    X_sc = X_sc.cpu().numpy()\n",
    "if isinstance(D_induced, torch.Tensor):\n",
    "    D_induced = D_induced.cpu().numpy()\n",
    "\n",
    "# Run the analysis\n",
    "results = run_gnn_analysis(X_sc, D_induced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehtesamenv_gains",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
