{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Cell 2: force single‐threaded BLAS\n",
    "os.environ[\"OMP_NUM_THREADS\"]       = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: actually cap BLAS to 1 thread\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "# 'blas' covers OpenBLAS, MKL, etc.\n",
    "threadpool_limits(limits=1, user_api='blas')\n",
    "\n",
    "# now import as usual, no more warning\n",
    "import numpy as np\n",
    "import scipy\n",
    "# … any other packages that use OpenBLAS …\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "from sklearn.preprocessing import normalize\n",
    "import ot \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph_torch(X, k, mode='connectivity', metric = 'minkowski', p=2, device='cuda'):\n",
    "    '''construct knn graph with torch and gpu\n",
    "    args:\n",
    "        X: input data containing features (torch tensor)\n",
    "        k: number of neighbors for each data point\n",
    "        mode: 'connectivity' or 'distance'\n",
    "        metric: distance metric (now euclidean supported for gpu knn)\n",
    "        p: param for minkowski (not used if metric is euclidean)\n",
    "    \n",
    "    Returns:\n",
    "        knn graph as a pytorch sparse tensor (coo format) or dense tensor depending on mode     \n",
    "    '''\n",
    "\n",
    "    assert mode in ['connectivity', 'distance'], \"mode must be 'connectivity' or 'distance'.\"\n",
    "    assert metric == 'euclidean', \"for gpu knn, only 'euclidean' metric is currently supported in this implementation\"\n",
    "\n",
    "    if mode == 'connectivity':\n",
    "        include_self = True\n",
    "        mode_knn = 'connectivity'\n",
    "    else:\n",
    "        include_self = False\n",
    "        mode_knn = 'distance'\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "    knn = NearestNeighbors(n_neighbors=k, metric=metric, algorithm='auto')\n",
    "\n",
    "    if device == 'cuda' and torch.cuda.is_available():\n",
    "        X_cpu = X.cpu().numpy()\n",
    "    else:\n",
    "        X_cpu = X.numpy()\n",
    "\n",
    "    knn.fit(X_cpu)\n",
    "    knn_graph_cpu = kneighbors_graph(knn, k, mode=mode_knn, include_self=include_self, metric=metric) #scipy sparse matrix on cpu\n",
    "    knn_graph_coo = knn_graph_cpu.tocoo()\n",
    "\n",
    "    if mode == 'connectivity':\n",
    "        knn_graph = torch.sparse_coo_tensor(torch.LongTensor([knn_graph_coo.row, knn_graph_coo.col]),\n",
    "                                            torch.FloatTensor(knn_graph_coo.data),\n",
    "                                            size = knn_graph_coo.shape).to(device)\n",
    "    elif mode == 'distance':\n",
    "        knn_graph_dense = torch.tensor(knn_graph_cpu.toarray(), dtype=torch.float32, device=device) #move to gpu as dense tensor\n",
    "        knn_graph = knn_graph_dense\n",
    "    \n",
    "    return knn_graph\n",
    "    \n",
    "def distances_cal_torch(graph, type_aware=None, aware_power =2, device='cuda'):\n",
    "    '''\n",
    "    calculate distance matrix from graph using dijkstra's algo\n",
    "    args:\n",
    "        graph: knn graph (pytorch sparse or dense tensor)\n",
    "        type_aware: not implemented in this torch version for simplicity\n",
    "        aware_power: same ^^\n",
    "        device (str): 'cpu' or 'cuda' device to use\n",
    "    Returns:\n",
    "        distance matrix as a torch tensor\n",
    "    '''\n",
    "\n",
    "    if isinstance(graph, torch.Tensor) and graph.is_sparse:\n",
    "        graph_cpu_csr = csr_matrix(graph.cpu().to_dense().numpy())\n",
    "    elif isinstance(graph, torch.Tensor) and not graph.is_sparse:\n",
    "        graph_cpu_csr = csr_matrix(graph.cpu().numpy())\n",
    "    else:\n",
    "        graph_cpu_csr = csr_matrix(graph) #assume scipy sparse matrix if not torch tensor\n",
    "\n",
    "    shortestPath_cpu = dijkstra(csgraph = graph_cpu_csr, directed=False, return_predecessors=False) #dijkstra on cpu\n",
    "    shortestPath = torch.tensor(shortestPath_cpu, dtype=torch.float32, device=device)\n",
    "\n",
    "    # the_max = torch.nanmax(shortestPath[shortestPath != float('inf')])\n",
    "    # shortestPath[shortestPath > the_max] = the_max\n",
    "\n",
    "    #mask out infinite distances\n",
    "    mask = shortestPath != float('inf')\n",
    "    if mask.any():\n",
    "        the_max = torch.max(shortestPath[mask])\n",
    "        shortestPath[~mask] = the_max #replace inf with max value\n",
    "    else:\n",
    "        the_max = 1.0 #fallback if all are inf (should not happen in connected graphs)\n",
    "\n",
    "    original_max_distance = the_max.item()\n",
    "    C_dis = shortestPath / the_max\n",
    "    # C_dis = shortestPath\n",
    "    # C_dis -= torch.mean(C_dis)\n",
    "    return C_dis, original_max_distance\n",
    "\n",
    "def calculate_D_sc_torch(X_sc, k_neighbors=10, graph_mode='connectivity', device='cpu'):\n",
    "    '''calculate distance matrix from graph using dijkstra's algo\n",
    "    args:\n",
    "        graph: knn graph (torch sparse or dense tensor)\n",
    "        type_aware: not implemented\n",
    "        aware_power: same ^^\n",
    "        \n",
    "    returns:\n",
    "        distanced matrix as torch tensor'''\n",
    "    \n",
    "    if not isinstance(X_sc, torch.Tensor):\n",
    "        raise TypeError('Input X_sc must be a pytorch tensor')\n",
    "    \n",
    "    if device == 'cuda' and torch.cuda.is_available():\n",
    "        X_sc = X_sc.cuda(device=device)\n",
    "    else:\n",
    "        X_sc = X_sc.cpu()\n",
    "        device= 'cpu'\n",
    "\n",
    "    print(f'using device: {device}')\n",
    "    print(f'constructing knn graph...')\n",
    "    # X_normalized = normalize(X_sc.cpu().numpy(), norm='l2') #normalize on cpu for sklearn knn\n",
    "    X_normalized = X_sc\n",
    "    X_normalized_torch = torch.tensor(X_normalized, dtype=torch.float32, device=device)\n",
    "\n",
    "    Xgraph = construct_graph_torch(X_normalized_torch, k=k_neighbors, mode=graph_mode, metric='euclidean', device=device)\n",
    "\n",
    "    print('calculating distances from graph....')\n",
    "    D_sc, sc_max_distance = distances_cal_torch(Xgraph, device=device)\n",
    "\n",
    "    print('D_sc calculation complete')\n",
    "    \n",
    "    return D_sc, sc_max_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph, NearestNeighbors\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "from sklearn.preprocessing import normalize\n",
    "import ot\n",
    "\n",
    "def construct_graph_spatial(location_array, k, mode='distance', metric='euclidean', p=2):\n",
    "    '''construct KNN graph based on spatial coordinates\n",
    "    args:\n",
    "        location_array: spatial coordinates of spots (n-spots * 2)\n",
    "        k: number of neighbors for each spot\n",
    "        mode: 'connectivity' or 'distance'\n",
    "        metric: distance metric for knn (p=2 is euclidean)\n",
    "        p: param for minkowski if connectivity\n",
    "        \n",
    "    returns:\n",
    "        scipy.sparse.csr_matrix: knn graph in csr format\n",
    "    '''\n",
    "\n",
    "    assert mode in ['connectivity', 'distance'], \"mode must be 'connectivity' or 'distance'\"\n",
    "    if mode == 'connectivity':\n",
    "        include_self = True\n",
    "    else:\n",
    "        include_self = False\n",
    "    \n",
    "    c_graph = kneighbors_graph(location_array, k, mode=mode, metric=metric, include_self=include_self, p=p)\n",
    "    return c_graph\n",
    "\n",
    "def distances_cal_spatial(graph, spot_ids=None, spot_types=None, aware_power=2):\n",
    "    '''calculate spatial distance matrix from knn graph\n",
    "    args:\n",
    "        graph (scipy.sparse.csr_matrix): knn graph\n",
    "        spot_ids (list, optional): list of spot ids corresponding to the rows/cols of the graph. required if type_aware is used\n",
    "        spot_types (pd.Series, optinal): pandas series of spot types for type aware distance adjustment. required if type_aware is used\n",
    "        aware_power (int): power for type-aware distance adjustment\n",
    "        \n",
    "    returns:\n",
    "        sptial distance matrix'''\n",
    "    shortestPath = dijkstra(csgraph = csr_matrix(graph), directed=False, return_predecessors=False)\n",
    "    shortestPath = np.nan_to_num(shortestPath, nan=np.inf) #handle potential inf valyes after dijkstra\n",
    "\n",
    "    if spot_types is not None and spot_ids is not None:\n",
    "        shortestPath_df = pd.DataFrame(shortestPath, index=spot_ids, columns=spot_ids)\n",
    "        shortestPath_df['id1'] = shortestPath_df.index\n",
    "        shortestPath_melted = shortestPath_df.melt(id_vars=['id1'], var_name='id2', value_name='value')\n",
    "\n",
    "        type_aware_df = pd.DataFrame({'spot': spot_ids, 'spot_type': spot_types}, index=spot_ids)\n",
    "        meta1 = type_aware_df.copy()\n",
    "        meta1.columns = ['id1', 'type1']\n",
    "        meta2 = type_aware_df.copy()\n",
    "        meta2.columns = ['id2', 'type2']\n",
    "\n",
    "        shortestPath_melted = pd.merge(shortestPath_melted, meta1, on='id1', how='left')\n",
    "        shortestPath_melted = pd.merge(shortestPath_melted, meta2, on='id2', how='left')\n",
    "\n",
    "        shortestPath_melted['same_type'] = shortestPath_melted['type1'] == shortestPath_melted['type2']\n",
    "        shortestPath_melted.loc[(~shortestPath_melted.smae_type), 'value'] = shortestPath_melted.loc[(~shortestPath_melted.same_type),\n",
    "                                                                                                     'value'] * aware_power\n",
    "        shortestPath_melted.drop(['type1', 'type2', 'same_type'], axis=1, inplace=True)\n",
    "        shortestPath_pivot = shortestPath_melted.pivot(index='id1', columns='id2', values='value')\n",
    "\n",
    "        order = spot_ids\n",
    "        shortestPath = shortestPath_pivot[order].loc[order].values\n",
    "    else:\n",
    "        shortestPath = np.asarray(shortestPath) #ensure it's a numpy array\n",
    "\n",
    "    #mask out infinite distances\n",
    "    mask = shortestPath != float('inf')\n",
    "    if mask.any():\n",
    "        the_max = np.max(shortestPath[mask])\n",
    "        shortestPath[~mask] = the_max #replace inf with max value\n",
    "    else:\n",
    "        the_max = 1.0 #fallback if all are inf (should not happen in connected graphs)\n",
    "\n",
    "    #store original max distance for scale reference\n",
    "    original_max_distance = the_max\n",
    "    C_dis = shortestPath / the_max\n",
    "    # C_dis = shortestPath\n",
    "    # C_dis -= np.mean(C_dis)\n",
    "\n",
    "    return C_dis, original_max_distance\n",
    "\n",
    "def calculate_D_st_from_coords(spatial_coords, X_st=None, k_neighbors=10, graph_mode='distance', aware_st=False, \n",
    "                               spot_types=None, aware_power_st=2, spot_ids=None):\n",
    "    '''calculates the spatial distance matrix D_st for spatial transcriptomics data directly from coordinates and optional spot types\n",
    "    args:\n",
    "        spatial_coords: spatial coordinates of spots (n_spots * 2)\n",
    "        X_st: St gene expression data (not used for D_st calculation itself)\n",
    "        k_neighbors: number of neighbors for knn graph\n",
    "        graph_mode: 'connectivity or 'distance' for knn graph\n",
    "        aware_st: whether to use type-aware distance adjustment\n",
    "        spot_types: pandas series of spot types for type-aware adjustment\n",
    "        aware_power_st: power for type-aware distance adjustment\n",
    "        spot_ids: list or index of spot ids, required if spot_ids is provided\n",
    "        \n",
    "    returns:\n",
    "        np.ndarray: spatial disance matrix D_st'''\n",
    "    \n",
    "    if isinstance(spatial_coords, pd.DataFrame):\n",
    "        location_array = spatial_coords.values\n",
    "        if spot_ids is None:\n",
    "            spot_ids = spatial_coords.index.tolist() #use index of dataframe if available\n",
    "    elif isinstance(spatial_coords, np.ndarray):\n",
    "        location_array = spatial_coords\n",
    "        if spot_ids is None:\n",
    "            spot_ids = list(range(location_array.shape[0])) #generate default ids if not provided\n",
    "\n",
    "    else:\n",
    "        raise TypeError('spatial_coords must be a pandas dataframe or a numpy array')\n",
    "    \n",
    "    print(f'constructing {graph_mode} graph for ST data with k={k_neighbors}.....')\n",
    "    Xgraph_st = construct_graph_spatial(location_array, k=k_neighbors, mode=graph_mode)\n",
    "    \n",
    "    if aware_st:\n",
    "        if spot_types is None or spot_ids is None:\n",
    "            raise ValueError('spot_types and spot_ids must be provided when aware_st=True')\n",
    "        if not isinstance(spot_types, pd.Series):\n",
    "            spot_types = pd.Series(spot_types, idnex=spot_ids) \n",
    "        print('applying type aware distance adjustment for ST data')\n",
    "        print(f'aware power for ST: {aware_power_st}')\n",
    "    else:\n",
    "        spot_types = None \n",
    "\n",
    "    print(f'calculating spatial distances.....')\n",
    "    D_st, st_max_distance = distances_cal_spatial(Xgraph_st, spot_ids=spot_ids, spot_types=spot_types, aware_power=aware_power_st)\n",
    "\n",
    "    print('D_st calculation complete')\n",
    "    return D_st, st_max_distance\n",
    "\n",
    "\n",
    "def calculate_D_st_euclidean(spatial_coords):\n",
    "    \"\"\"\n",
    "    Calculate Euclidean distance matrix for ST spots.\n",
    "    \n",
    "    Args:\n",
    "        spatial_coords: (m_spots, 2) spatial coordinates\n",
    "        \n",
    "    Returns:\n",
    "        D_st_euclid: (m_spots, m_spots) normalized Euclidean distance matrix\n",
    "    \"\"\"\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "    \n",
    "    if isinstance(spatial_coords, pd.DataFrame):\n",
    "        coords_array = spatial_coords.values\n",
    "    elif isinstance(spatial_coords, np.ndarray):\n",
    "        coords_array = spatial_coords\n",
    "    else:\n",
    "        coords_array = np.array(spatial_coords)\n",
    "    \n",
    "    # Compute pairwise Euclidean distances\n",
    "    D_euclid = squareform(pdist(coords_array, metric='euclidean'))\n",
    "    \n",
    "    # Normalize to [0,1]\n",
    "    max_dist = D_euclid.max()\n",
    "    if max_dist > 0:\n",
    "        D_euclid = D_euclid / max_dist\n",
    "    \n",
    "    return D_euclid.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_D_induced_proper_scaling(T, D_st, n_sc, n_st):\n",
    "    '''compute D_induced with proper scaling'''\n",
    "    #reweight transport matrix\n",
    "    T_reweight = T * n_sc\n",
    "    D_induced_raw = T_reweight @ D_st @ T_reweight.t()\n",
    "\n",
    "    #normalize to [0,1] range\n",
    "    D_induced_max = torch.max(D_induced_raw[D_induced_raw > 0])\n",
    "    if D_induced_max > 1e-10: #avoid dvision by very small numbers\n",
    "        D_induced = D_induced_raw / D_induced_max\n",
    "    else:\n",
    "        D_induced = D_induced_raw\n",
    "\n",
    "    return D_induced\n",
    "\n",
    "def fused_gw_torch(X_sc, X_st, Y_st, alpha, k_sc=100, k_st=30, G0=None, max_iter = 100, tol=1e-9, epsilon=0.1, device='cuda', n_iter = 1, D_st_precomputed=None):\n",
    "    n = X_sc.shape[0]\n",
    "    m = X_st.shape[0]\n",
    "\n",
    "    X_sc = X_sc.to(device)\n",
    "    X_st = X_st.to(device)\n",
    "\n",
    "    if not torch.is_tensor(Y_st):\n",
    "        Y_st_tensor = torch.tensor(Y_st, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        Y_st_tensor = Y_st.to(device, dtype=torch.float32)\n",
    "\n",
    "    #calculate distance matrices\n",
    "    print('calculating SC distances with knn-dijkstra.....')\n",
    "    D_sc, sc_max_distance = calculate_D_sc_torch(X_sc, graph_mode='distance', k_neighbors=k_sc, device=device)\n",
    "\n",
    "    if D_st_precomputed is not None:\n",
    "        print(\"Using precomputed block-diagonal D_st...\")\n",
    "        D_st = D_st_precomputed.to(device)\n",
    "        st_max_distance = 1.0 #assume already normalized\n",
    "    else:\n",
    "        print('Calculating ST distances.....')\n",
    "        D_st, st_max_distance = calculate_D_st_from_coords(spatial_coords=Y_st, k_neighbors=k_st, graph_mode=\"distance\")\n",
    "        D_st = torch.tensor(D_st, dtype=torch.float32, device=device)\n",
    "\n",
    "    #get expression distance matrix\n",
    "    C_exp = torch.cdist(X_sc, X_st, p=2) #euclidean distance\n",
    "    C_exp = C_exp / (torch.max(C_exp) + 1e-16) #normalize\n",
    "\n",
    "    #ensure distance matries are C-contiguouse numpy arrays for POT\n",
    "    D_sc_np = D_sc.cpu().numpy()\n",
    "    D_st_np = D_st.cpu().numpy()\n",
    "    C_exp_np = C_exp.cpu().numpy()\n",
    "    D_sc_np = np.ascontiguousarray(D_sc_np)\n",
    "    D_st_np = np.ascontiguousarray(D_st_np)\n",
    "    C_exp_np = np.ascontiguousarray(C_exp_np)\n",
    "\n",
    "    #uniform distributions\n",
    "    p = ot.unif(n)\n",
    "    q = ot.unif(m)\n",
    "\n",
    "    #anneal the reg param over several steps\n",
    "    T_np = None\n",
    "    for i in range(n_iter):\n",
    "        T_np, log = ot.gromov.entropic_fused_gromov_wasserstein(\n",
    "            M=C_exp_np, \n",
    "            C1=D_sc_np, \n",
    "            C2=D_st_np,\n",
    "            p=p, \n",
    "            q=q, \n",
    "            loss_fun='square_loss',\n",
    "            epsilon=epsilon,\n",
    "            alpha=alpha,\n",
    "            G0=T_np if T_np is not None else (G0.cpu().numpy() if G0 is not None else None),\n",
    "            log=True,\n",
    "            verbose=True,\n",
    "            max_iter=max_iter,\n",
    "            tol=tol\n",
    "        )\n",
    "\n",
    "    fgw_dist = log['fgw_dist']\n",
    "\n",
    "    print(f'fgw distance: {fgw_dist}')\n",
    "\n",
    "    T = torch.tensor(T_np, dtype=torch.float32, device=device)\n",
    "\n",
    "    n_sc = X_sc.shape[0]\n",
    "    n_st = X_st.shape[0]\n",
    "\n",
    "    D_induced = compute_D_induced_proper_scaling(T, D_st, n_sc, n_st)\n",
    "\n",
    "    return T, D_sc, D_st, D_induced, fgw_dist, sc_max_distance, st_max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# patient 2 data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_cscc_data():\n",
    "    \"\"\"\n",
    "    Load and process the cSCC dataset with multiple ST replicates.\n",
    "    \"\"\"\n",
    "    print(\"Loading cSCC data...\")\n",
    "    \n",
    "    # Load SC data\n",
    "    scadata = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP2.h5ad')\n",
    "    \n",
    "    # Load all 3 ST datasets\n",
    "    stadata1 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2.h5ad')\n",
    "    stadata2 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep2.h5ad')\n",
    "    stadata3 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep3.h5ad')\n",
    "    \n",
    "    # Normalize and log transform\n",
    "    for adata in [scadata, stadata1, stadata2, stadata3]:\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "    \n",
    "    # Create rough cell types for SC data\n",
    "    scadata.obs['rough_celltype'] = scadata.obs['level1_celltype'].astype(str)\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CLEC9A','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CD1C','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='ASDC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='PDC','rough_celltype'] = 'PDC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='MDSC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='LC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Mac','rough_celltype'] = 'Myeloid cell'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Tcell','rough_celltype'] = 'T cell'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype']=='TSK','rough_celltype'] = 'TSK'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype'].isin(['Tumor_KC_Basal', 'Tumor_KC_Diff','Tumor_KC_Cyc']),'rough_celltype'] = 'NonTSK'\n",
    "    \n",
    "    return scadata, stadata1, stadata2, stadata3\n",
    "\n",
    "def prepare_combined_st_for_diffusion(stadata1, stadata2, stadata3, scadata):\n",
    "    \"\"\"\n",
    "    Combine all ST datasets for diffusion training while maintaining gene alignment.\n",
    "    Key innovation: Use ALL ST data points for better training.\n",
    "    \"\"\"\n",
    "    print(\"Preparing combined ST data for diffusion training...\")\n",
    "    \n",
    "    # Get common genes between SC and all ST datasets\n",
    "    sc_genes = set(scadata.var_names)\n",
    "    st1_genes = set(stadata1.var_names)\n",
    "    st2_genes = set(stadata2.var_names)\n",
    "    st3_genes = set(stadata3.var_names)\n",
    "    \n",
    "    common_genes = sorted(list(sc_genes & st1_genes & st2_genes & st3_genes))\n",
    "    print(f\"Common genes across all datasets: {len(common_genes)}\")\n",
    "    \n",
    "    # Extract aligned expression data\n",
    "    sc_expr = scadata[:, common_genes].X\n",
    "    st1_expr = stadata1[:, common_genes].X\n",
    "    st2_expr = stadata2[:, common_genes].X\n",
    "    st3_expr = stadata3[:, common_genes].X\n",
    "    \n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(sc_expr, 'toarray'):\n",
    "        sc_expr = sc_expr.toarray()\n",
    "    if hasattr(st1_expr, 'toarray'):\n",
    "        st1_expr = st1_expr.toarray()\n",
    "    if hasattr(st2_expr, 'toarray'):\n",
    "        st2_expr = st2_expr.toarray()\n",
    "    if hasattr(st3_expr, 'toarray'):\n",
    "        st3_expr = st3_expr.toarray()\n",
    "    \n",
    "    # Get spatial coordinates\n",
    "    st1_coords = stadata1.obsm['spatial']\n",
    "    st2_coords = stadata2.obsm['spatial']\n",
    "    st3_coords = stadata3.obsm['spatial']\n",
    "\n",
    "    # Store separate coordinate lists for block-diagonal graph\n",
    "    st_coords_list = [st1_coords, st2_coords, st3_coords]\n",
    "    \n",
    "    # Combine all ST data\n",
    "    st_expr_combined = np.vstack([st1_expr, st2_expr, st3_expr])\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    st_expr_combined = scaler.fit_transform(st_expr_combined)\n",
    "\n",
    "    st_coords_combined = np.vstack([st1_coords, st2_coords, st3_coords])\n",
    "\n",
    "    sc_expr = scaler.fit_transform(sc_expr)\n",
    "\n",
    "    \n",
    "    # Create dataset labels for tracking\n",
    "    dataset_labels = (['dataset1'] * len(st1_expr) + \n",
    "                     ['dataset2'] * len(st2_expr) + \n",
    "                     ['dataset3'] * len(st3_expr))\n",
    "    \n",
    "    print(f\"Combined ST data shape: {st_expr_combined.shape}\")\n",
    "    print(f\"Combined ST coords shape: {st_coords_combined.shape}\")\n",
    "    print(f\"SC data shape: {sc_expr.shape}\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_sc = torch.tensor(sc_expr, dtype=torch.float32)\n",
    "    X_st_combined = torch.tensor(st_expr_combined, dtype=torch.float32)\n",
    "    Y_st_combined = st_coords_combined.astype(np.float32)\n",
    "    \n",
    "    return X_sc, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list\n",
    "\n",
    "# Load and process data\n",
    "scadata, stadata1, stadata2, stadata3 = load_and_process_cscc_data()\n",
    "\n",
    "# Prepare combined data for diffusion\n",
    "X_sc, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list = prepare_combined_st_for_diffusion(\n",
    "    stadata1, stadata2, stadata3, scadata\n",
    ")\n",
    "\n",
    "print(f\"Data preparation complete!\")\n",
    "print(f\"SC cells: {X_sc.shape[0]}\")\n",
    "print(f\"Combined ST spots: {X_st_combined.shape[0]}\")\n",
    "print(f\"Common genes: {len(common_genes)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import cKDTree\n",
    "from typing import Optional, Dict, Tuple, List\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# =====================================================\n",
    "# PART X: Graph-VAE Components\n",
    "# =====================================================\n",
    "\n",
    "class GraphVAEEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph encoder that learns latent representations from ST spot graphs.\n",
    "    ⚠️ Do **not** touch `train_encoder`; its aligned embeddings are the sole conditioning signal throughout.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=128, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Two GraphConv layers as specified\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # MLP to output μ and log σ² FOR EACH NODE (not graph-level)\n",
    "        self.mu_head = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.logvar_head = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_weight=None, batch=None):\n",
    "        \"\"\"\n",
    "        x: node features (aligned embeddings E(X_st)) - shape (n_nodes, input_dim)\n",
    "        edge_index: graph edges from K-NN adjacency\n",
    "        edge_weight: optional edge weights\n",
    "        batch: not used since we want node-level representations\n",
    "        \n",
    "        Returns:\n",
    "        mu: (n_nodes, latent_dim)\n",
    "        logvar: (n_nodes, latent_dim)\n",
    "        \"\"\"\n",
    "        # Two GraphConv layers\n",
    "        h = torch.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        h = torch.relu(self.conv2(h, edge_index, edge_weight))\n",
    "        \n",
    "        # NO GLOBAL POOLING - we want node-level representations\n",
    "        # Output μ and log σ² for each node\n",
    "        mu = self.mu_head(h)        # Shape: (n_nodes, latent_dim)\n",
    "        logvar = self.logvar_head(h)  # Shape: (n_nodes, latent_dim)\n",
    "        \n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Reparameterization trick - works element-wise\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "class GraphVAEDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph decoder that outputs 2D coordinates from latent z + aligned embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=32, condition_dim=128, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.condition_dim = condition_dim\n",
    "        \n",
    "        # Concatenate latent z with aligned embedding for conditioning\n",
    "        input_dim = latent_dim + condition_dim\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2)  # Output 2D coordinates\n",
    "        )\n",
    "        \n",
    "    def forward(self, z, condition):\n",
    "        \"\"\"\n",
    "        z: latent vectors (batch_size, latent_dim)\n",
    "        condition: aligned embeddings E(X) (batch_size, condition_dim)\n",
    "        \"\"\"\n",
    "        # Concatenate latent with conditioning\n",
    "        combined = torch.cat([z, condition], dim=-1)\n",
    "        coords = self.decoder(combined)\n",
    "        return coords\n",
    "\n",
    "def precompute_knn_edges(coords, k=30, device='cuda'):\n",
    "    \"\"\"\n",
    "    Helper function to precompute K-NN edges for torch-geometric style layers.\n",
    "    Uses existing graph construction utilities where possible.\n",
    "    \"\"\"\n",
    "    if isinstance(coords, torch.Tensor):\n",
    "        coords_np = coords.cpu().numpy()\n",
    "    else:\n",
    "        coords_np = coords\n",
    "        \n",
    "    # Use existing construct_graph_spatial function\n",
    "    from sklearn.neighbors import kneighbors_graph\n",
    "    \n",
    "    # Build KNN graph\n",
    "    knn_graph = kneighbors_graph(\n",
    "        coords_np, \n",
    "        n_neighbors=k, \n",
    "        mode='connectivity', \n",
    "        include_self=False\n",
    "    )\n",
    "    \n",
    "    # Convert to torch-geometric format\n",
    "    from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "    edge_index, edge_weight = from_scipy_sparse_matrix(knn_graph)\n",
    "    \n",
    "    # CRITICAL FIX: Ensure correct dtypes\n",
    "    edge_index = edge_index.long().to(device)      # Edge indices should be long\n",
    "    edge_weight = edge_weight.float().to(device)   # Edge weights should be float32\n",
    "    \n",
    "    return edge_index, edge_weight\n",
    "\n",
    "class LatentDenoiser(nn.Module):\n",
    "    \"\"\"\n",
    "    Latent-space denoiser identical to current MLP/U-Net stack but for latent dim=32.\n",
    "    ⚠️ Do **not** touch `train_encoder`; its aligned embeddings are the sole conditioning signal throughout.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=32, condition_dim=128, hidden_dim=256, n_blocks=6):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.condition_dim = condition_dim\n",
    "        \n",
    "        # Time embedding (reuse existing SinusoidalEmbedding)\n",
    "        self.time_embed = nn.Sequential(\n",
    "            SinusoidalEmbedding(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Latent encoder\n",
    "        self.latent_encoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Condition encoder (for aligned embeddings)\n",
    "        self.condition_encoder = nn.Sequential(\n",
    "            nn.Linear(condition_dim, hidden_dim),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Denoising blocks (similar to existing hierarchical blocks)\n",
    "        self.denoising_blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            ) for _ in range(n_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Output head\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, z_noisy, t, condition):\n",
    "        \"\"\"\n",
    "        z_noisy: noisy latent vectors (batch_size, latent_dim)\n",
    "        t: timestep (batch_size,) - NOW 1D instead of 2D\n",
    "        condition: aligned embeddings E(X) (batch_size, condition_dim)\n",
    "        \"\"\"\n",
    "        # ENSURE inputs are 2D\n",
    "        if z_noisy.dim() > 2:\n",
    "            z_noisy = z_noisy.squeeze()\n",
    "        if condition.dim() > 2:\n",
    "            condition = condition.squeeze()\n",
    "            \n",
    "        # Handle 1D timestep input\n",
    "        if t.dim() == 1:\n",
    "            t = t.unsqueeze(1)  # Make it (batch_size, 1)\n",
    "        \n",
    "        # Encode inputs\n",
    "        z_enc = self.latent_encoder(z_noisy)\n",
    "        t_enc = self.time_embed(t)\n",
    "        c_enc = self.condition_encoder(condition)\n",
    "        \n",
    "        # Combine features\n",
    "        h = z_enc + t_enc + c_enc\n",
    "        \n",
    "        # Apply denoising blocks\n",
    "        for block in self.denoising_blocks:\n",
    "            h = h + block(h)  # Residual connections\n",
    "            \n",
    "        # Output predicted noise\n",
    "        noise_pred = self.output_head(h)\n",
    "        return noise_pred\n",
    "\n",
    "# =====================================================\n",
    "# PART 1: Advanced Network Components\n",
    "# =====================================================\n",
    "\n",
    "class FeatureNet(nn.Module):\n",
    "    def __init__(self, n_genes, n_embedding=[512, 256, 128], dp=0):\n",
    "        super(FeatureNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(n_genes, n_embedding[0])\n",
    "        self.bn1 = nn.LayerNorm(n_embedding[0])\n",
    "        self.fc2 = nn.Linear(n_embedding[0], n_embedding[1])\n",
    "        self.bn2 = nn.LayerNorm(n_embedding[1])\n",
    "        self.fc3 = nn.Linear(n_embedding[1], n_embedding[2])\n",
    "        \n",
    "        self.dp = nn.Dropout(dp)\n",
    "        \n",
    "    def forward(self, x, isdp=False):\n",
    "        if isdp:\n",
    "            x = self.dp(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class SinusoidalEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = np.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=x.device) * -emb)\n",
    "        emb = x.unsqueeze(-1) * emb.unsqueeze(0)\n",
    "        emb = torch.cat([emb.sin(), emb.cos()], dim=-1)\n",
    "        return emb\n",
    "\n",
    "import torch.optim as optim   \n",
    "from geomloss import SamplesLoss\n",
    "\n",
    "# OT refinement function\n",
    "def refine_with_ot(sc_coords, st_coords, n_steps=50, lr=1e-2):\n",
    "    \"\"\"\n",
    "    Refines SC coordinates by minimizing entropic OT divergence to ST coords.\n",
    "    sc_coords: Tensor (N,2) initial SC coordinates\n",
    "    st_coords: Tensor (M,2) ST spot coordinates\n",
    "    \"\"\"\n",
    "    sinkhorn = SamplesLoss(\"sinkhorn\", p=2, blur=0.05, scaling=0.9)\n",
    "    coords = sc_coords.clone().detach().requires_grad_(True)\n",
    "    optimizer = optim.Adam([coords], lr=lr)\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        optimizer.zero_grad()\n",
    "        loss_ot = sinkhorn(coords.unsqueeze(0), st_coords.unsqueeze(0))\n",
    "        loss_ot.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return coords.detach()\n",
    "    \n",
    "class OTGuidedSampler:\n",
    "    def __init__(self,\n",
    "                 T_opt: torch.Tensor,\n",
    "                 st_coords_norm: torch.Tensor,\n",
    "                 n_timesteps: int):\n",
    "        self.T_opt       = T_opt           # (n_sc, n_st)\n",
    "        self.st_coords   = st_coords_norm  # (n_st, 2)\n",
    "        self.n_timesteps = n_timesteps\n",
    "\n",
    "    def get_ot_guidance(self, sc_indices: List[int], t: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the expected OT‐based target for each sc index,\n",
    "        plus a small decaying jitter.\n",
    "        \"\"\"\n",
    "        if self.T_opt is None:\n",
    "            return None\n",
    "\n",
    "        guidance = []\n",
    "        for sc_idx in sc_indices:\n",
    "            st_w = self.T_opt[sc_idx]                 # (n_st,)\n",
    "            total = st_w.sum()\n",
    "            if total <= 0:\n",
    "                guidance.append(torch.zeros(2, device=self.st_coords.device))\n",
    "                continue\n",
    "            # expected spot location (no argmax sampling)\n",
    "            w_norm = st_w / total                    # normalize\n",
    "            target_mean = (w_norm.unsqueeze(1) * self.st_coords).sum(dim=0)\n",
    "            # decaying noise: maximal when t≈T, zero at t=0\n",
    "            noise_scale = 0.02 * (t / self.n_timesteps)\n",
    "            jitter = torch.randn_like(target_mean) * noise_scale\n",
    "            guidance.append(target_mean + jitter)\n",
    "\n",
    "        return torch.stack(guidance)  # (batch_size, 2)\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "class CellTypeEmbedding(nn.Module):\n",
    "    \"\"\"Learned embeddings for cell types\"\"\"\n",
    "    def __init__(self, num_cell_types, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_cell_types, embedding_dim)\n",
    "        \n",
    "    def forward(self, cell_type_indices):\n",
    "        return self.embedding(cell_type_indices)\n",
    "\n",
    "class UncertaintyHead(nn.Module):\n",
    "    \"\"\"Predicts coordinate uncertainty\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2)  # Uncertainty for x and y\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.softplus(self.net(x)) + 0.01  # Ensure positive uncertainty\n",
    "\n",
    "class PhysicsInformedLayer(nn.Module):\n",
    "    \"\"\"Incorporates cell non-overlap constraints\"\"\"\n",
    "    def __init__(self, feature_dim):\n",
    "        super().__init__()\n",
    "        self.radius_predictor = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        self.repulsion_strength = nn.Parameter(torch.tensor(0.1))\n",
    "        \n",
    "    def compute_repulsion_gradient(self, coords, radii, cell_types=None):\n",
    "        \"\"\"Compute repulsion forces between cells\"\"\"\n",
    "        batch_size = coords.shape[0]\n",
    "        \n",
    "        # Compute pairwise distances\n",
    "        distances = torch.cdist(coords, coords, p=2)\n",
    "        \n",
    "        # Compute sum of radii for each pair\n",
    "        radii_sum = radii + radii.T\n",
    "        \n",
    "        # Compute overlap (positive when cells overlap)\n",
    "        overlap = F.relu(radii_sum - distances + 1e-6)\n",
    "        \n",
    "        # Mask out self-interactions\n",
    "        mask = (1 - torch.eye(batch_size, device=coords.device))\n",
    "        overlap = overlap * mask\n",
    "        \n",
    "        # Compute repulsion forces\n",
    "        coord_diff = coords.unsqueeze(1) - coords.unsqueeze(0)  # (B, B, 2)\n",
    "        distances_safe = distances + 1e-6  # Avoid division by zero\n",
    "        \n",
    "        # Normalize direction vectors\n",
    "        directions = coord_diff / distances_safe.unsqueeze(-1)\n",
    "        \n",
    "        # Apply stronger repulsion for same cell types (optional)\n",
    "        if cell_types is not None:\n",
    "            same_type_mask = (cell_types.unsqueeze(1) == cell_types.unsqueeze(0)).float()\n",
    "            repulsion_weight = 1.0 + 0.5 * same_type_mask  # 50% stronger for same type\n",
    "        else:\n",
    "            # repulsion_weight = 1.0\n",
    "            batch_size = coords.shape[0]\n",
    "            repulsion_weight = torch.ones(batch_size, batch_size, device=coords.device)\n",
    "            \n",
    "        # Compute repulsion magnitude\n",
    "        repulsion_magnitude = overlap.unsqueeze(-1) * repulsion_weight.unsqueeze(-1)\n",
    "        \n",
    "        # Sum repulsion forces from all other cells\n",
    "        repulsion_forces = (repulsion_magnitude * directions * mask.unsqueeze(-1)).sum(dim=1)\n",
    "        \n",
    "        return repulsion_forces\n",
    "        \n",
    "    def forward(self, coords, features, cell_types=None):\n",
    "        # Predict cell radii based on features\n",
    "        radii = self.radius_predictor(features).squeeze(-1) * 0.01  # Scale to reasonable size\n",
    "        \n",
    "        # Compute repulsion gradient\n",
    "        repulsion_grad = self.compute_repulsion_gradient(coords, radii, cell_types)\n",
    "        \n",
    "        return repulsion_grad * self.repulsion_strength, radii\n",
    "    \n",
    "class SpatialBatchSampler:\n",
    "    \"\"\"Sample spatially contiguous batches for geometric attention\"\"\"\n",
    "    \n",
    "    def __init__(self, coordinates, batch_size, k_neighbors=None):\n",
    "        \"\"\"\n",
    "        coordinates: (N, 2) array of spatial coordinates\n",
    "        batch_size: size of each batch\n",
    "        k_neighbors: number of neighbors to precompute (default: batch_size)\n",
    "        \"\"\"\n",
    "        self.coordinates = coordinates\n",
    "        self.batch_size = batch_size\n",
    "        self.k_neighbors = k_neighbors or min(batch_size, len(coordinates))\n",
    "        \n",
    "        # Precompute nearest neighbors\n",
    "        self.nbrs = NearestNeighbors(\n",
    "            n_neighbors=self.k_neighbors, \n",
    "            algorithm='kd_tree'\n",
    "        ).fit(coordinates)\n",
    "        \n",
    "    def sample_spatial_batch(self):\n",
    "        \"\"\"Sample a spatially contiguous batch\"\"\"\n",
    "        # Pick random center point\n",
    "        center_idx = np.random.randint(len(self.coordinates))\n",
    "        \n",
    "        # Get k nearest neighbors\n",
    "        distances, indices = self.nbrs.kneighbors(\n",
    "            self.coordinates[center_idx:center_idx+1], \n",
    "            return_distance=True\n",
    "        )\n",
    "        \n",
    "        # Return indices as torch tensor\n",
    "        batch_indices = torch.tensor(indices.flatten()[:self.batch_size], dtype=torch.long)\n",
    "        return batch_indices\n",
    "\n",
    "# =====================================================\n",
    "# PART 2: Hierarchical Diffusion Architecture\n",
    "# =====================================================\n",
    "\n",
    "class HierarchicalDiffusionBlock(nn.Module):\n",
    "    \"\"\"Multi-scale diffusion block for coarse-to-fine generation\"\"\"\n",
    "    def __init__(self, dim, num_scales=3):\n",
    "        super().__init__()\n",
    "        self.num_scales = num_scales\n",
    "        \n",
    "        # Coarse-level predictor (for clusters/regions)\n",
    "        self.coarse_net = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim * 2, dim)\n",
    "        )\n",
    "        \n",
    "        # Fine-level predictor (for individual cells)\n",
    "        self.fine_net = nn.Sequential(\n",
    "            nn.Linear(dim * 2, dim * 2),  # Takes both coarse and fine features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim * 2, dim)\n",
    "        )\n",
    "        \n",
    "        # Scale mixing weights\n",
    "        self.scale_mixer = nn.Sequential(\n",
    "            nn.Linear(1, 64),  # Takes timestep\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_scales),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t, coarse_context=None):\n",
    "        # Determine scale weights based on timestep\n",
    "        scale_weights = self.scale_mixer(t.unsqueeze(-1))\n",
    "        \n",
    "        # Coarse prediction\n",
    "        coarse_pred = self.coarse_net(x)\n",
    "        \n",
    "        # Fine prediction (conditioned on coarse if available)\n",
    "        if coarse_context is not None:\n",
    "            fine_input = torch.cat([x, coarse_context], dim=-1)\n",
    "        else:\n",
    "            fine_input = torch.cat([x, coarse_pred], dim=-1)\n",
    "        fine_pred = self.fine_net(fine_input)\n",
    "        \n",
    "        # Mix scales based on timestep\n",
    "        output = scale_weights[:, 0:1] * coarse_pred + scale_weights[:, 1:2] * fine_pred\n",
    "        \n",
    "        return output  \n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# PART 3: Main Advanced Diffusion Model\n",
    "# =====================================================\n",
    "\n",
    "class AdvancedHierarchicalDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        st_gene_expr,\n",
    "        st_coords,\n",
    "        sc_gene_expr,\n",
    "        cell_types_sc=None,  # Cell type labels for SC data\n",
    "        transport_plan=None,  # Optimal transport plan from domain alignment\n",
    "        D_st=None,\n",
    "        D_induced=None,\n",
    "        n_genes=None,\n",
    "        # n_embedding=128,\n",
    "        n_embedding=[512, 256, 128],\n",
    "        coord_space_diameter=200,\n",
    "        st_max_distance=None,\n",
    "        sc_max_distance=None,\n",
    "        sigma=3.0,\n",
    "        alpha=0.9,\n",
    "        mmdbatch=0.1,\n",
    "        batch_size=64,\n",
    "        device='cuda',\n",
    "        lr_e=0.0001,\n",
    "        lr_d=0.0002,\n",
    "        n_timesteps=1000,\n",
    "        n_denoising_blocks=6,\n",
    "        hidden_dim=512,\n",
    "        num_heads=8,\n",
    "        num_hierarchical_scales=3,\n",
    "        dp=0.1,\n",
    "        outf='output'\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.diffusion_losses = {\n",
    "            'total': [],\n",
    "            'diffusion': [],\n",
    "            'struct': [],\n",
    "            'physics': [],\n",
    "            'uncertainty': [],\n",
    "            'epochs': []\n",
    "        }\n",
    "\n",
    "        # Loss tracking for Graph-VAE training\n",
    "        self.vae_losses = {\n",
    "            'total': [],\n",
    "            'reconstruction': [],\n",
    "            'kl': [],\n",
    "            'epochs': []\n",
    "        }\n",
    "        \n",
    "        # Loss tracking for Latent Diffusion training  \n",
    "        self.latent_diffusion_losses = {\n",
    "            'total': [],\n",
    "            'diffusion': [],\n",
    "            'struct': [],\n",
    "            'epochs': []\n",
    "        }\n",
    "        \n",
    "        # Keep encoder losses separate (if you want to track them)\n",
    "        self.encoder_losses = {\n",
    "            'total': [],\n",
    "            'pred': [],\n",
    "            'circle': [],\n",
    "            'mmd': [],\n",
    "            'epochs': []\n",
    "        }\n",
    "        \n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.sigma = sigma\n",
    "        self.alpha = alpha\n",
    "        self.mmdbatch = mmdbatch\n",
    "        self.n_embedding = n_embedding\n",
    "        \n",
    "        # Create output directory\n",
    "        self.outf = outf\n",
    "        if not os.path.exists(outf):\n",
    "            os.makedirs(outf)\n",
    "        \n",
    "        # Store data\n",
    "        self.st_gene_expr = torch.tensor(st_gene_expr, dtype=torch.float32).to(device)\n",
    "        self.st_coords = torch.tensor(st_coords, dtype=torch.float32).to(device)\n",
    "        self.sc_gene_expr = torch.tensor(sc_gene_expr, dtype=torch.float32).to(device)\n",
    "\n",
    "        \n",
    "        # Temperature regularization for geometric attention\n",
    "        self.temp_weight_decay = 1e-4\n",
    "        \n",
    "        # Store transport plan if provided\n",
    "        self.transport_plan = torch.tensor(transport_plan, dtype=torch.float32).to(device) if transport_plan is not None else None\n",
    "        \n",
    "        # Process cell types\n",
    "        if cell_types_sc is not None:\n",
    "            # Convert cell type strings to indices\n",
    "            unique_cell_types = np.unique(cell_types_sc)\n",
    "            self.cell_type_to_idx = {ct: i for i, ct in enumerate(unique_cell_types)}\n",
    "            self.num_cell_types = len(unique_cell_types)\n",
    "            cell_type_indices = [self.cell_type_to_idx[ct] for ct in cell_types_sc]\n",
    "            self.sc_cell_types = torch.tensor(cell_type_indices, dtype=torch.long).to(device)\n",
    "        else:\n",
    "            self.sc_cell_types = None\n",
    "            self.num_cell_types = 0\n",
    "            \n",
    "        # Store distance matrices\n",
    "        self.D_st = torch.tensor(D_st, dtype=torch.float32).to(device) if D_st is not None else None\n",
    "        self.D_induced = torch.tensor(D_induced, dtype=torch.float32).to(device) if D_induced is not None else None\n",
    "\n",
    "        # If D_st is not provided, calculate it from spatial coordinates\n",
    "        if self.D_st is None:\n",
    "            print(\"D_st not provided, calculating from spatial coordinates...\")\n",
    "            if isinstance(st_coords, torch.Tensor):\n",
    "                st_coords_np = st_coords.cpu().numpy()\n",
    "            else:\n",
    "                st_coords_np = st_coords\n",
    "            \n",
    "            D_st_np, st_max_distance = calculate_D_st_from_coords(\n",
    "                spatial_coords=st_coords_np, \n",
    "                k_neighbors=50, \n",
    "                graph_mode=\"distance\"\n",
    "            )\n",
    "            self.D_st = torch.tensor(D_st_np, dtype=torch.float32).to(device)\n",
    "            self.st_max_distance = st_max_distance\n",
    "            print(f\"D_st calculated, shape: {self.D_st.shape}\")\n",
    "\n",
    "\n",
    "        print(f\"Final matrices - D_st: {self.D_st.shape if self.D_st is not None else None}, \"\n",
    "            f\"D_induced: {self.D_induced.shape if self.D_induced is not None else None}\")\n",
    "        \n",
    "        # Normalize coordinates\n",
    "        self.st_coords_norm, self.coords_center, self.coords_radius = self.normalize_coordinates_isotropic(self.st_coords)        \n",
    "        # Model parameters\n",
    "        self.n_genes = n_genes or st_gene_expr.shape[1]\n",
    "        \n",
    "        # ========== FEATURE ENCODER ==========\n",
    "        self.netE = self.build_feature_encoder(self.n_genes, n_embedding, dp)\n",
    "\n",
    "        self.train_log = os.path.join(outf, 'train.log')\n",
    "\n",
    "        \n",
    "        # ========== CELL TYPE EMBEDDING ==========\n",
    "\n",
    "        use_cell_types = (cell_types_sc is not None)  # Check if SC data has cell types\n",
    "        self.use_cell_types = use_cell_types\n",
    "\n",
    "        if self.num_cell_types > 0:\n",
    "            self.cell_type_embedding = CellTypeEmbedding(self.num_cell_types, n_embedding[-1] // 2)\n",
    "            total_feature_dim = n_embedding[-1] + n_embedding[-1] // 2\n",
    "        else:\n",
    "            self.cell_type_embedding = None\n",
    "            total_feature_dim = n_embedding[-1]\n",
    "            \n",
    "        # ========== HIERARCHICAL DIFFUSION COMPONENTS ==========\n",
    "        # Time embedding\n",
    "        self.time_embed = nn.Sequential(\n",
    "            SinusoidalEmbedding(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Coordinate encoder\n",
    "        self.coord_encoder = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Feature projection (includes cell type if available)\n",
    "        self.feat_proj = nn.Sequential(\n",
    "            nn.Linear(total_feature_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        # ========== GRAPH-VAE COMPONENTS (REPLACING HIERARCHICAL DIFFUSION) ==========        \n",
    "        # Graph-VAE parameters\n",
    "        self.latent_dim = 32  # As specified in instructions\n",
    "        \n",
    "        # Graph-VAE Encoder (learns latent representations from ST graphs)\n",
    "        self.graph_vae_encoder = GraphVAEEncoder(\n",
    "            input_dim=n_embedding[-1],  # Aligned embedding dimension\n",
    "            hidden_dim=128,             # GraphConv hidden dimension  \n",
    "            latent_dim=self.latent_dim\n",
    "        ).to(device)\n",
    "        \n",
    "        # Graph-VAE Decoder (outputs coordinates from latent + conditioning)\n",
    "        self.graph_vae_decoder = GraphVAEDecoder(\n",
    "            latent_dim=self.latent_dim,\n",
    "            condition_dim=n_embedding[-1],  # Same as aligned embedding\n",
    "            hidden_dim=128\n",
    "        ).to(device)\n",
    "        \n",
    "        # Latent Denoiser (replaces hierarchical_blocks)\n",
    "        self.latent_denoiser = LatentDenoiser(\n",
    "            latent_dim=self.latent_dim,\n",
    "            condition_dim=n_embedding[-1],\n",
    "            hidden_dim=hidden_dim,\n",
    "            n_blocks=n_denoising_blocks\n",
    "        ).to(device)\n",
    "        \n",
    "        # ========== HIERARCHICAL DENOISING BLOCKS ==========\n",
    "        self.hierarchical_blocks = nn.ModuleList([\n",
    "            HierarchicalDiffusionBlock(hidden_dim, num_hierarchical_scales)\n",
    "            for _ in range(n_denoising_blocks)\n",
    "        ])    \n",
    "\n",
    "        # ========== PHYSICS-INFORMED COMPONENTS ==========\n",
    "        self.physics_layer = PhysicsInformedLayer(hidden_dim)\n",
    "        \n",
    "        # ========== UNCERTAINTY QUANTIFICATION ==========\n",
    "        self.uncertainty_head = UncertaintyHead(hidden_dim)\n",
    "        \n",
    "        # ========== OPTIMAL TRANSPORT GUIDANCE ==========\n",
    "        if self.transport_plan is not None:\n",
    "            self.ot_guidance_strength = nn.Parameter(torch.tensor(0.1))\n",
    "            \n",
    "        # ========== OUTPUT LAYERS ==========\n",
    "        self.noise_predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2)\n",
    "        )\n",
    "        \n",
    "        # Create noise schedule\n",
    "        self.noise_schedule = self.create_noise_schedule()\n",
    "        \n",
    "        # Optimizers\n",
    "        self.setup_optimizers(lr_e, lr_d)\n",
    "        \n",
    "        # MMD Loss for domain alignment\n",
    "        self.mmd_loss = MMDLoss()\n",
    "\n",
    "        # Move entire model to device\n",
    "        self.to(self.device)\n",
    "\n",
    "    def setup_spatial_sampling(self):\n",
    "        if hasattr(self, 'st_coords_norm'):\n",
    "            self.spatial_sampler = SpatialBatchSampler(\n",
    "                coordinates=self.st_coords_norm.cpu().numpy(),\n",
    "                batch_size=self.batch_size\n",
    "            )\n",
    "        else:\n",
    "            self.spatial_sampler = None\n",
    "\n",
    "    def get_spatial_batch(self):\n",
    "        \"\"\"Get spatially contiguous batch for training\"\"\"\n",
    "        if self.spatial_sampler is not None:\n",
    "            return self.spatial_sampler.sample_spatial_batch()\n",
    "        else:\n",
    "            # Fallback to random sampling\n",
    "            return torch.randperm(len(self.st_coords_norm))[:self.batch_size]\n",
    "        \n",
    "    def normalize_coordinates_isotropic(self, coords):\n",
    "        \"\"\"Normalize coordinates isotropically to [-1, 1]\"\"\"\n",
    "        center = coords.mean(dim=0)\n",
    "        centered_coords = coords - center\n",
    "        max_dist = torch.max(torch.norm(centered_coords, dim=1))\n",
    "        normalized_coords = centered_coords / (max_dist + 1e-8)\n",
    "        return normalized_coords, center, max_dist\n",
    "        \n",
    "\n",
    "    def build_feature_encoder(self, n_genes, n_embedding, dp):\n",
    "        \"\"\"Build the feature encoder network\"\"\"\n",
    "        return FeatureNet(n_genes, n_embedding=n_embedding, dp=dp).to(self.device)\n",
    "        \n",
    "    def create_noise_schedule(self):\n",
    "        \"\"\"Create the noise schedule for diffusion\"\"\"\n",
    "        betas = torch.linspace(0.0001, 0.02, self.n_timesteps, device=self.device)\n",
    "        alphas = 1 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        \n",
    "        return {\n",
    "            'betas': betas,\n",
    "            'alphas': alphas,\n",
    "            'alphas_cumprod': alphas_cumprod,\n",
    "            'sqrt_alphas_cumprod': torch.sqrt(alphas_cumprod),\n",
    "            'sqrt_one_minus_alphas_cumprod': torch.sqrt(1 - alphas_cumprod)\n",
    "        }\n",
    "        \n",
    "    def setup_optimizers(self, lr_e, lr_d):\n",
    "        \"\"\"Setup optimizers and schedulers\"\"\"\n",
    "        # Encoder optimizer\n",
    "        self.optimizer_E = torch.optim.AdamW(self.netE.parameters(), lr=0.002)               \n",
    "        self.scheduler_E = lr_scheduler.StepLR(self.optimizer_E, step_size=200, gamma=0.5) \n",
    "\n",
    "        # MMD Loss\n",
    "        self.mmd_fn = MMDLoss()   \n",
    "        \n",
    "        # Diffusion model optimizer\n",
    "        diff_params = []\n",
    "        diff_params.extend(self.time_embed.parameters())\n",
    "        diff_params.extend(self.coord_encoder.parameters())\n",
    "        diff_params.extend(self.feat_proj.parameters())\n",
    "        diff_params.extend(self.hierarchical_blocks.parameters())\n",
    "        # diff_params.extend(self.geometric_attention_blocks.parameters())\n",
    "        diff_params.extend(self.physics_layer.parameters())\n",
    "        diff_params.extend(self.uncertainty_head.parameters())\n",
    "        diff_params.extend(self.noise_predictor.parameters())\n",
    "        \n",
    "        if self.cell_type_embedding is not None:\n",
    "            diff_params.extend(self.cell_type_embedding.parameters())\n",
    "            \n",
    "        if self.transport_plan is not None:\n",
    "            diff_params.append(self.ot_guidance_strength)\n",
    "            \n",
    "        self.optimizer_diff = torch.optim.Adam(diff_params, lr=lr_d, betas=(0.9, 0.999))\n",
    "        self.scheduler_diff = lr_scheduler.CosineAnnealingWarmRestarts(self.optimizer_diff, T_0=500)\n",
    "        \n",
    "    def add_noise(self, coords, t, noise_schedule):\n",
    "        \"\"\"Add noise to coordinates according to the diffusion schedule\"\"\"\n",
    "        noise = torch.randn_like(coords)\n",
    "        sqrt_alphas_cumprod_t = noise_schedule['sqrt_alphas_cumprod'][t].view(-1, 1)\n",
    "        sqrt_one_minus_alphas_cumprod_t = noise_schedule['sqrt_one_minus_alphas_cumprod'][t].view(-1, 1)\n",
    "        \n",
    "        noisy_coords = sqrt_alphas_cumprod_t * coords + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "        return noisy_coords, noise\n",
    "        \n",
    "        \n",
    "    def forward_diffusion(self, noisy_coords, t, features, cell_types=None):\n",
    "        \"\"\"Forward pass through the advanced diffusion model\"\"\"\n",
    "        batch_size = noisy_coords.shape[0]\n",
    "        \n",
    "        # Encode inputs\n",
    "        time_emb = self.time_embed(t)\n",
    "        coord_emb = self.coord_encoder(noisy_coords)\n",
    "        \n",
    "        # Process features with optional cell type\n",
    "        if cell_types is not None and self.cell_type_embedding is not None:\n",
    "            cell_type_emb = self.cell_type_embedding(cell_types)\n",
    "            combined_features = torch.cat([features, cell_type_emb], dim=-1)\n",
    "        else:\n",
    "            #when no cell types, pad with zeros to match expected input size\n",
    "            if self.cell_type_embedding is not None:\n",
    "                #create zero padding for cell type embedding\n",
    "                cell_type_dim = self.n_embedding[-1] // 2\n",
    "                zero_padding = torch.zeros(batch_size, cell_type_dim, device=features.device)\n",
    "                combined_features = torch.cat([features, zero_padding], dim=-1)\n",
    "            else:\n",
    "                combined_features = features\n",
    "            # combined_features = features\n",
    "            \n",
    "        feat_emb = self.feat_proj(combined_features)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        h = coord_emb + time_emb + feat_emb\n",
    "        \n",
    "        # Process through hierarchical blocks with geometric attention\n",
    "        for i, block in enumerate(self.hierarchical_blocks):\n",
    "            h = block(h, t)\n",
    "                \n",
    "        # Predict noise\n",
    "        noise_pred = self.noise_predictor(h)\n",
    "        \n",
    "        # Compute physics-informed correction\n",
    "        physics_correction, cell_radii = self.physics_layer(noisy_coords, h, cell_types)\n",
    "        \n",
    "        # Compute uncertainty\n",
    "        uncertainty = self.uncertainty_head(h)\n",
    "        \n",
    "        # Apply corrections based on timestep (less physics at high noise)\n",
    "        # t_factor = 1 - t / self.n_timesteps  # 0 at start, 1 at end\n",
    "        # noise_pred = noise_pred + t_factor * physics_correction * 0.1\n",
    "        t_factor = (1 - t).unsqueeze(-1) #shape: (natch_size, 1)\n",
    "        noise_pred = noise_pred + t_factor * physics_correction * 0.1\n",
    "        \n",
    "        return noise_pred, uncertainty, cell_radii\n",
    "        \n",
    "    def train_encoder(self, n_epochs=1000, ratio_start=0, ratio_end=1.0):\n",
    "        \"\"\"Train the STEM encoder to align ST and SC data\"\"\"\n",
    "        print(\"Training STEM encoder...\")\n",
    "        \n",
    "        # Log training start\n",
    "        with open(self.train_log, 'a') as f:\n",
    "            localtime = time.asctime(time.localtime(time.time()))\n",
    "            f.write(f\"{localtime} - Starting STEM encoder training\\n\")\n",
    "            f.write(f\"n_epochs={n_epochs}, ratio_start={ratio_start}, ratio_end={ratio_end}\\n\")\n",
    "        \n",
    "        # Calculate spatial adjacency matrix\n",
    "        if self.sigma == 0:\n",
    "            nettrue = torch.eye(self.st_coords.shape[0], device=self.device)\n",
    "        else:\n",
    "            nettrue = torch.tensor(scipy.spatial.distance.cdist(\n",
    "                self.st_coords.cpu().numpy(), \n",
    "                self.st_coords.cpu().numpy()\n",
    "            ), device=self.device).to(torch.float32)\n",
    "            \n",
    "            sigma = self.sigma\n",
    "            nettrue = torch.exp(-nettrue**2/(2*sigma**2))/(np.sqrt(2*np.pi)*sigma)\n",
    "            nettrue = F.normalize(nettrue, p=1, dim=1)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            # Schedule for circle loss weight\n",
    "            ratio = ratio_start + (ratio_end - ratio_start) * min(epoch / (n_epochs * 0.8), 1.0)\n",
    "            \n",
    "            # Forward pass ST data\n",
    "            e_seq_st = self.netE(self.st_gene_expr, True)\n",
    "            \n",
    "            # Sample from SC data due to large size\n",
    "            sc_idx = torch.randint(0, self.sc_gene_expr.shape[0], (min(self.batch_size, self.mmdbatch),), device=self.device)\n",
    "            sc_batch = self.sc_gene_expr[sc_idx]\n",
    "            e_seq_sc = self.netE(sc_batch, False)\n",
    "            \n",
    "            # Calculate losses\n",
    "            self.optimizer_E.zero_grad()\n",
    "            \n",
    "            # Prediction loss (equivalent to netpred in STEM)\n",
    "            netpred = e_seq_st.mm(e_seq_st.t())\n",
    "            loss_E_pred = F.cross_entropy(netpred, nettrue, reduction='mean')\n",
    "            \n",
    "            # Mapping matrices\n",
    "            st2sc = F.softmax(e_seq_st.mm(e_seq_sc.t()), dim=1)\n",
    "            sc2st = F.softmax(e_seq_sc.mm(e_seq_st.t()), dim=1)\n",
    "            \n",
    "            # Circle loss\n",
    "            st2st = torch.log(st2sc.mm(sc2st) + 1e-7)\n",
    "            loss_E_circle = F.kl_div(st2st, nettrue, reduction='none').sum(1).mean()\n",
    "            \n",
    "            # MMD loss\n",
    "            ranidx = torch.randint(0, e_seq_sc.shape[0], (min(self.mmdbatch, e_seq_sc.shape[0]),), device=self.device)\n",
    "            loss_E_mmd = self.mmd_fn(e_seq_st, e_seq_sc[ranidx])\n",
    "            \n",
    "            # Total loss\n",
    "            loss_E = loss_E_pred + self.alpha * loss_E_mmd + ratio * loss_E_circle\n",
    "            \n",
    "            # Backward and optimize\n",
    "            loss_E.backward()\n",
    "            self.optimizer_E.step()\n",
    "            self.scheduler_E.step()\n",
    "            \n",
    "            # Log progress\n",
    "            if epoch % 200 == 0:\n",
    "                log_msg = (f\"Encoder epoch {epoch}/{n_epochs}, \"\n",
    "                          f\"Loss_E: {loss_E.item():.6f}, \"\n",
    "                          f\"Loss_E_pred: {loss_E_pred.item():.6f}, \"\n",
    "                          f\"Loss_E_circle: {loss_E_circle.item():.6f}, \"\n",
    "                          f\"Loss_E_mmd: {loss_E_mmd.item():.6f}, \"\n",
    "                          f\"Ratio: {ratio:.4f}\")\n",
    "                \n",
    "                print(log_msg)\n",
    "                with open(self.train_log, 'a') as f:\n",
    "                    f.write(log_msg + '\\n')\n",
    "                \n",
    "                # Save checkpoint\n",
    "                if epoch % 500 == 0:\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'netE_state_dict': self.netE.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer_E.state_dict(),\n",
    "                        'scheduler_state_dict': self.scheduler_E.state_dict(),\n",
    "                    }, os.path.join(self.outf, f'encoder_checkpoint_epoch_{epoch}.pt'))\n",
    "        \n",
    "        # Save final encoder\n",
    "        torch.save({\n",
    "            'netE_state_dict': self.netE.state_dict(),\n",
    "        }, os.path.join(self.outf, 'final_encoder.pt'))\n",
    "        \n",
    "        print(\"Encoder training complete!\")\n",
    "\n",
    "    def train_graph_vae(self, epochs=800, lr=1e-3):\n",
    "        \"\"\"\n",
    "        Train the Graph-VAE that learns the outline.\n",
    "        ⚠️ Do **not** touch `train_encoder`; its aligned embeddings are the sole conditioning signal throughout.\n",
    "        \"\"\"\n",
    "        print(\"Training Graph-VAE...\")\n",
    "        \n",
    "        # Freeze encoder as specified\n",
    "        self.netE.eval()\n",
    "        for param in self.netE.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Build graph from ST spatial coordinates\n",
    "        print(\"Building spatial graph for ST data...\")\n",
    "        adj_idx, adj_w = precompute_knn_edges(self.st_coords_norm, k=30, device=self.device)\n",
    "\n",
    "        self._current_adj_idx = adj_idx\n",
    "        \n",
    "        # Get aligned embeddings E(X_st) using trained encoder\n",
    "        with torch.no_grad():\n",
    "            st_features_aligned = self.netE(self.st_gene_expr)\n",
    "            # ENSURE FLOAT32 DTYPE\n",
    "            st_features_aligned = st_features_aligned.float()\n",
    "        \n",
    "        # Optimizers for Graph-VAE components\n",
    "        vae_params = list(self.graph_vae_encoder.parameters()) + list(self.graph_vae_decoder.parameters())\n",
    "        optimizer_vae = torch.optim.Adam(vae_params, lr=lr, weight_decay=1e-5)\n",
    "        scheduler_vae = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_vae, T_max=epochs)\n",
    "        \n",
    "        # Training loop\n",
    "        best_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            optimizer_vae.zero_grad()\n",
    "            \n",
    "            # Forward pass through VAE encoder (now returns node-level representations)\n",
    "            mu, logvar = self.graph_vae_encoder(st_features_aligned, adj_idx, adj_w)\n",
    "            \n",
    "            # Reparameterization trick (now works element-wise)\n",
    "            z = self.graph_vae_encoder.reparameterize(mu, logvar)\n",
    "            \n",
    "            # Decode to coordinates (now z and st_features_aligned have same batch size)\n",
    "            coords_pred = self.graph_vae_decoder(z, st_features_aligned)\n",
    "            \n",
    "            # Compute losses as specified\n",
    "            # L_recon = MSE between decoded coords and true st_coords_norm\n",
    "            L_recon = torch.nn.functional.mse_loss(coords_pred, self.st_coords_norm)\n",
    "            \n",
    "            # L_KL = D_KL(q(z|x) || N(0, I)) - sum over all nodes and latent dims\n",
    "            L_KL = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / mu.shape[0]\n",
    "            \n",
    "            # Combined loss with specified weights (λ_recon : λ_KL = 1.0 : 0.01)\n",
    "            # total_loss = 1.0 * L_recon + 0.1 * L_KL\n",
    "            lambda_recon = 1.0\n",
    "            lambda_KL    = 0.01   # <<<< drop this from 1.0 down to 1e-3 or even 0\n",
    "\n",
    "            total_loss = lambda_recon * L_recon +  lambda_KL * L_KL\n",
    "\n",
    "            # Record losses for plotting\n",
    "            self.vae_losses['total'].append(total_loss.item())\n",
    "            self.vae_losses['reconstruction'].append(L_recon.item())\n",
    "            self.vae_losses['kl'].append(L_KL.item())\n",
    "            self.vae_losses['epochs'].append(epoch)\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss.backward()\n",
    "            optimizer_vae.step()\n",
    "            scheduler_vae.step()\n",
    "            \n",
    "            # Logging\n",
    "            if epoch % 200 == 0:\n",
    "                log_msg = (f\"Graph-VAE epoch {epoch}/{epochs}, \"\n",
    "                        f\"Total Loss: {total_loss.item():.6f}, \"\n",
    "                        f\"L_recon: {L_recon.item():.6f}, \"\n",
    "                        f\"L_KL: {L_KL.item():.6f}\")\n",
    "                print(log_msg)\n",
    "                with open(self.train_log, 'a') as f:\n",
    "                    f.write(log_msg + '\\n')\n",
    "            \n",
    "            # Save best model\n",
    "            if total_loss.item() < best_loss:\n",
    "                best_loss = total_loss.item()\n",
    "                torch.save({\n",
    "                    'encoder_state_dict': self.graph_vae_encoder.state_dict(),\n",
    "                    'decoder_state_dict': self.graph_vae_decoder.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'loss': best_loss\n",
    "                }, os.path.join(self.outf, 'best_graph_vae.pt'))\n",
    "        \n",
    "        # Save final models\n",
    "        torch.save({\n",
    "            'encoder_state_dict': self.graph_vae_encoder.state_dict(),\n",
    "            'decoder_state_dict': self.graph_vae_decoder.state_dict(),\n",
    "        }, os.path.join(self.outf, 'final_graph_vae.pt'))\n",
    "        \n",
    "        print(\"Graph-VAE training complete!\")\n",
    "\n",
    "    def train_diffusion_latent(self, n_epochs=400, lambda_struct=10.0):\n",
    "        \"\"\"\n",
    "        Train latent-space conditional DDPM.\n",
    "        ⚠️ Do **not** touch `train_encoder`; its aligned embeddings are the sole conditioning signal throughout.\n",
    "        \"\"\"\n",
    "        print(\"Training latent-space diffusion model...\")\n",
    "        \n",
    "        # Freeze encoder and Graph-VAE encoder\n",
    "        self.netE.eval()\n",
    "        self.graph_vae_encoder.eval()\n",
    "        for param in self.netE.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.graph_vae_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Precompute fixed ST latents as specified\n",
    "        print(\"Computing fixed ST latents...\")\n",
    "        st_adj_idx, st_adj_w = precompute_knn_edges(self.st_coords_norm, k=30, device=self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            st_features_aligned = self.netE(self.st_gene_expr)\n",
    "            # ENSURE FLOAT32 DTYPE\n",
    "            st_features_aligned = st_features_aligned.float()\n",
    "            st_mu, st_logvar = self.graph_vae_encoder(st_features_aligned, st_adj_idx, st_adj_w)\n",
    "            z_st = self.graph_vae_encoder.reparameterize(st_mu, st_logvar)\n",
    "        \n",
    "        # Setup optimizer for latent denoiser\n",
    "        optimizer_latent = torch.optim.AdamW(\n",
    "            self.latent_denoiser.parameters(), \n",
    "            lr=self.optimizer_diff.param_groups[0]['lr'], \n",
    "            weight_decay=1e-5\n",
    "        )\n",
    "        scheduler_latent = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer_latent, T_max=n_epochs, eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        # Training loop - identical to old train_diffusion but in latent space\n",
    "        best_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            # Sample batch\n",
    "            idx = torch.randperm(len(z_st))[:self.batch_size]\n",
    "            batch_z_st = z_st[idx]\n",
    "            batch_st_features = st_features_aligned[idx]\n",
    "            \n",
    "            # Sample random timesteps\n",
    "            t = torch.randint(0, self.n_timesteps, (len(batch_z_st),), device=self.device)\n",
    "            \n",
    "            # Add noise to latent vectors (targets = random noise in latent space)\n",
    "            noise = torch.randn_like(batch_z_st)\n",
    "            \n",
    "            # Get noise schedule parameters\n",
    "            alpha_t = self.noise_schedule['alphas_cumprod'][t].view(-1, 1)\n",
    "            \n",
    "            # Forward diffusion: add noise to clean latents\n",
    "            z_noisy = torch.sqrt(alpha_t) * batch_z_st + torch.sqrt(1 - alpha_t) * noise\n",
    "            \n",
    "            # Predict noise using latent denoiser\n",
    "            t_normalized = t.float().unsqueeze(1) / self.n_timesteps\n",
    "            noise_pred = self.latent_denoiser(z_noisy, t_normalized, batch_st_features)\n",
    "            \n",
    "            # Compute diffusion loss\n",
    "            loss_diffusion = torch.nn.functional.mse_loss(noise_pred, noise)\n",
    "            \n",
    "            # Structure loss in latent space (optional, can be simplified)\n",
    "            # loss_struct = 0.0\n",
    "            if lambda_struct > 0:\n",
    "                # Simple latent space structure loss\n",
    "                latent_distances = torch.cdist(batch_z_st, batch_z_st, p=2)\n",
    "                pred_distances = torch.cdist(noise_pred, noise_pred, p=2)\n",
    "                loss_struct = torch.nn.functional.mse_loss(pred_distances, latent_distances)\n",
    "            \n",
    "            # Combined loss\n",
    "            total_loss = loss_diffusion + lambda_struct * loss_struct\n",
    "\n",
    "            # Record losses for plotting\n",
    "            self.latent_diffusion_losses['total'].append(total_loss.item())\n",
    "            self.latent_diffusion_losses['diffusion'].append(loss_diffusion.item())\n",
    "            self.latent_diffusion_losses['struct'].append(loss_struct.item() if isinstance(loss_struct, torch.Tensor) else loss_struct)\n",
    "            self.latent_diffusion_losses['epochs'].append(epoch)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer_latent.zero_grad()\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.latent_denoiser.parameters(), 1.0)\n",
    "            optimizer_latent.step()\n",
    "            scheduler_latent.step()\n",
    "            \n",
    "            # Logging\n",
    "            if epoch % 500 == 0:\n",
    "                log_msg = (f\"Latent Diffusion epoch {epoch}/{n_epochs}, \"\n",
    "                        f\"Total Loss: {total_loss.item():.6f}, \"\n",
    "                        f\"Diffusion Loss: {loss_diffusion.item():.6f}, \"\n",
    "                        f\"Struct Loss: {loss_struct:.6f}\" if isinstance(loss_struct, float) \n",
    "                        else f\"Struct Loss: {loss_struct.item():.6f}\")\n",
    "                print(log_msg)\n",
    "                with open(self.train_log, 'a') as f:\n",
    "                    f.write(log_msg + '\\n')\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if epoch % 500 == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'latent_denoiser_state_dict': self.latent_denoiser.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer_latent.state_dict(),\n",
    "                }, os.path.join(self.outf, f'latent_diffusion_checkpoint_epoch_{epoch}.pt'))\n",
    "        \n",
    "        # Save final model\n",
    "        torch.save({\n",
    "            'latent_denoiser_state_dict': self.latent_denoiser.state_dict(),\n",
    "        }, os.path.join(self.outf, 'final_latent_diffusion.pt'))\n",
    "        \n",
    "        print(\"Latent diffusion training complete!\")\n",
    "                        \n",
    "\n",
    "    def train(self, encoder_epochs=1000, vae_epochs=800, diffusion_epochs=400, **kwargs):\n",
    "        \"\"\"\n",
    "        Combined training pipeline: encoder → graph_vae → diffusion_latent\n",
    "        ⚠️ Do **not** touch `train_encoder`; its aligned embeddings are the sole conditioning signal throughout.\n",
    "        \"\"\"\n",
    "        print(\"Starting Graph-VAE + Latent Diffusion training pipeline...\")\n",
    "        \n",
    "        # Stage 1: Train encoder (DO NOT MODIFY - keep existing train_encoder)\n",
    "        print(\"Stage 1: Training domain alignment encoder...\")\n",
    "        self.train_encoder(n_epochs=encoder_epochs)\n",
    "        \n",
    "        # Stage 2: Train Graph-VAE\n",
    "        print(\"Stage 2: Training Graph-VAE...\")\n",
    "        self.train_graph_vae(epochs=vae_epochs)\n",
    "        \n",
    "        # Stage 3: Train latent diffusion\n",
    "        print(\"Stage 3: Training latent diffusion...\")\n",
    "        self.train_diffusion_latent(n_epochs=diffusion_epochs, **kwargs)\n",
    "        \n",
    "        print(\"Complete training pipeline finished!\")\n",
    "\n",
    "    def sample_sc_coordinates_batched(self, batch_size=512):\n",
    "        \"\"\"\n",
    "        Batched version of sample_sc_coordinates to handle memory constraints.\n",
    "        ⚠️ Do **not** touch `train_encoder`; its aligned embeddings are the sole conditioning signal throughout.\n",
    "        \"\"\"\n",
    "        n_total = len(self.sc_gene_expr)\n",
    "        print(f\"Sampling {n_total} SC coordinates using Graph-VAE + Latent Diffusion (batched)...\")\n",
    "        \n",
    "        # Set models to eval mode\n",
    "        self.netE.eval()\n",
    "        self.graph_vae_encoder.eval()\n",
    "        self.graph_vae_decoder.eval()\n",
    "        self.latent_denoiser.eval()\n",
    "        \n",
    "        all_coords = []\n",
    "        n_batches = (n_total + batch_size - 1) // batch_size\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx in range(n_batches):\n",
    "                start_idx = batch_idx * batch_size\n",
    "                end_idx = min(start_idx + batch_size, n_total)\n",
    "                batch_sc_expr = self.sc_gene_expr[start_idx:end_idx]\n",
    "                \n",
    "                print(f\"Processing batch {batch_idx + 1}/{n_batches} ({len(batch_sc_expr)} cells)...\")\n",
    "                \n",
    "                # Get aligned SC embeddings for this batch\n",
    "                sc_features_aligned = self.netE(batch_sc_expr).float()\n",
    "                \n",
    "                # Build SC graph for this batch in expression space\n",
    "                sc_adj_idx, sc_adj_w = precompute_knn_edges(batch_sc_expr, k=30, device=self.device)\n",
    "                \n",
    "                # Get SC latents using Graph-VAE encoder\n",
    "                sc_mu, sc_logvar = self.graph_vae_encoder(sc_features_aligned, sc_adj_idx, sc_adj_w)\n",
    "                z_sc = self.graph_vae_encoder.reparameterize(sc_mu, sc_logvar)\n",
    "                \n",
    "                # ENSURE z_sc is 2D\n",
    "                if z_sc.dim() > 2:\n",
    "                    z_sc = z_sc.squeeze()\n",
    "                \n",
    "                # Initialize random noise in latent space\n",
    "                # z_t = torch.randn_like(z_sc)\n",
    "                # Instead of starting from pure random noise, start from noised Graph-VAE latents\n",
    "                eps = torch.randn_like(z_sc)\n",
    "                alpha_bar_T = self.noise_schedule['alphas_cumprod'][self.n_timesteps - 1]  # ᾱ_T (final timestep)\n",
    "                z_t = (alpha_bar_T.sqrt() * z_sc) + ((1 - alpha_bar_T).sqrt() * eps)\n",
    "                \n",
    "                # Reverse diffusion process in latent space\n",
    "                for t in reversed(range(self.n_timesteps)):\n",
    "                    # FIX: Use 1D timestep tensor instead of 2D\n",
    "                    t_tensor = torch.full((len(z_sc),), t / self.n_timesteps, device=self.device)\n",
    "                    \n",
    "                    # Predict noise in latent space\n",
    "                    noise_pred = self.latent_denoiser(z_t, t_tensor, sc_features_aligned)\n",
    "                    \n",
    "                    # ENSURE noise_pred is 2D\n",
    "                    if noise_pred.dim() > 2:\n",
    "                        noise_pred = noise_pred.squeeze()\n",
    "                    \n",
    "                    # Update latent representation (standard DDPM reverse step)\n",
    "                    alpha_t = self.noise_schedule['alphas'][t]\n",
    "                    alpha_cumprod_t = self.noise_schedule['alphas_cumprod'][t]\n",
    "                    beta_t = self.noise_schedule['betas'][t]\n",
    "                    \n",
    "                    if t > 0:\n",
    "                        noise = torch.randn_like(z_t)\n",
    "                    else:\n",
    "                        noise = 0\n",
    "                        \n",
    "                    z_t = (1 / torch.sqrt(alpha_t)) * (\n",
    "                        z_t - ((1 - alpha_t) / torch.sqrt(1 - alpha_cumprod_t)) * noise_pred\n",
    "                    ) + torch.sqrt(beta_t) * noise\n",
    "                    \n",
    "                    # ENSURE z_t stays 2D\n",
    "                    if z_t.dim() > 2:\n",
    "                        z_t = z_t.squeeze()\n",
    "                \n",
    "                    # ENSURE both inputs to decoder are 2D - FORCE CORRECT SHAPES\n",
    "                    if z_t.dim() > 2:\n",
    "                        # If z_t is [256, 256, 32], we want [256, 32] - take diagonal or first slice\n",
    "                        if z_t.shape[0] == z_t.shape[1]:  # Square matrix case\n",
    "                            # Take diagonal elements to get [256, 32]\n",
    "                            z_t = torch.diagonal(z_t, dim1=0, dim2=1).T\n",
    "                        else:\n",
    "                            z_t = z_t.squeeze()\n",
    "\n",
    "                    if sc_features_aligned.dim() > 2:\n",
    "                        sc_features_aligned = sc_features_aligned.squeeze()\n",
    "\n",
    "                    # print(f\"DEBUG AFTER FIX: z_t.shape = {z_t.shape}, sc_features_aligned.shape = {sc_features_aligned.shape}\")\n",
    "\n",
    "                # Decode final latent to 2D coordinates using Graph-VAE decoder\n",
    "                batch_coords = self.graph_vae_decoder(z_t, sc_features_aligned)\n",
    "                \n",
    "                # Move to CPU and store\n",
    "                all_coords.append(batch_coords.cpu())\n",
    "                \n",
    "                # Clear GPU cache between batches\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Combine all batches\n",
    "        final_coords = torch.cat(all_coords, dim=0)\n",
    "                \n",
    "        print(\"Batched sampling complete!\")\n",
    "        return final_coords.cpu().numpy()\n",
    "\n",
    "\n",
    "    def plot_training_losses(self):\n",
    "        \"\"\"Plot training losses for Graph-VAE + Latent Diffusion pipeline\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        \n",
    "        # Determine how many subplots we need\n",
    "        n_plots = 0\n",
    "        if len(self.vae_losses['epochs']) > 0:\n",
    "            n_plots += 2  # VAE losses and VAE smoothed\n",
    "        if len(self.latent_diffusion_losses['epochs']) > 0:\n",
    "            n_plots += 2  # Latent diffusion losses and smoothed\n",
    "        \n",
    "        if n_plots == 0:\n",
    "            print(\"No training losses to plot.\")\n",
    "            return\n",
    "        \n",
    "        # Create figure with appropriate number of subplots\n",
    "        if n_plots == 2:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            axes = [axes] if n_plots == 2 else axes\n",
    "        elif n_plots == 4:\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            axes = axes.flatten()\n",
    "        else:\n",
    "            fig, axes = plt.subplots(1, n_plots, figsize=(7*n_plots, 5))\n",
    "            if n_plots == 1:\n",
    "                axes = [axes]\n",
    "        \n",
    "        plot_idx = 0\n",
    "        \n",
    "        # Plot 1: Graph-VAE losses\n",
    "        if len(self.vae_losses['epochs']) > 0:\n",
    "            epochs_vae = np.array(self.vae_losses['epochs'])\n",
    "            ax = axes[plot_idx]\n",
    "            \n",
    "            ax.plot(epochs_vae, self.vae_losses['total'], 'b-', label='Total VAE Loss', linewidth=2)\n",
    "            ax.plot(epochs_vae, self.vae_losses['reconstruction'], 'g-', label='Reconstruction Loss', linewidth=2)\n",
    "            ax.plot(epochs_vae, np.array(self.vae_losses['kl']) * 0.01, 'r--', label='KL Loss (×0.01)', alpha=0.8)\n",
    "            \n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel('Loss')\n",
    "            ax.set_title('Graph-VAE Training Losses')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.set_yscale('log')\n",
    "            plot_idx += 1\n",
    "            \n",
    "            # Plot 2: Graph-VAE smoothed\n",
    "            if len(self.vae_losses['total']) > 1:\n",
    "                ax = axes[plot_idx]\n",
    "                window = min(50, len(self.vae_losses['total']) // 10)\n",
    "                if window > 1:\n",
    "                    smoothed = np.convolve(self.vae_losses['total'], \n",
    "                                        np.ones(window)/window, mode='valid')\n",
    "                    smooth_epochs = epochs_vae[window-1:]\n",
    "                    ax.plot(epochs_vae, self.vae_losses['total'], 'lightblue', alpha=0.5, label='Raw')\n",
    "                    ax.plot(smooth_epochs, smoothed, 'blue', linewidth=2, label=f'Smoothed (window={window})')\n",
    "                else:\n",
    "                    ax.plot(epochs_vae, self.vae_losses['total'], 'blue', linewidth=2)\n",
    "                \n",
    "                ax.set_xlabel('Epoch')\n",
    "                ax.set_ylabel('Loss')\n",
    "                ax.set_title('Graph-VAE Total Loss (Smoothed)')\n",
    "                if window > 1:\n",
    "                    ax.legend()\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                ax.set_yscale('log')\n",
    "                plot_idx += 1\n",
    "        \n",
    "        # Plot 3: Latent Diffusion losses\n",
    "        if len(self.latent_diffusion_losses['epochs']) > 0:\n",
    "            epochs_diff = np.array(self.latent_diffusion_losses['epochs'])\n",
    "            ax = axes[plot_idx]\n",
    "            \n",
    "            ax.plot(epochs_diff, self.latent_diffusion_losses['total'], 'b-', label='Total Loss', linewidth=2)\n",
    "            ax.plot(epochs_diff, self.latent_diffusion_losses['diffusion'], 'k-', label='Diffusion Loss', linewidth=2)\n",
    "            \n",
    "            # Only plot struct loss if it's non-zero\n",
    "            struct_losses = np.array(self.latent_diffusion_losses['struct'])\n",
    "            if np.any(struct_losses > 0):\n",
    "                ax.plot(epochs_diff, struct_losses, 'r--', label='Structure Loss', alpha=0.8)\n",
    "            \n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel('Loss')\n",
    "            ax.set_title('Latent Diffusion Training Losses')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.set_yscale('log')\n",
    "            plot_idx += 1\n",
    "            \n",
    "            # Plot 4: Latent Diffusion smoothed\n",
    "            if len(self.latent_diffusion_losses['total']) > 1:\n",
    "                ax = axes[plot_idx]\n",
    "                window = min(50, len(self.latent_diffusion_losses['total']) // 10)\n",
    "                if window > 1:\n",
    "                    smoothed = np.convolve(self.latent_diffusion_losses['total'],\n",
    "                                        np.ones(window)/window, mode='valid')\n",
    "                    smooth_epochs = epochs_diff[window-1:]\n",
    "                    ax.plot(epochs_diff, self.latent_diffusion_losses['total'], 'lightcoral', alpha=0.5, label='Raw')\n",
    "                    ax.plot(smooth_epochs, smoothed, 'red', linewidth=2, label=f'Smoothed (window={window})')\n",
    "                else:\n",
    "                    ax.plot(epochs_diff, self.latent_diffusion_losses['total'], 'red', linewidth=2)\n",
    "                \n",
    "                ax.set_xlabel('Epoch')\n",
    "                ax.set_ylabel('Loss')\n",
    "                ax.set_title('Latent Diffusion Total Loss (Smoothed)')\n",
    "                if window > 1:\n",
    "                    ax.legend()\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                ax.set_yscale('log')\n",
    "                plot_idx += 1\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print final loss values\n",
    "        print(\"\\n=== Training Loss Summary ===\")\n",
    "        \n",
    "        if len(self.vae_losses['total']) > 0:\n",
    "            print(f\"Graph-VAE - Initial Loss: {self.vae_losses['total'][0]:.6f}\")\n",
    "            print(f\"Graph-VAE - Final Loss: {self.vae_losses['total'][-1]:.6f}\")\n",
    "            print(f\"Graph-VAE - Loss Reduction: {(1 - self.vae_losses['total'][-1]/self.vae_losses['total'][0])*100:.2f}%\")\n",
    "            print(f\"Graph-VAE - Final Reconstruction Loss: {self.vae_losses['reconstruction'][-1]:.6f}\")\n",
    "            print(f\"Graph-VAE - Final KL Loss: {self.vae_losses['kl'][-1]:.6f}\")\n",
    "        \n",
    "        if len(self.latent_diffusion_losses['total']) > 0:\n",
    "            print(f\"Latent Diffusion - Initial Loss: {self.latent_diffusion_losses['total'][0]:.6f}\")\n",
    "            print(f\"Latent Diffusion - Final Loss: {self.latent_diffusion_losses['total'][-1]:.6f}\")\n",
    "            print(f\"Latent Diffusion - Loss Reduction: {(1 - self.latent_diffusion_losses['total'][-1]/self.latent_diffusion_losses['total'][0])*100:.2f}%\")\n",
    "            print(f\"Latent Diffusion - Final Diffusion Loss: {self.latent_diffusion_losses['diffusion'][-1]:.6f}\")\n",
    "            if np.any(np.array(self.latent_diffusion_losses['struct']) > 0):\n",
    "                print(f\"Latent Diffusion - Final Structure Loss: {self.latent_diffusion_losses['struct'][-1]:.6f}\")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# PART 4: MMD Loss Implementation\n",
    "# =====================================================\n",
    "\n",
    "class MMDLoss(nn.Module):\n",
    "    def __init__(self, kernel_type='rbf', kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "        super(MMDLoss, self).__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.fix_sigma = fix_sigma\n",
    "        self.kernel_type = kernel_type\n",
    "\n",
    "    def guassian_kernel(self, source, target, kernel_mul, kernel_num, fix_sigma):\n",
    "        n_samples = int(source.size()[0]) + int(target.size()[0])\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        total0 = total.unsqueeze(0).expand(\n",
    "            int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        total1 = total.unsqueeze(1).expand(\n",
    "            int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        L2_distance = ((total0-total1)**2).sum(2)\n",
    "        if fix_sigma:\n",
    "            bandwidth = fix_sigma\n",
    "        else:\n",
    "            bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "        bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "        bandwidth_list = [bandwidth * (kernel_mul**i)\n",
    "                          for i in range(kernel_num)]\n",
    "        kernel_val = [torch.exp(-L2_distance / bandwidth_temp)\n",
    "                      for bandwidth_temp in bandwidth_list]\n",
    "        tmp = 0\n",
    "        for x in kernel_val:\n",
    "            tmp += x\n",
    "        return tmp\n",
    "\n",
    "    def linear_mmd2(self, f_of_X, f_of_Y):\n",
    "        loss = 0.0\n",
    "        delta = f_of_X.float().mean(0) - f_of_Y.float().mean(0)\n",
    "        loss = delta.dot(delta.T)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        if self.kernel_type == 'linear':\n",
    "            return self.linear_mmd2(source, target)\n",
    "        elif self.kernel_type == 'rbf':\n",
    "            batch_size = int(source.size()[0])\n",
    "            kernels = self.guassian_kernel(\n",
    "                source, target, kernel_mul=self.kernel_mul, kernel_num=self.kernel_num, fix_sigma=self.fix_sigma)\n",
    "            XX = torch.mean(kernels[:batch_size, :batch_size])\n",
    "            YY = torch.mean(kernels[batch_size:, batch_size:])\n",
    "            XY = torch.mean(kernels[:batch_size, batch_size:])\n",
    "            YX = torch.mean(kernels[batch_size:, :batch_size])\n",
    "            loss = torch.mean(XX + YY - XY - YX)\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_cscc_data_individual_norm():\n",
    "    \"\"\"\n",
    "    Load and process cSCC data with individual normalization per ST dataset.\n",
    "    \"\"\"\n",
    "    print(\"Loading cSCC data with individual normalization...\")\n",
    "    \n",
    "    # Load SC data\n",
    "    scadata = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP2.h5ad')\n",
    "    \n",
    "    # Load all 3 ST datasets\n",
    "    stadata1 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2.h5ad')\n",
    "    stadata2 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep2.h5ad')\n",
    "    stadata3 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP2rep3.h5ad')\n",
    "    \n",
    "    # Normalize expression data (same for all)\n",
    "    for adata in [scadata, stadata1, stadata2, stadata3]:\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "    \n",
    "    # Create rough cell types for SC data\n",
    "    scadata.obs['rough_celltype'] = scadata.obs['level1_celltype'].astype(str)\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CLEC9A','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='CD1C','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='ASDC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='PDC','rough_celltype'] = 'PDC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='MDSC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='LC','rough_celltype'] = 'DC'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Mac','rough_celltype'] = 'Myeloid cell'\n",
    "    scadata.obs.loc[scadata.obs['level1_celltype']=='Tcell','rough_celltype'] = 'T cell'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype']=='TSK','rough_celltype'] = 'TSK'\n",
    "    scadata.obs.loc[scadata.obs['level2_celltype'].isin(['Tumor_KC_Basal', 'Tumor_KC_Diff','Tumor_KC_Cyc']),'rough_celltype'] = 'NonTSK'\n",
    "\n",
    "\n",
    "    \n",
    "    return scadata, stadata1, stadata2, stadata3\n",
    "\n",
    "def normalize_coordinates_individually(coords):\n",
    "    \"\"\"\n",
    "    Normalize coordinates to [-1, 1] range individually.\n",
    "    \"\"\"\n",
    "    coords_min = coords.min(axis=0)\n",
    "    coords_max = coords.max(axis=0)\n",
    "    coords_range = coords_max - coords_min\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    coords_range[coords_range == 0] = 1.0\n",
    "    \n",
    "    # Normalize to [-1, 1]\n",
    "    coords_normalized = 2 * (coords - coords_min) / coords_range - 1\n",
    "    \n",
    "    return coords_normalized, coords_min, coords_max, coords_range\n",
    "\n",
    "def prepare_individually_normalized_st_data(stadata1, stadata2, stadata3, scadata):\n",
    "    \"\"\"\n",
    "    Normalize each ST dataset individually, then combine.\n",
    "    \"\"\"\n",
    "    print(\"Preparing individually normalized ST data...\")\n",
    "    \n",
    "    # Get common genes\n",
    "    sc_genes = set(scadata.var_names)\n",
    "    st1_genes = set(stadata1.var_names)\n",
    "    st2_genes = set(stadata2.var_names)\n",
    "    st3_genes = set(stadata3.var_names)\n",
    "    \n",
    "    common_genes = sorted(list(sc_genes & st1_genes & st2_genes & st3_genes))\n",
    "    print(f\"Common genes across all datasets: {len(common_genes)}\")\n",
    "    \n",
    "    # Extract aligned expression data\n",
    "    sc_expr = scadata[:, common_genes].X\n",
    "    st1_expr = stadata1[:, common_genes].X\n",
    "    st2_expr = stadata2[:, common_genes].X\n",
    "    st3_expr = stadata3[:, common_genes].X\n",
    "    \n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(sc_expr, 'toarray'):\n",
    "        sc_expr = sc_expr.toarray()\n",
    "    if hasattr(st1_expr, 'toarray'):\n",
    "        st1_expr = st1_expr.toarray()\n",
    "    if hasattr(st2_expr, 'toarray'):\n",
    "        st2_expr = st2_expr.toarray()\n",
    "    if hasattr(st3_expr, 'toarray'):\n",
    "        st3_expr = st3_expr.toarray()\n",
    "    \n",
    "    # Get spatial coordinates and normalize individually\n",
    "    st1_coords = stadata1.obsm['spatial']\n",
    "    st2_coords = stadata2.obsm['spatial']\n",
    "    st3_coords = stadata3.obsm['spatial']\n",
    "    \n",
    "    print(\"Normalizing coordinates individually...\")\n",
    "    st1_coords_norm, st1_min, st1_max, st1_range = normalize_coordinates_individually(st1_coords)\n",
    "    st2_coords_norm, st2_min, st2_max, st2_range = normalize_coordinates_individually(st2_coords)\n",
    "    st3_coords_norm, st3_min, st3_max, st3_range = normalize_coordinates_individually(st3_coords)\n",
    "    \n",
    "    print(f\"ST1 coord range: [{st1_coords_norm.min():.3f}, {st1_coords_norm.max():.3f}]\")\n",
    "    print(f\"ST2 coord range: [{st2_coords_norm.min():.3f}, {st2_coords_norm.max():.3f}]\")\n",
    "    print(f\"ST3 coord range: [{st3_coords_norm.min():.3f}, {st3_coords_norm.max():.3f}]\")\n",
    "    \n",
    "    # Combine all ST data\n",
    "    st_expr_combined = np.vstack([st1_expr, st2_expr, st3_expr])\n",
    "    st_coords_combined = np.vstack([st1_coords_norm, st2_coords_norm, st3_coords_norm])\n",
    "    \n",
    "    # Create dataset metadata\n",
    "    dataset_info = {\n",
    "        'labels': (['dataset1'] * len(st1_expr) + \n",
    "                  ['dataset2'] * len(st2_expr) + \n",
    "                  ['dataset3'] * len(st3_expr)),\n",
    "        'normalization_params': {\n",
    "            'dataset1': {'min': st1_min, 'max': st1_max, 'range': st1_range},\n",
    "            'dataset2': {'min': st2_min, 'max': st2_max, 'range': st2_range},\n",
    "            'dataset3': {'min': st3_min, 'max': st3_max, 'range': st3_range}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"Combined ST data shape: {st_expr_combined.shape}\")\n",
    "    print(f\"Combined ST coords shape: {st_coords_combined.shape}\")\n",
    "    print(f\"SC data shape: {sc_expr.shape}\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_sc = torch.tensor(sc_expr, dtype=torch.float32)\n",
    "    X_st_combined = torch.tensor(st_expr_combined, dtype=torch.float32)\n",
    "    Y_st_combined = st_coords_combined.astype(np.float32)\n",
    "    \n",
    "    return X_sc, X_st_combined, Y_st_combined, dataset_info, common_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scadata, stadata1, stadata2, stadata3 = load_and_process_cscc_data_individual_norm()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cell_interactions_advanced(scadata, coords_key='advanced_diffusion_coords_avg'):\n",
    "    \"\"\"Analyze cell-cell interactions using the advanced diffusion coordinates\"\"\"\n",
    "    \n",
    "    # Get coordinates from scadata\n",
    "    coords_mean = scadata.obsm[coords_key]\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "    distances = squareform(pdist(coords_mean))\n",
    "    \n",
    "    # Get cell types\n",
    "    cell_types = scadata.obs['rough_celltype'].values\n",
    "    unique_types = np.unique(cell_types)\n",
    "    \n",
    "    # Analyze minimum distances between cell types\n",
    "    min_distances = {}\n",
    "    for i, type1 in enumerate(unique_types):\n",
    "        for j, type2 in enumerate(unique_types):\n",
    "            if i <= j:  # Include self-interactions\n",
    "                mask1 = cell_types == type1\n",
    "                mask2 = cell_types == type2\n",
    "                \n",
    "                if i == j:\n",
    "                    # Same cell type - exclude self\n",
    "                    sub_dist = distances[np.ix_(mask1, mask2)]\n",
    "                    np.fill_diagonal(sub_dist, np.inf)\n",
    "                    if sub_dist.size > 0:\n",
    "                        min_dist = np.min(sub_dist[sub_dist < np.inf])\n",
    "                    else:\n",
    "                        min_dist = np.nan\n",
    "                else:\n",
    "                    # Different cell types\n",
    "                    sub_dist = distances[np.ix_(mask1, mask2)]\n",
    "                    min_dist = np.min(sub_dist) if sub_dist.size > 0 else np.nan\n",
    "                \n",
    "                min_distances[(type1, type2)] = min_dist\n",
    "    \n",
    "    # Create interaction matrix visualization\n",
    "    interaction_matrix = np.full((len(unique_types), len(unique_types)), np.nan)\n",
    "    for i, type1 in enumerate(unique_types):\n",
    "        for j, type2 in enumerate(unique_types):\n",
    "            key = (type1, type2) if i <= j else (type2, type1)\n",
    "            if key in min_distances:\n",
    "                interaction_matrix[i, j] = min_distances[key]\n",
    "                interaction_matrix[j, i] = min_distances[key]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    mask = ~np.isnan(interaction_matrix)\n",
    "    sns.heatmap(interaction_matrix, \n",
    "                annot=True, fmt='.3f', \n",
    "                xticklabels=unique_types,\n",
    "                yticklabels=unique_types,\n",
    "                cmap='coolwarm_r',\n",
    "                mask=~mask,\n",
    "                cbar_kws={'label': 'Minimum Distance'})\n",
    "    plt.title(f'Minimum Distances Between Cell Types ({coords_key})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return min_distances, interaction_matrix\n",
    "\n",
    "def visualize_advanced_results_multi_model(scadata):\n",
    "    \"\"\"Visualize results from multiple models with uncertainty analysis\"\"\"\n",
    "    \n",
    "    # Get coordinates from all models\n",
    "    coords_avg = scadata.obsm['advanced_diffusion_coords_avg']\n",
    "    coords_rep1 = scadata.obsm['advanced_diffusion_coords_rep1'] \n",
    "    coords_rep2 = scadata.obsm['advanced_diffusion_coords_rep2']\n",
    "    coords_rep3 = scadata.obsm['advanced_diffusion_coords_rep3']\n",
    "    \n",
    "    # Calculate uncertainty metrics across models\n",
    "    all_coords = np.stack([coords_rep1, coords_rep2, coords_rep3], axis=0)  # (3, n_cells, 2)\n",
    "    coords_std = np.std(all_coords, axis=0)  # Standard deviation across models\n",
    "    coords_var = np.var(all_coords, axis=0)  # Variance across models\n",
    "    \n",
    "    # Total variability (combining x and y dimensions)\n",
    "    total_std = np.sqrt(coords_std[:, 0]**2 + coords_std[:, 1]**2)\n",
    "    total_var = coords_var[:, 0] + coords_var[:, 1]\n",
    "    \n",
    "    # Create confidence scores (inverse of variability)\n",
    "    confidence = 1 / (1 + total_std)\n",
    "    scadata.obs['spatial_confidence'] = confidence\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Spatial coordinates colored by cell type\n",
    "    ax = axes[0, 0]\n",
    "    cell_types = scadata.obs['rough_celltype']\n",
    "    unique_types = cell_types.unique()\n",
    "    colors = sns.color_palette('tab20', n_colors=len(unique_types))\n",
    "    \n",
    "    for i, ct in enumerate(unique_types):\n",
    "        mask = cell_types == ct\n",
    "        ax.scatter(coords_avg[mask, 0], coords_avg[mask, 1], \n",
    "                  c=[colors[i]], label=ct, s=30, alpha=0.7)\n",
    "    ax.set_title('Averaged Spatial Coordinates by Cell Type', fontsize=14)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    \n",
    "    # 2. Model variability (standard deviation across 3 models)\n",
    "    ax = axes[0, 1]\n",
    "    scatter = ax.scatter(coords_avg[:, 0], coords_avg[:, 1], \n",
    "                        c=total_std, cmap='viridis_r', \n",
    "                        s=30, alpha=0.7)\n",
    "    plt.colorbar(scatter, ax=ax, label='Model Std Dev')\n",
    "    ax.set_title('Model Prediction Variability', fontsize=14)\n",
    "    \n",
    "    # 3. X vs Y coordinate uncertainty\n",
    "    ax = axes[0, 2]\n",
    "    scatter = ax.scatter(coords_std[:, 0], coords_std[:, 1], \n",
    "                        c=total_std, cmap='plasma', s=30, alpha=0.7)\n",
    "    plt.colorbar(scatter, ax=ax, label='Total Std')\n",
    "    ax.set_xlabel('X Coordinate Std')\n",
    "    ax.set_ylabel('Y Coordinate Std')\n",
    "    ax.set_title('Coordinate Uncertainty (X vs Y)', fontsize=14)\n",
    "    \n",
    "    # 4. Cell density heatmap\n",
    "    ax = axes[1, 0]\n",
    "    from scipy.stats import gaussian_kde\n",
    "    xy = coords_avg.T\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    scatter = ax.scatter(coords_avg[:, 0], coords_avg[:, 1], \n",
    "                        c=z, cmap='hot', s=30, alpha=0.7)\n",
    "    plt.colorbar(scatter, ax=ax, label='Density')\n",
    "    ax.set_title('Cell Density (Averaged Coordinates)', fontsize=14)\n",
    "    \n",
    "    # 5. Confidence scores\n",
    "    ax = axes[1, 1]\n",
    "    scatter = ax.scatter(coords_avg[:, 0], coords_avg[:, 1], \n",
    "                        c=confidence, cmap='RdYlGn', s=30, alpha=0.7)\n",
    "    plt.colorbar(scatter, ax=ax, label='Confidence')\n",
    "    ax.set_title('Prediction Confidence Across Models', fontsize=14)\n",
    "    \n",
    "    # 6. Model agreement visualization\n",
    "    ax = axes[1, 2]\n",
    "    # Show cells where models agree vs disagree\n",
    "    high_agreement = total_std < np.percentile(total_std, 25)  # Bottom 25%\n",
    "    low_agreement = total_std > np.percentile(total_std, 75)   # Top 25%\n",
    "    \n",
    "    ax.scatter(coords_avg[high_agreement, 0], coords_avg[high_agreement, 1], \n",
    "              c='green', s=20, alpha=0.7, label='High Agreement')\n",
    "    ax.scatter(coords_avg[low_agreement, 0], coords_avg[low_agreement, 1], \n",
    "              c='red', s=20, alpha=0.7, label='Low Agreement')\n",
    "    ax.scatter(coords_avg[~(high_agreement | low_agreement), 0], \n",
    "              coords_avg[~(high_agreement | low_agreement), 1], \n",
    "              c='gray', s=10, alpha=0.5, label='Medium Agreement')\n",
    "    ax.set_title('Model Agreement', fontsize=14)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig, total_std, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_individual_advanced_diffusion_models(scadata, stadata1, stadata2, stadata3):\n",
    "    \"\"\"\n",
    "    Train separate AdvancedHierarchicalDiffusion models for each ST dataset and average the results.\n",
    "    \n",
    "    Returns:\n",
    "        scadata: Updated with averaged coordinates in obsm['advanced_diffusion_coords_avg']\n",
    "        models_all: All trained models for further analysis\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Store results from each model\n",
    "    sc_coords_results = []\n",
    "    models_all = []\n",
    "    \n",
    "    # List of ST datasets for iteration\n",
    "    st_datasets = [\n",
    "        (stadata1, \"dataset1\"),\n",
    "        (stadata2, \"dataset2\"), \n",
    "        (stadata3, \"dataset3\")\n",
    "    ]\n",
    "    \n",
    "    for i, (stadata, dataset_name) in enumerate(st_datasets):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training AdvancedHierarchicalDiffusion model {i+1}/3 for {dataset_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Get common genes between SC and current ST dataset\n",
    "        sc_genes = set(scadata.var_names)\n",
    "        st_genes = set(stadata.var_names)\n",
    "        common_genes = sorted(list(sc_genes & st_genes))\n",
    "        \n",
    "        print(f\"Common genes for {dataset_name}: {len(common_genes)}\")\n",
    "        \n",
    "        # Extract expression data\n",
    "        sc_expr = scadata[:, common_genes].X\n",
    "        st_expr = stadata[:, common_genes].X\n",
    "        \n",
    "        # Convert to dense if sparse\n",
    "        if hasattr(sc_expr, 'toarray'):\n",
    "            sc_expr = sc_expr.toarray()\n",
    "        if hasattr(st_expr, 'toarray'):\n",
    "            st_expr = st_expr.toarray()\n",
    "            \n",
    "        # Get spatial coordinates\n",
    "        st_coords = stadata.obsm['spatial']\n",
    "        \n",
    "        print(f\"SC data shape: {sc_expr.shape}\")\n",
    "        print(f\"ST data shape: {st_expr.shape}\")\n",
    "        print(f\"ST coords shape: {st_coords.shape}\")\n",
    "        \n",
    "        # Initialize AdvancedHierarchicalDiffusion model\n",
    "        model = AdvancedHierarchicalDiffusion(\n",
    "            st_gene_expr=st_expr,\n",
    "            st_coords=st_coords,\n",
    "            sc_gene_expr=sc_expr,\n",
    "            cell_types_sc=scadata.obs['rough_celltype'].values,  # No cell type labels\n",
    "            transport_plan=None,  # No OT transport plan\n",
    "            D_st=None,           # No distance matrices\n",
    "            D_induced=None,\n",
    "            n_genes=len(common_genes),\n",
    "            n_embedding=[512, 256, 128],  # Same as STEMDiffusion\n",
    "            coord_space_diameter=2.00,\n",
    "            sigma=3.0,\n",
    "            alpha=0.8,\n",
    "            mmdbatch=1000,\n",
    "            batch_size=256,\n",
    "            device=device,\n",
    "            lr_e=0.0001,\n",
    "            lr_d=0.0002,\n",
    "            n_timesteps=600,     # Same as STEMDiffusion\n",
    "            n_denoising_blocks=4,\n",
    "            hidden_dim=256,      # Same as STEMDiffusion\n",
    "            num_heads=8,\n",
    "            num_hierarchical_scales=3,\n",
    "            dp=0.2,\n",
    "            outf=f'advanced_diffusion_{dataset_name}'\n",
    "        )\n",
    "        \n",
    "        print(f\"Training model for {dataset_name}...\")\n",
    "        \n",
    "        # Train using new Graph-VAE + Latent Diffusion pipeline\n",
    "        model.train(\n",
    "            encoder_epochs=1000,  # Stage 1: Domain alignment encoder\n",
    "            vae_epochs=1000,       # Stage 2: Graph-VAE training\n",
    "            diffusion_epochs=2500, # Stage 3: Latent diffusion\n",
    "            lambda_struct=2.0     # Structure loss weight\n",
    "        )\n",
    "        \n",
    "        model.plot_training_losses()\n",
    "        \n",
    "        print(f\"Generating SC coordinates using model {i+1}...\")\n",
    "        # Sample SC coordinates using new Graph-VAE + Latent Diffusion pipeline\n",
    "        # sc_coords = model.sample_sc_coordinates(\n",
    "        #     n_samples=None     # Use all SC cells\n",
    "        # )\n",
    "        sc_coords = model.sample_sc_coordinates_batched(\n",
    "            batch_size=512  # Even smaller batches\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        sc_coords_results.append(sc_coords)\n",
    "        models_all.append(model)\n",
    "        \n",
    "        print(f\"Model {i+1} complete! Generated coordinates shape: {sc_coords.shape}\")\n",
    "        \n",
    "        # Clean up GPU memory\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Average the results from all 3 models\n",
    "    print(f\"\\nAveraging results from {len(sc_coords_results)} models...\")\n",
    "    sc_coords_avg = np.mean(sc_coords_results, axis=0)\n",
    "    \n",
    "    # Verify shapes match\n",
    "    shapes = [coords.shape for coords in sc_coords_results]\n",
    "    assert all(shape == shapes[0] for shape in shapes), f\"Shape mismatch: {shapes}\"\n",
    "    \n",
    "    print(f\"Final averaged coordinates shape: {sc_coords_avg.shape}\")\n",
    "    \n",
    "    # Add to AnnData\n",
    "    scadata.obsm['advanced_diffusion_coords_avg'] = sc_coords_avg\n",
    "    \n",
    "    # Optionally, save individual results too\n",
    "    for i, coords in enumerate(sc_coords_results):\n",
    "        scadata.obsm[f'advanced_diffusion_coords_rep{i+1}'] = coords\n",
    "    \n",
    "    print(f\"\\nAdvanced diffusion training complete!\")\n",
    "    print(f\"Results saved in scadata.obsm['advanced_diffusion_coords_avg']\")\n",
    "    \n",
    "    return scadata, models_all\n",
    "\n",
    "# Load and process data\n",
    "scadata, stadata1, stadata2, stadata3 = load_and_process_cscc_data()\n",
    "\n",
    "# Train individual AdvancedHierarchicalDiffusion models and get averaged results\n",
    "scadata, advanced_models = train_individual_advanced_diffusion_models(\n",
    "    scadata, stadata1, stadata2, stadata3\n",
    ")\n",
    "\n",
    "print(\"Advanced diffusion training complete! Results saved in scadata.obsm['advanced_diffusion_coords_avg']\")\n",
    "\n",
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "my_tab20 = sns.color_palette(\"tab20\", n_colors=20).as_hex()\n",
    "\n",
    "# Plot 1: Averaged coordinates\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc.pl.embedding(scadata, basis='advanced_diffusion_coords_avg', color='rough_celltype',\n",
    "               size=85, title='SC Advanced Diffusion Coords (Averaged)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Individual model results\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sc.pl.embedding(scadata, basis=f'advanced_diffusion_coords_rep{i+1}', color='rough_celltype',\n",
    "                   size=85, title=f'SC Coordinates (Advanced Model {i+1})',\n",
    "                   palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scadata.obsm['advanced_diffusion_coords_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scadata.obsm['advanced_diffusion_coords_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results with separate plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (4, 4)\n",
    "# import scanpy as sc\n",
    "# sc.settings.set_figure_params(figsize=(4,4), dpi=100)\n",
    "\n",
    "# Plot 1: Averaged coordinates\n",
    "plt.figure(figsize=(4, 4))\n",
    "sc.pl.embedding(scadata, basis='advanced_diffusion_coords_avg', color='rough_celltype',\n",
    "               size=85, title='SC Spatial Coordinates (Averaged from 3 Models)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Model 1 results\n",
    "plt.figure(figsize=(4, 4))\n",
    "sc.pl.embedding(scadata, basis='advanced_diffusion_coords_rep1', color='rough_celltype',\n",
    "               size=85, title='SC Coordinates (Model 1)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Model 2 results\n",
    "plt.figure(figsize=(4, 4))\n",
    "sc.pl.embedding(scadata, basis='advanced_diffusion_coords_rep2', color='rough_celltype',\n",
    "               size=85, title='SC Coordinates (Model 2)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "my_tab20 = sns.color_palette(\"tab20\", n_colors=12).as_hex()\n",
    "\n",
    "# Plot 4: Model 3 results\n",
    "plt.figure(figsize=(4, 4))\n",
    "sc.pl.embedding(scadata, basis='advanced_diffusion_coords_rep3', color='rough_celltype',\n",
    "               size=85, title='SC Coordinates (Model 3)',\n",
    "             palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you have: scadata.obsm['advanced_diffusion_coords_avg'], etc.\n",
    "\n",
    "print(\"\\n=== Advanced Analysis and Visualization ===\")\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "\n",
    "\n",
    "# 1. Visualize advanced results with uncertainty analysis\n",
    "print(\"Creating advanced visualization plots...\")\n",
    "fig, model_uncertainty, confidence_scores = visualize_advanced_results_multi_model(scadata)\n",
    "\n",
    "# 2. Analyze cell interactions for averaged coordinates\n",
    "print(\"Analyzing cell interactions (averaged coordinates)...\")\n",
    "min_distances_avg, interaction_matrix_avg = analyze_cell_interactions_advanced(\n",
    "    scadata, coords_key='advanced_diffusion_coords_avg'\n",
    ")\n",
    "\n",
    "# 3. Optional: Analyze interactions for individual models too\n",
    "print(\"Analyzing cell interactions (individual models)...\")\n",
    "for i in range(1, 4):\n",
    "    print(f\"\\nModel {i} interactions:\")\n",
    "    min_distances, interaction_matrix = analyze_cell_interactions_advanced(\n",
    "        scadata, coords_key=f'advanced_diffusion_coords_rep{i}'\n",
    "    )\n",
    "\n",
    "# 4. Print summary statistics\n",
    "print(\"\\n=== Advanced Model Statistics ===\")\n",
    "print(f\"Total cells mapped: {len(scadata.obsm['advanced_diffusion_coords_avg'])}\")\n",
    "print(f\"Average model uncertainty: {model_uncertainty.mean():.4f}\")\n",
    "print(f\"Model uncertainty range: [{model_uncertainty.min():.4f}, {model_uncertainty.max():.4f}]\")\n",
    "print(f\"Average confidence: {confidence_scores.mean():.4f}\")\n",
    "\n",
    "print(\"\\n=== Cell Type Confidence ===\")\n",
    "for ct in scadata.obs['rough_celltype'].unique():\n",
    "    mask = scadata.obs['rough_celltype'] == ct\n",
    "    print(f\"{ct}: {mask.sum()} cells, \"\n",
    "          f\"avg confidence: {confidence_scores[mask].mean():.3f}, \"\n",
    "          f\"avg uncertainty: {model_uncertainty[mask].mean():.4f}\")\n",
    "\n",
    "print(\"\\n=== Physics Constraints (Averaged Coordinates) ===\")\n",
    "all_distances = []\n",
    "for key, dist in min_distances_avg.items():\n",
    "    if not np.isnan(dist):\n",
    "        all_distances.append(dist)\n",
    "        print(f\"Min distance {key[0]} - {key[1]}: {dist:.4f}\")\n",
    "\n",
    "if all_distances:\n",
    "    print(f\"\\nOverall minimum cell-cell distance: {np.min(all_distances):.4f}\")\n",
    "    print(f\"Cells with potential overlaps (< 0.01): {np.sum(np.array(all_distances) < 0.01)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "\n",
    "my_tab20 = sns.color_palette(\"tab20\", n_colors=20).as_hex()\n",
    "\n",
    "# Plot 1: Averaged coordinates\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc.pl.embedding(scadata, basis='advanced_diffusion_coords_avg', color='rough_celltype',\n",
    "               size=85, title='SC Advanced Diffusion Coords (Averaged)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Individual model results\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(6, 5)) \n",
    "    sc.pl.embedding(scadata, basis=f'advanced_diffusion_coords_rep{i+1}', color='rough_celltype',\n",
    "                   size=85, title=f'SC Coordinates (Advanced Model {i+1})',\n",
    "                   palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coordinates_isotropic(coords):\n",
    "    '''normalize coordinates to unit circle preserving aspect ratio'''\n",
    "    if torch.is_tensor(coords):\n",
    "        center = coords.mean(dim=0)\n",
    "        centered = coords - center\n",
    "        max_radius = torch.max(torch.norm(centered, dim=1))\n",
    "        coords_norm = centered / max_radius\n",
    "        return coords_norm, center, max_radius\n",
    "    else:\n",
    "        center = coords.mean(axis=0)\n",
    "        centered = coords - center\n",
    "        max_radius = np.max(np.linalg.norm(centered, axis=1))\n",
    "        coords_norm = centered / max_radius\n",
    "        return coords_norm, center, max_radius\n",
    "\n",
    "# Load and prepare data for validation\n",
    "scadata_val, stadata1_val, stadata2_val, stadata3_val = load_and_process_cscc_data_individual_norm()\n",
    "\n",
    "# Get normalized ground truth coordinates for ST3\n",
    "st3_coords_gt = stadata3_val.obsm['spatial']\n",
    "st3_coords_gt_norm, _, _ = normalize_coordinates_isotropic(st3_coords_gt)\n",
    "\n",
    "print(\"=== VALIDATION EXPERIMENT ===\")\n",
    "print(\"Training diffusion models on ST1+ST2, testing on ST3...\")\n",
    "\n",
    "# Prepare datasets for training (only first 2)\n",
    "st_datasets_train = [\n",
    "    (stadata1_val, \"dataset1\"),\n",
    "    (stadata2_val, \"dataset2\")\n",
    "]\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Storage for results\n",
    "T_all = []\n",
    "D_induced_all = []\n",
    "D_st_all = []\n",
    "D_sc_all = []\n",
    "trained_models = []\n",
    "\n",
    "# Train on first two datasets\n",
    "for i, (stadata, dataset_name) in enumerate(st_datasets_train):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training Advanced Diffusion model {i+1}/2 for {dataset_name} using SpaOTsc\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Get common genes between SC and current ST dataset\n",
    "    sc_genes = set(scadata_val.var_names)\n",
    "    st_genes = set(stadata.var_names)\n",
    "    common_genes = sorted(list(sc_genes & st_genes))\n",
    "    \n",
    "    print(f\"Common genes for {dataset_name}: {len(common_genes)}\")\n",
    "    \n",
    "    # Extract expression data\n",
    "    sc_expr = scadata_val[:, common_genes].X\n",
    "    st_expr = stadata[:, common_genes].X\n",
    "    \n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(sc_expr, 'toarray'):\n",
    "        sc_expr = sc_expr.toarray()\n",
    "    if hasattr(st_expr, 'toarray'):\n",
    "        st_expr = st_expr.toarray()\n",
    "        \n",
    "    # Get coordinates\n",
    "    st_coords = stadata.obsm['spatial']\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_sc = torch.tensor(sc_expr, dtype=torch.float32).to(device)\n",
    "    X_st = torch.tensor(st_expr, dtype=torch.float32).to(device)\n",
    "    Y_st = torch.tensor(st_coords, dtype=torch.float32).to(device)\n",
    "    \n",
    "    print(f\"SC data shape: {X_sc.shape}\")\n",
    "    print(f\"ST data shape: {X_st.shape}\")\n",
    "    print(f\"ST coords shape: {Y_st.shape}\")\n",
    "    \n",
    "    # === REPLACE FUSED_GW_TORCH WITH SPAOTSC ===\n",
    "    print(f\"Running optimal transport for {dataset_name}...\")\n",
    "\n",
    "    # === PREPARE CELL TYPE INFORMATION ===\n",
    "    # Extract cell types from scadata\n",
    "    if 'rough_celltype' in scadata_val.obs.columns:\n",
    "        cell_types_sc = scadata_val.obs['rough_celltype'].values\n",
    "        unique_cell_types = np.unique(cell_types_sc)\n",
    "        print(f\"Found {len(unique_cell_types)} unique cell types: {unique_cell_types}\")\n",
    "    else:\n",
    "        cell_types_sc = None\n",
    "        print(\"No cell type information found\")\n",
    "\n",
    "    # === INITIALIZE ADVANCED HIERARCHICAL DIFFUSION MODEL ===\n",
    "    print(f\"Initializing AdvancedHierarchicalDiffusion for {dataset_name}...\")\n",
    "    \n",
    "    output_dir = f'./cscc_advanced_diffusion_{dataset_name}_validation'\n",
    "    \n",
    "    model = AdvancedHierarchicalDiffusion(\n",
    "        st_gene_expr=st_expr,\n",
    "        st_coords=st_coords,\n",
    "        sc_gene_expr=sc_expr,\n",
    "        cell_types_sc=scadata.obs['rough_celltype'].values,  # No cell type labels\n",
    "        transport_plan=None,  # No OT transport plan\n",
    "        D_st=None,           # No distance matrices\n",
    "        D_induced=None,\n",
    "        n_genes=len(common_genes),\n",
    "        n_embedding=[512, 256, 128],  # Same as STEMDiffusion\n",
    "        coord_space_diameter=2.00,\n",
    "        sigma=3.0,\n",
    "        alpha=0.8,\n",
    "        mmdbatch=1000,\n",
    "        batch_size=256,\n",
    "        device=device,\n",
    "        lr_e=0.0001,\n",
    "        lr_d=0.0002,\n",
    "        n_timesteps=800,     # Same as STEMDiffusion\n",
    "        n_denoising_blocks=6,\n",
    "        hidden_dim=256,      # Same as STEMDiffusion\n",
    "        num_heads=8,\n",
    "        num_hierarchical_scales=3,\n",
    "        dp=0.2,\n",
    "        outf=f'advanced_diffusion_{dataset_name}'\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(f\"Training model for {dataset_name}...\")\n",
    "    # model.train()\n",
    "\n",
    "    model.train(\n",
    "        encoder_epochs=1000,  # Stage 1: Domain alignment encoder\n",
    "        vae_epochs=1000,       # Stage 2: Graph-VAE training\n",
    "        diffusion_epochs=2500, # Stage 3: Latent diffusion\n",
    "        lambda_struct=5.0     # Structure loss weight\n",
    "    )\n",
    "    \n",
    "    # Store the trained model\n",
    "    trained_models.append(model)\n",
    "    print(f\"Model {i+1} training completed!\")\n",
    "\n",
    "print(f\"\\nTraining completed! {len(trained_models)} models trained.\")\n",
    "\n",
    "# Test on the third dataset by creating new model instances\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Testing on ST3 dataset...\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Get common genes for testing\n",
    "sc_genes = set(scadata_val.var_names)\n",
    "st1_genes = set(stadata1_val.var_names)\n",
    "st2_genes = set(stadata2_val.var_names)\n",
    "st3_genes = set(stadata3_val.var_names)\n",
    "common_genes_test = sorted(list(sc_genes & st1_genes & st2_genes & st3_genes))\n",
    "\n",
    "print(f\"Common genes for testing: {len(common_genes_test)}\")\n",
    "\n",
    "# Extract ST3 expression data\n",
    "st3_expr = stadata3_val[:, common_genes_test].X\n",
    "if hasattr(st3_expr, 'toarray'):\n",
    "    st3_expr = st3_expr.toarray()\n",
    "\n",
    "# We'll create dummy models just to get predictions\n",
    "# Use ST1 as reference for coordinates (since we need some spatial reference)\n",
    "st1_coords = stadata1_val.obsm['spatial']\n",
    "st1_expr_ref = stadata1_val[:, common_genes_test].X\n",
    "if hasattr(st1_expr_ref, 'toarray'):\n",
    "    st1_expr_ref = st1_expr_ref.toarray()\n",
    "\n",
    "# Convert to tensors\n",
    "X_st1_ref = torch.tensor(st1_expr_ref, dtype=torch.float32).to(device)\n",
    "X_st3_test = torch.tensor(st3_expr, dtype=torch.float32).to(device)\n",
    "Y_st1_ref = torch.tensor(st1_coords, dtype=torch.float32).to(device)\n",
    "\n",
    "# Get cell types\n",
    "cell_types_sc = scadata_val.obs['rough_celltype'].values if 'rough_celltype' in scadata_val.obs.columns else None\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "# Get the number of cell types from the original training\n",
    "original_cell_types = scadata_val.obs['rough_celltype'].values\n",
    "unique_cell_types = np.unique(original_cell_types)\n",
    "num_original_cell_types = len(unique_cell_types)\n",
    "\n",
    "print(f\"Original model has {num_original_cell_types} cell types\")\n",
    "\n",
    "# Create dummy cell types for ST3 data to match the original number\n",
    "dummy_cell_types = np.random.choice(unique_cell_types, size=X_st3_test.shape[0])\n",
    "\n",
    "# For each trained model, create a test version\n",
    "for i, trained_model in enumerate(trained_models):\n",
    "    print(f\"Creating test model based on trained model {i+1}...\")\n",
    "    \n",
    "    # Create a minimal model instance for testing (no training)\n",
    "    test_model = AdvancedHierarchicalDiffusion(\n",
    "        st_gene_expr=X_st1_ref.cpu().numpy(),  # Use ST1 as reference\n",
    "        st_coords=Y_st1_ref.cpu().numpy(),     # Use ST1 coords as reference\n",
    "        sc_gene_expr=X_st3_test.cpu().numpy(), # ST3 data as \"SC\" data\n",
    "        cell_types_sc=dummy_cell_types,                    # No cell types for ST3\n",
    "        transport_plan=None,               # Use transport plan from training\n",
    "        D_st=None,                      # Use distance matrices from training\n",
    "        D_induced=None,\n",
    "        n_genes=len(common_genes_test),\n",
    "        n_embedding=[512, 256, 128],\n",
    "        coord_space_diameter=2.00,\n",
    "        sigma=3.0,\n",
    "        alpha=0.8,\n",
    "        mmdbatch=1000,\n",
    "        batch_size=256,\n",
    "        device=device,\n",
    "        lr_e=0.0001,\n",
    "        lr_d=0.0002,\n",
    "        n_timesteps=800,\n",
    "        n_denoising_blocks=6,\n",
    "        hidden_dim=256,\n",
    "        num_heads=8,\n",
    "        num_hierarchical_scales=3,\n",
    "        dp=0.2,\n",
    "        outf=f'./temp_test_model_{i}'\n",
    "    )\n",
    "    \n",
    "    # Copy trained parameters (this is a hack, but should work)\n",
    "    state_dict = trained_model.state_dict()\n",
    "    # if 'ot_guidance_strength' in state_dict:\n",
    "    #     del state_dict['ot_guidance_strength']\n",
    "    # test_model.load_state_dict(state_dict)\n",
    "    test_model.load_state_dict(trained_model.state_dict(), strict=False)\n",
    "    \n",
    "    # Now sample coordinates (this should work since ST3 data is the \"SC\" data)\n",
    "    print(f\"Generating predictions from test model {i+1}...\")\n",
    "\n",
    "    predicted_coords = test_model.sample_sc_coordinates_batched(\n",
    "            batch_size=512  # Even smaller batches\n",
    "    )\n",
    "    all_predictions.append(predicted_coords)\n",
    "\n",
    "# Continue with the rest of your evaluation code...\n",
    "\n",
    "# Average predictions from both models\n",
    "predicted_coords_avg = np.mean(all_predictions, axis=0)\n",
    "print(f\"Predicted coordinates shape: {predicted_coords_avg.shape}\")\n",
    "print(f\"Ground truth coordinates shape: {st3_coords_gt_norm.shape}\")\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# MSE and MAE\n",
    "mse = mean_squared_error(st3_coords_gt_norm, predicted_coords_avg)\n",
    "mae = mean_absolute_error(st3_coords_gt_norm, predicted_coords_avg)\n",
    "\n",
    "# Correlation for each dimension\n",
    "corr_x, p_x = pearsonr(st3_coords_gt_norm[:, 0], predicted_coords_avg[:, 0])\n",
    "corr_y, p_y = pearsonr(st3_coords_gt_norm[:, 1], predicted_coords_avg[:, 1])\n",
    "\n",
    "print(\"=== VALIDATION RESULTS ===\")\n",
    "print(f\"Mean Squared Error: {mse:.6f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.6f}\")\n",
    "print(f\"Correlation X-dimension: {corr_x:.4f} (p={p_x:.6f})\")\n",
    "print(f\"Correlation Y-dimension: {corr_y:.4f} (p={p_y:.6f})\")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Ground truth coordinates\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(st3_coords_gt_norm[:, 0], st3_coords_gt_norm[:, 1], \n",
    "           c=range(len(st3_coords_gt_norm)), cmap='viridis', alpha=0.6, s=20)\n",
    "plt.title('Ground Truth ST3 Coordinates\\n(Isotropic Normalized)')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.colorbar(label='Spot index')\n",
    "\n",
    "# Plot 2: Predicted coordinates\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(predicted_coords_avg[:, 0], predicted_coords_avg[:, 1], \n",
    "           c=range(len(predicted_coords_avg)), cmap='viridis', alpha=0.6, s=20)\n",
    "plt.title('Predicted ST3 Coordinates\\n(Averaged from 2 Models)')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.colorbar(label='Spot index')\n",
    "\n",
    "# Plot 3: Correlation plot\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(st3_coords_gt_norm[:, 0], predicted_coords_avg[:, 0], \n",
    "           alpha=0.5, label=f'X-coord (r={corr_x:.3f})', s=15)\n",
    "plt.scatter(st3_coords_gt_norm[:, 1], predicted_coords_avg[:, 1], \n",
    "           alpha=0.5, label=f'Y-coord (r={corr_y:.3f})', s=15)\n",
    "plt.plot([st3_coords_gt_norm.min(), st3_coords_gt_norm.max()], \n",
    "         [st3_coords_gt_norm.min(), st3_coords_gt_norm.max()], \n",
    "         'r--', alpha=0.8, label='Perfect correlation')\n",
    "plt.xlabel('Ground Truth Coordinates')\n",
    "plt.ylabel('Predicted Coordinates')\n",
    "plt.title('Prediction vs Ground Truth')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional distance-based evaluation\n",
    "euclidean_distances = np.sqrt(np.sum((st3_coords_gt_norm - predicted_coords_avg)**2, axis=1))\n",
    "median_distance = np.median(euclidean_distances)\n",
    "mean_distance = np.mean(euclidean_distances)\n",
    "\n",
    "print(f\"\\nDistance-based metrics:\")\n",
    "print(f\"Mean Euclidean distance: {mean_distance:.6f}\")\n",
    "print(f\"Median Euclidean distance: {median_distance:.6f}\")\n",
    "print(f\"Max Euclidean distance: {np.max(euclidean_distances):.6f}\")\n",
    "print(f\"Min Euclidean distance: {np.min(euclidean_distances):.6f}\")\n",
    "\n",
    "print(\"=== VALIDATION EXPERIMENT COMPLETED ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now sample coordinates (this should work since ST3 data is the \"SC\" data)\n",
    "print(f\"Generating predictions from test model {i+1}...\")\n",
    "all_predictions = []\n",
    "for i, trained_model in enumerate(trained_models):\n",
    "    print(f\"Creating test model based on trained model {i+1}...\")\n",
    "    \n",
    "    # Create a minimal model instance for testing (no training)\n",
    "    test_model = AdvancedHierarchicalDiffusion(\n",
    "        st_gene_expr=X_st1_ref.cpu().numpy(),  # Use ST1 as reference\n",
    "        st_coords=Y_st1_ref.cpu().numpy(),     # Use ST1 coords as reference\n",
    "        sc_gene_expr=X_st3_test.cpu().numpy(), # ST3 data as \"SC\" data\n",
    "        cell_types_sc=dummy_cell_types,                    # No cell types for ST3\n",
    "        transport_plan=None,               # Use transport plan from training\n",
    "        D_st=None,                      # Use distance matrices from training\n",
    "        D_induced=None,\n",
    "        n_genes=len(common_genes_test),\n",
    "        n_embedding=[512, 256, 128],\n",
    "        coord_space_diameter=2.00,\n",
    "        sigma=3.0,\n",
    "        alpha=0.8,\n",
    "        mmdbatch=1000,\n",
    "        batch_size=256,\n",
    "        device=device,\n",
    "        lr_e=0.0001,\n",
    "        lr_d=0.0002,\n",
    "        n_timesteps=800,\n",
    "        n_denoising_blocks=6,\n",
    "        hidden_dim=256,\n",
    "        num_heads=8,\n",
    "        num_hierarchical_scales=3,\n",
    "        dp=0.2,\n",
    "        outf=f'./temp_test_model_{i}'\n",
    "    )\n",
    "    \n",
    "    # Copy trained parameters (this is a hack, but should work)\n",
    "    state_dict = trained_model.state_dict()\n",
    "    # if 'ot_guidance_strength' in state_dict:\n",
    "    #     del state_dict['ot_guidance_strength']\n",
    "    # test_model.load_state_dict(state_dict)\n",
    "    test_model.load_state_dict(trained_model.state_dict(), strict=False)\n",
    "    \n",
    "    # Now sample coordinates (this should work since ST3 data is the \"SC\" data)\n",
    "    print(f\"Generating predictions from test model {i+1}...\")\n",
    "    predicted_coords = test_model.sample_sc_coordinates_batched(\n",
    "            batch_size=512  # Even smaller batches\n",
    "    )\n",
    "    all_predictions.append(predicted_coords)\n",
    "\n",
    "# Continue with the rest of your evaluation code...\n",
    "\n",
    "# Average predictions from both models\n",
    "predicted_coords_avg = np.mean(all_predictions, axis=0)\n",
    "print(f\"Predicted coordinates shape: {predicted_coords_avg.shape}\")\n",
    "print(f\"Ground truth coordinates shape: {st3_coords_gt_norm.shape}\")\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# MSE and MAE\n",
    "mse = mean_squared_error(st3_coords_gt_norm, predicted_coords_avg)\n",
    "mae = mean_absolute_error(st3_coords_gt_norm, predicted_coords_avg)\n",
    "\n",
    "# Correlation for each dimension\n",
    "corr_x, p_x = pearsonr(st3_coords_gt_norm[:, 0], predicted_coords_avg[:, 0])\n",
    "corr_y, p_y = pearsonr(st3_coords_gt_norm[:, 1], predicted_coords_avg[:, 1])\n",
    "\n",
    "print(\"=== VALIDATION RESULTS ===\")\n",
    "print(f\"Mean Squared Error: {mse:.6f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.6f}\")\n",
    "print(f\"Correlation X-dimension: {corr_x:.4f} (p={p_x:.6f})\")\n",
    "print(f\"Correlation Y-dimension: {corr_y:.4f} (p={p_y:.6f})\")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Ground truth coordinates\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(st3_coords_gt_norm[:, 0], st3_coords_gt_norm[:, 1], \n",
    "           c=range(len(st3_coords_gt_norm)), cmap='viridis', alpha=0.6, s=20)\n",
    "plt.title('Ground Truth ST3 Coordinates\\n(Isotropic Normalized)')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.colorbar(label='Spot index')\n",
    "\n",
    "# Plot 2: Predicted coordinates\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(predicted_coords_avg[:, 0], predicted_coords_avg[:, 1], \n",
    "           c=range(len(predicted_coords_avg)), cmap='viridis', alpha=0.6, s=20)\n",
    "plt.title('Predicted ST3 Coordinates\\n(Averaged from 2 Models)')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.colorbar(label='Spot index')\n",
    "\n",
    "# Plot 3: Correlation plot\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(st3_coords_gt_norm[:, 0], predicted_coords_avg[:, 0], \n",
    "           alpha=0.5, label=f'X-coord (r={corr_x:.3f})', s=15)\n",
    "plt.scatter(st3_coords_gt_norm[:, 1], predicted_coords_avg[:, 1], \n",
    "           alpha=0.5, label=f'Y-coord (r={corr_y:.3f})', s=15)\n",
    "plt.plot([st3_coords_gt_norm.min(), st3_coords_gt_norm.max()], \n",
    "         [st3_coords_gt_norm.min(), st3_coords_gt_norm.max()], \n",
    "         'r--', alpha=0.8, label='Perfect correlation')\n",
    "plt.xlabel('Ground Truth Coordinates')\n",
    "plt.ylabel('Predicted Coordinates')\n",
    "plt.title('Prediction vs Ground Truth')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional distance-based evaluation\n",
    "euclidean_distances = np.sqrt(np.sum((st3_coords_gt_norm - predicted_coords_avg)**2, axis=1))\n",
    "median_distance = np.median(euclidean_distances)\n",
    "mean_distance = np.mean(euclidean_distances)\n",
    "\n",
    "print(f\"\\nDistance-based metrics:\")\n",
    "print(f\"Mean Euclidean distance: {mean_distance:.6f}\")\n",
    "print(f\"Median Euclidean distance: {median_distance:.6f}\")\n",
    "print(f\"Max Euclidean distance: {np.max(euclidean_distances):.6f}\")\n",
    "print(f\"Min Euclidean distance: {np.min(euclidean_distances):.6f}\")\n",
    "\n",
    "print(\"=== VALIDATION EXPERIMENT COMPLETED ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model separately AND the average\n",
    "predicted_coords_avg = np.mean(all_predictions, axis=0)\n",
    "print(f\"Predicted coordinates shape: {predicted_coords_avg.shape}\")\n",
    "print(f\"Ground truth coordinates shape: {st3_coords_gt_norm.shape}\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Evaluate individual models\n",
    "for i, pred in enumerate(all_predictions):\n",
    "    mse_i = mean_squared_error(st3_coords_gt_norm, pred)\n",
    "    mae_i = mean_absolute_error(st3_coords_gt_norm, pred)\n",
    "    corr_x_i, p_x_i = pearsonr(st3_coords_gt_norm[:, 0], pred[:, 0])\n",
    "    corr_y_i, p_y_i = pearsonr(st3_coords_gt_norm[:, 1], pred[:, 1])\n",
    "    \n",
    "    print(f\"\\n=== MODEL {i+1} RESULTS ===\")\n",
    "    print(f\"MSE: {mse_i:.6f}, MAE: {mae_i:.6f}\")\n",
    "    print(f\"Corr X: {corr_x_i:.4f}, Corr Y: {corr_y_i:.4f}\")\n",
    "\n",
    "# Evaluate averaged results\n",
    "mse = mean_squared_error(st3_coords_gt_norm, predicted_coords_avg)\n",
    "mae = mean_absolute_error(st3_coords_gt_norm, predicted_coords_avg)\n",
    "corr_x, p_x = pearsonr(st3_coords_gt_norm[:, 0], predicted_coords_avg[:, 0])\n",
    "corr_y, p_y = pearsonr(st3_coords_gt_norm[:, 1], predicted_coords_avg[:, 1])\n",
    "\n",
    "print(f\"\\n=== AVERAGED RESULTS ===\")\n",
    "print(f\"MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "print(f\"Corr X: {corr_x:.4f}, Corr Y: {corr_y:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization - individual models + average + ground truth\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "# Plot 1: Ground truth coordinates\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.scatter(st3_coords_gt_norm[:, 0], st3_coords_gt_norm[:, 1], \n",
    "           c=range(len(st3_coords_gt_norm)), cmap='viridis', alpha=0.6, s=20)\n",
    "plt.title('Ground Truth ST3 Coordinates\\n(Isotropic Normalized)')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.colorbar(label='Spot index')\n",
    "\n",
    "# Plot 2: Model 1 predictions\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.scatter(all_predictions[0][:, 0], all_predictions[0][:, 1], \n",
    "           c=range(len(all_predictions[0])), cmap='viridis', alpha=0.6, s=20)\n",
    "plt.title('Model 1 Predictions')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.colorbar(label='Spot index')\n",
    "\n",
    "# Plot 3: Model 2 predictions\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.scatter(all_predictions[1][:, 0], all_predictions[1][:, 1], \n",
    "           c=range(len(all_predictions[1])), cmap='viridis', alpha=0.6, s=20)\n",
    "plt.title('Model 2 Predictions')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.colorbar(label='Spot index')\n",
    "\n",
    "# Plot 4: Averaged predictions\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.scatter(predicted_coords_avg[:, 0], predicted_coords_avg[:, 1], \n",
    "           c=range(len(predicted_coords_avg)), cmap='viridis', alpha=0.6, s=20)\n",
    "plt.title('Averaged Predictions')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.colorbar(label='Spot index')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation plots for each model\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, pred in enumerate(all_predictions):\n",
    "    corr_x_i, _ = pearsonr(st3_coords_gt_norm[:, 0], pred[:, 0])\n",
    "    corr_y_i, _ = pearsonr(st3_coords_gt_norm[:, 1], pred[:, 1])\n",
    "    \n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.scatter(st3_coords_gt_norm[:, 0], pred[:, 0], \n",
    "               alpha=0.5, label=f'X-coord (r={corr_x_i:.3f})', s=15)\n",
    "    plt.scatter(st3_coords_gt_norm[:, 1], pred[:, 1], \n",
    "               alpha=0.5, label=f'Y-coord (r={corr_y_i:.3f})', s=15)\n",
    "    plt.plot([st3_coords_gt_norm.min(), st3_coords_gt_norm.max()], \n",
    "             [st3_coords_gt_norm.min(), st3_coords_gt_norm.max()], \n",
    "             'r--', alpha=0.8, label='Perfect correlation')\n",
    "    plt.xlabel('Ground Truth Coordinates')\n",
    "    plt.ylabel('Predicted Coordinates')\n",
    "    plt.title(f'Model {i+1} vs Ground Truth')\n",
    "    plt.legend()\n",
    "\n",
    "# Averaged correlation plot\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(st3_coords_gt_norm[:, 0], predicted_coords_avg[:, 0], \n",
    "           alpha=0.5, label=f'X-coord (r={corr_x:.3f})', s=15)\n",
    "plt.scatter(st3_coords_gt_norm[:, 1], predicted_coords_avg[:, 1], \n",
    "           alpha=0.5, label=f'Y-coord (r={corr_y:.3f})', s=15)\n",
    "plt.plot([st3_coords_gt_norm.min(), st3_coords_gt_norm.max()], \n",
    "         [st3_coords_gt_norm.min(), st3_coords_gt_norm.max()], \n",
    "         'r--', alpha=0.8, label='Perfect correlation')\n",
    "plt.xlabel('Ground Truth Coordinates')\n",
    "plt.ylabel('Predicted Coordinates')\n",
    "plt.title('Averaged Predictions vs Ground Truth')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distance error plots for each model\n",
    "euclidean_distances_all = []\n",
    "for i, pred in enumerate(all_predictions):\n",
    "    distances = np.sqrt(np.sum((st3_coords_gt_norm - pred)**2, axis=1))\n",
    "    euclidean_distances_all.append(distances)\n",
    "\n",
    "euclidean_distances_avg = np.sqrt(np.sum((st3_coords_gt_norm - predicted_coords_avg)**2, axis=1))\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# Distance histograms\n",
    "for i, distances in enumerate(euclidean_distances_all):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.hist(distances, bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Euclidean Distance')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Model {i+1} Error Distribution\\nMean: {np.mean(distances):.4f}')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(euclidean_distances_avg, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Euclidean Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Averaged Model Error Distribution\\nMean: {np.mean(euclidean_distances_avg):.4f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print distance metrics for all models\n",
    "for i, distances in enumerate(euclidean_distances_all):\n",
    "    print(f\"\\nModel {i+1} distance metrics:\")\n",
    "    print(f\"Mean: {np.mean(distances):.6f}, Median: {np.median(distances):.6f}\")\n",
    "    print(f\"Max: {np.max(distances):.6f}, Min: {np.min(distances):.6f}\")\n",
    "\n",
    "print(f\"\\nAveraged model distance metrics:\")\n",
    "print(f\"Mean: {np.mean(euclidean_distances_avg):.6f}, Median: {np.median(euclidean_distances_avg):.6f}\")\n",
    "print(f\"Max: {np.max(euclidean_distances_avg):.6f}, Min: {np.min(euclidean_distances_avg):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (4, 4)\n",
    "\n",
    "sc.pl.spatial(scadata,color=\"rough_celltype\",spot_size=0.04, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (4, 4)\n",
    "sc.pl.spatial(scadata,color=\"level2_celltype\",groups=[\"PDC\"],spot_size=0.04, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcParams['pdf.fonttype'] = 42\n",
    "# rcParams['ps.fonttype'] = 42\n",
    "# figsize(4,4)\n",
    "mpl.rcParams['figure.figsize'] = (4, 4)\n",
    "sc.pl.spatial(scadata,color=\"level3_celltype\",groups=[\"TSK\"],spot_size=0.04, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False)\n",
    "#save='TSK',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figsize(4,4)\n",
    "mpl.rcParams['figure.figsize'] = (4, 4)\n",
    "sc.pl.spatial(scadata,color=\"level2_celltype\",groups=[\"Tumor_KC_Cyc\"],spot_size=0.04, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False,save='P2cyc')\n",
    "sc.pl.spatial(scadata,color=\"level2_celltype\",groups=[\"Tumor_KC_Basal\"],spot_size=0.04, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False,save='P2bas')\n",
    "sc.pl.spatial(scadata,color=\"level2_celltype\",groups=[\"Tumor_KC_Diff\"],spot_size=0.04, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False,save='P2diff')\n",
    "#save='nonTSK',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squidpy as sq\n",
    "sq.gr.spatial_neighbors(scadata,spatial_key='advanced_diffusion_coords_avg')\n",
    "sq.gr.nhood_enrichment(scadata,cluster_key='rough_celltype')\n",
    "sq.gr.interaction_matrix(scadata,cluster_key='rough_celltype')\n",
    "kscadata = scadata[ scadata.obs.level2_celltype.isin(['Tumor_KC_Cyc','Tumor_KC_Basal','Tumor_KC_Diff','TSK'])].copy()\n",
    "sq.gr.spatial_neighbors(kscadata,spatial_key='advanced_diffusion_coords_avg')\n",
    "sq.gr.nhood_enrichment(kscadata,cluster_key='level2_celltype')\n",
    "# sq.pl.nhood_enrichment(kscadata, cluster_key=\"level2_celltype\",cmap='coolwarm',save='TSKKC_new_good.png',figsize=(3,5))\n",
    "sq.pl.nhood_enrichment(kscadata, cluster_key=\"level2_celltype\",cmap='coolwarm',figsize=(3,5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# patient 10 stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_cscc_data_p10():\n",
    "    \"\"\"\n",
    "    Load and process the cSCC dataset with multiple ST replicates.\n",
    "    \"\"\"\n",
    "    print(\"Loading cSCC data...\")\n",
    "    \n",
    "    # Load SC data\n",
    "    scadata_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/scP10.h5ad')\n",
    "    \n",
    "    # Load all 3 ST datasets\n",
    "    stadata1_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep1.h5ad')\n",
    "    stadata2_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep2.h5ad')\n",
    "    stadata3_p10 = sc.read_h5ad('/home/ehtesamul/sc_st/data/cSCC/processed/stP10rep3.h5ad')\n",
    "    \n",
    "    # Normalize and log transform\n",
    "    for adata in [scadata_p10, stadata1_p10, stadata2_p10, stadata3_p10]:\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "    \n",
    "    # Create rough cell types for SC data\n",
    "    scadata_p10.obs['rough_celltype'] = scadata_p10.obs['level1_celltype'].astype(str)\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='CLEC9A','rough_celltype'] = 'DC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='CD1C','rough_celltype'] = 'DC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='ASDC','rough_celltype'] = 'DC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='PDC','rough_celltype'] = 'PDC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='MDSC','rough_celltype'] = 'DC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='LC','rough_celltype'] = 'DC'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='Mac','rough_celltype'] = 'Myeloid cell'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level1_celltype']=='Tcell','rough_celltype'] = 'T cell'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level2_celltype']=='TSK','rough_celltype'] = 'TSK'\n",
    "    scadata_p10.obs.loc[scadata_p10.obs['level2_celltype'].isin(['Tumor_KC_Basal', 'Tumor_KC_Diff','Tumor_KC_Cyc']),'rough_celltype'] = 'NonTSK'\n",
    "    \n",
    "    return scadata_p10, stadata1_p10, stadata2_p10, stadata3_p10\n",
    "\n",
    "def prepare_combined_st_for_diffusion(stadata1, stadata2, stadata3, scadata):\n",
    "    \"\"\"\n",
    "    Combine all ST datasets for diffusion training while maintaining gene alignment.\n",
    "    Key innovation: Use ALL ST data points for better training.\n",
    "    \"\"\"\n",
    "    print(\"Preparing combined ST data for diffusion training...\")\n",
    "    \n",
    "    # Get common genes between SC and all ST datasets\n",
    "    sc_genes = set(scadata.var_names)\n",
    "    st1_genes = set(stadata1.var_names)\n",
    "    st2_genes = set(stadata2.var_names)\n",
    "    st3_genes = set(stadata3.var_names)\n",
    "    \n",
    "    common_genes = sorted(list(sc_genes & st1_genes & st2_genes & st3_genes))\n",
    "    print(f\"Common genes across all datasets: {len(common_genes)}\")\n",
    "    \n",
    "    # Extract aligned expression data\n",
    "    sc_expr = scadata[:, common_genes].X\n",
    "    st1_expr = stadata1[:, common_genes].X\n",
    "    st2_expr = stadata2[:, common_genes].X\n",
    "    st3_expr = stadata3[:, common_genes].X\n",
    "    \n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(sc_expr, 'toarray'):\n",
    "        sc_expr = sc_expr.toarray()\n",
    "    if hasattr(st1_expr, 'toarray'):\n",
    "        st1_expr = st1_expr.toarray()\n",
    "    if hasattr(st2_expr, 'toarray'):\n",
    "        st2_expr = st2_expr.toarray()\n",
    "    if hasattr(st3_expr, 'toarray'):\n",
    "        st3_expr = st3_expr.toarray()\n",
    "    \n",
    "    # Get spatial coordinates\n",
    "    st1_coords = stadata1.obsm['spatial']\n",
    "    st2_coords = stadata2.obsm['spatial']\n",
    "    st3_coords = stadata3.obsm['spatial']\n",
    "\n",
    "    # Store separate coordinate lists for block-diagonal graph\n",
    "    st_coords_list = [st1_coords, st2_coords, st3_coords]\n",
    "    \n",
    "    # Combine all ST data\n",
    "    st_expr_combined = np.vstack([st1_expr, st2_expr, st3_expr])\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    st_expr_combined = scaler.fit_transform(st_expr_combined)\n",
    "\n",
    "    st_coords_combined = np.vstack([st1_coords, st2_coords, st3_coords])\n",
    "\n",
    "    sc_expr = scaler.fit_transform(sc_expr)\n",
    "\n",
    "\n",
    "    \n",
    "    # Create dataset labels for tracking\n",
    "    dataset_labels = (['dataset1'] * len(st1_expr) + \n",
    "                     ['dataset2'] * len(st2_expr) + \n",
    "                     ['dataset3'] * len(st3_expr))\n",
    "    \n",
    "    print(f\"Combined ST data shape: {st_expr_combined.shape}\")\n",
    "    print(f\"Combined ST coords shape: {st_coords_combined.shape}\")\n",
    "    print(f\"SC data shape: {sc_expr.shape}\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_sc = torch.tensor(sc_expr, dtype=torch.float32)\n",
    "    X_st_combined = torch.tensor(st_expr_combined, dtype=torch.float32)\n",
    "    Y_st_combined = st_coords_combined.astype(np.float32)\n",
    "    \n",
    "    return X_sc, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list\n",
    "\n",
    "# Load and process data\n",
    "scadata_p10, stadata1_p10, stadata2_p10, stadata3_p10 = load_and_process_cscc_data_p10()\n",
    "\n",
    "# Prepare combined data for diffusion\n",
    "X_sc, X_st_combined, Y_st_combined, dataset_labels, common_genes, st_coords_list = prepare_combined_st_for_diffusion(\n",
    "    stadata1_p10, stadata2_p10, stadata3_p10, scadata_p10\n",
    ")\n",
    "\n",
    "print(f\"Data preparation complete!\")\n",
    "print(f\"SC cells: {X_sc.shape[0]}\")\n",
    "print(f\"Combined ST spots: {X_st_combined.shape[0]}\")\n",
    "print(f\"Common genes: {len(common_genes)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_individual_advanced_diffusion_models(scadata, stadata1, stadata2, stadata3):\n",
    "    \"\"\"\n",
    "    Train separate AdvancedHierarchicalDiffusion models for each ST dataset and average the results.\n",
    "    \n",
    "    Returns:\n",
    "        scadata: Updated with averaged coordinates in obsm['advanced_diffusion_coords_avg']\n",
    "        models_all: All trained models for further analysis\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Store results from each model\n",
    "    sc_coords_results = []\n",
    "    models_all = []\n",
    "    \n",
    "    # List of ST datasets for iteration\n",
    "    st_datasets = [\n",
    "        (stadata1, \"dataset1\"),\n",
    "        (stadata2, \"dataset2\"), \n",
    "        (stadata3, \"dataset3\")\n",
    "    ]\n",
    "    \n",
    "    for i, (stadata, dataset_name) in enumerate(st_datasets):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training AdvancedHierarchicalDiffusion model {i+1}/3 for {dataset_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Get common genes between SC and current ST dataset\n",
    "        sc_genes = set(scadata.var_names)\n",
    "        st_genes = set(stadata.var_names)\n",
    "        common_genes = sorted(list(sc_genes & st_genes))\n",
    "        \n",
    "        print(f\"Common genes for {dataset_name}: {len(common_genes)}\")\n",
    "        \n",
    "        # Extract expression data\n",
    "        sc_expr = scadata[:, common_genes].X\n",
    "        st_expr = stadata[:, common_genes].X\n",
    "        \n",
    "        # Convert to dense if sparse\n",
    "        if hasattr(sc_expr, 'toarray'):\n",
    "            sc_expr = sc_expr.toarray()\n",
    "        if hasattr(st_expr, 'toarray'):\n",
    "            st_expr = st_expr.toarray()\n",
    "            \n",
    "        # Get spatial coordinates\n",
    "        st_coords = stadata.obsm['spatial']\n",
    "        \n",
    "        print(f\"SC data shape: {sc_expr.shape}\")\n",
    "        print(f\"ST data shape: {st_expr.shape}\")\n",
    "        print(f\"ST coords shape: {st_coords.shape}\")\n",
    "        \n",
    "        # Initialize AdvancedHierarchicalDiffusion model\n",
    "        model = AdvancedHierarchicalDiffusion(\n",
    "            st_gene_expr=st_expr,\n",
    "            st_coords=st_coords,\n",
    "            sc_gene_expr=sc_expr,\n",
    "            cell_types_sc=scadata.obs['rough_celltype'].values,  # No cell type labels\n",
    "            transport_plan=None,  # No OT transport plan\n",
    "            D_st=None,           # No distance matrices\n",
    "            D_induced=None,\n",
    "            n_genes=len(common_genes),\n",
    "            n_embedding=[512, 256, 128],  # Same as STEMDiffusion\n",
    "            coord_space_diameter=2.00,\n",
    "            sigma=3.0,\n",
    "            alpha=0.8,\n",
    "            mmdbatch=1000,\n",
    "            batch_size=256,\n",
    "            device=device,\n",
    "            lr_e=0.0001,\n",
    "            lr_d=0.0002,\n",
    "            n_timesteps=600,     # Same as STEMDiffusion\n",
    "            n_denoising_blocks=4,\n",
    "            hidden_dim=256,      # Same as STEMDiffusion\n",
    "            num_heads=8,\n",
    "            num_hierarchical_scales=3,\n",
    "            dp=0.2,\n",
    "            outf=f'advanced_diffusion_{dataset_name}'\n",
    "        )\n",
    "        \n",
    "        print(f\"Training model for {dataset_name}...\")\n",
    "        \n",
    "        # Train using new Graph-VAE + Latent Diffusion pipeline\n",
    "        model.train(\n",
    "            encoder_epochs=1000,  # Stage 1: Domain alignment encoder\n",
    "            vae_epochs=1200,       # Stage 2: Graph-VAE training\n",
    "            diffusion_epochs=2500, # Stage 3: Latent diffusion\n",
    "            lambda_struct=3.0     # Structure loss weight\n",
    "        )\n",
    "        \n",
    "        model.plot_training_losses()\n",
    "        \n",
    "        print(f\"Generating SC coordinates using model {i+1}...\")\n",
    "        # Sample SC coordinates using new Graph-VAE + Latent Diffusion pipeline\n",
    "        # sc_coords = model.sample_sc_coordinates(\n",
    "        #     n_samples=None     # Use all SC cells\n",
    "        # )\n",
    "        sc_coords = model.sample_sc_coordinates_batched(\n",
    "            batch_size=512  # Even smaller batches\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        sc_coords_results.append(sc_coords)\n",
    "        models_all.append(model)\n",
    "        \n",
    "        print(f\"Model {i+1} complete! Generated coordinates shape: {sc_coords.shape}\")\n",
    "        \n",
    "        # Clean up GPU memory\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Average the results from all 3 models\n",
    "    print(f\"\\nAveraging results from {len(sc_coords_results)} models...\")\n",
    "    sc_coords_avg = np.mean(sc_coords_results, axis=0)\n",
    "    \n",
    "    # Verify shapes match\n",
    "    shapes = [coords.shape for coords in sc_coords_results]\n",
    "    assert all(shape == shapes[0] for shape in shapes), f\"Shape mismatch: {shapes}\"\n",
    "    \n",
    "    print(f\"Final averaged coordinates shape: {sc_coords_avg.shape}\")\n",
    "    \n",
    "    # Add to AnnData\n",
    "    scadata.obsm['advanced_diffusion_coords_avg'] = sc_coords_avg\n",
    "    \n",
    "    # Optionally, save individual results too\n",
    "    for i, coords in enumerate(sc_coords_results):\n",
    "        scadata.obsm[f'advanced_diffusion_coords_rep{i+1}'] = coords\n",
    "    \n",
    "    print(f\"\\nAdvanced diffusion training complete!\")\n",
    "    print(f\"Results saved in scadata.obsm['advanced_diffusion_coords_avg']\")\n",
    "    \n",
    "    return scadata, models_all\n",
    "\n",
    "# Load and process data\n",
    "scadata_p10, stadata1_p10, stadata2_p10, stadata3_p10 = load_and_process_cscc_data_p10()\n",
    "\n",
    "# Train individual AdvancedHierarchicalDiffusion models and get averaged results\n",
    "scadata_p10, advanced_models_p10 = train_individual_advanced_diffusion_models(\n",
    "    scadata_p10, stadata1_p10, stadata2_p10, stadata3_p10\n",
    ")\n",
    "\n",
    "print(\"Advanced diffusion training complete! Results saved in scadata.obsm['advanced_diffusion_coords_avg']\")\n",
    "\n",
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (4, 4)\n",
    "\n",
    "my_tab20 = sns.color_palette(\"tab20\", n_colors=20).as_hex()\n",
    "\n",
    "# Plot 1: Averaged coordinates\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc.pl.embedding(scadata_p10, basis='advanced_diffusion_coords_avg', color='rough_celltype',\n",
    "               size=85, title='SC Advanced Diffusion Coords (Averaged)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Individual model results\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sc.pl.embedding(scadata_p10, basis=f'advanced_diffusion_coords_rep{i+1}', color='rough_celltype',\n",
    "                   size=85, title=f'SC Coordinates (Advanced Model {i+1})',\n",
    "                   palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results with separate plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (6, 6)\n",
    "# import scanpy as sc\n",
    "# sc.settings.set_figure_params(figsize=(4,4), dpi=100)\n",
    "\n",
    "my_tab20 = sns.color_palette(\"tab20\", n_colors=20).as_hex()\n",
    "\n",
    "\n",
    "# Plot 1: Averaged coordinates\n",
    "plt.figure(figsize=(4, 4))\n",
    "sc.pl.embedding(scadata_p10, basis='advanced_diffusion_coords_avg', color='rough_celltype',\n",
    "               size=85, title='SC Spatial Coordinates (Averaged from 3 Models)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Model 1 results\n",
    "plt.figure(figsize=(4, 4))\n",
    "sc.pl.embedding(scadata_p10, basis='advanced_diffusion_coords_rep1', color='rough_celltype',\n",
    "               size=85, title='SC Coordinates (Model 1)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Model 2 results\n",
    "plt.figure(figsize=(4, 4))\n",
    "sc.pl.embedding(scadata_p10, basis='advanced_diffusion_coords_rep2', color='rough_celltype',\n",
    "               size=85, title='SC Coordinates (Model 2)',\n",
    "               palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "my_tab20 = sns.color_palette(\"tab20\", n_colors=12).as_hex()\n",
    "\n",
    "# Plot 4: Model 3 results\n",
    "plt.figure(figsize=(4, 4))\n",
    "sc.pl.embedding(scadata_p10, basis='advanced_diffusion_coords_rep3', color='rough_celltype',\n",
    "               size=85, title='SC Coordinates (Model 3)',\n",
    "             palette=my_tab20, legend_loc='right margin', legend_fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scadata_p10.obs['selection'] = (scadata_p10.obs['level2_celltype']=='TSK').astype(int)\n",
    "scadata_p10.obs['selection2'] = (scadata_p10.obs['level1_celltype']=='Fibroblast').astype(int)\n",
    "scadata_p10.obs['selection3'] = (scadata_p10.obs['rough_celltype']=='Epithelial').astype(int)\n",
    "\n",
    "# figsize(6,5)\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "sc.pl.spatial(scadata_p10, color=['selection','selection2','selection3','level3_celltype'], spot_size=0.025,cmap='bwr',basis='advanced_diffusion_coords_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(scadata_p10,color=\"level3_celltype\",groups=[\"TSK\"],spot_size=0.03, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squidpy as sq\n",
    "sq.gr.spatial_neighbors(scadata_p10,spatial_key='advanced_diffusion_coords_avg')\n",
    "sq.gr.nhood_enrichment(scadata_p10,cluster_key='rough_celltype')\n",
    "sq.gr.interaction_matrix(scadata_p10,cluster_key='rough_celltype')\n",
    "kscadata_p10 = scadata_p10[ scadata_p10.obs.level2_celltype.isin(['Tumor_KC_Cyc','Tumor_KC_Basal','Tumor_KC_Diff','TSK'])].copy()\n",
    "sq.gr.spatial_neighbors(kscadata_p10,spatial_key='advanced_diffusion_coords_avg')\n",
    "sq.gr.nhood_enrichment(kscadata_p10,cluster_key='level2_celltype')\n",
    "# sq.pl.nhood_enrichment(kscadata, cluster_key=\"level2_celltype\",cmap='coolwarm',save='TSKKC_new_best_p10.svg',figsize=(3,5), title=None)\n",
    "# sq.pl.nhood_enrichment(kscadata, cluster_key=\"level2_celltype\", cmap='coolwarm', save='TSKKC_new_best_p10.svg', figsize=(3,5), ylabel='')\n",
    "# sq.pl.nhood_enrichment(kscadata, cluster_key=\"level2_celltype\",cmap='coolwarm',figsize=(3,5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,5))\n",
    "sq.pl.nhood_enrichment(kscadata_p10, cluster_key=\"level2_celltype\", cmap='coolwarm', ax=ax)\n",
    "ax.set_ylabel('')\n",
    "# plt.savefig('TSKKC_new_best_p10.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figsize(4,4)\n",
    "# sc.settings.file_format_figs = 'svg'\n",
    "\n",
    "sc.pl.spatial(scadata_p10,color=\"level2_celltype\",groups=[\"Tumor_KC_Cyc\"],spot_size=0.03, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False,save='P10_cyc')\n",
    "sc.pl.spatial(scadata_p10,color=\"level2_celltype\",groups=[\"Tumor_KC_Basal\"],spot_size=0.03, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False,save='P10_bas')\n",
    "sc.pl.spatial(scadata_p10,color=\"level2_celltype\",groups=[\"Tumor_KC_Diff\"],spot_size=0.03, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False,save='P10_diff')\n",
    "#save='nonTSK',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(scadata_p10,color=\"level2_celltype\",groups=[\"PDC\"],spot_size=0.04, show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(scadata_p10,color=\"level2_celltype\",groups=['Tumor_KC_Cyc','Tumor_KC_Basal','Tumor_KC_Diff'],spot_size=0.025, \n",
    "              show=True,basis='advanced_diffusion_coords_avg',title='reconstructed',na_in_legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehtesamenv_gains",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
